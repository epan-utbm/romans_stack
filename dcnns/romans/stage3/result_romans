Script started on Thu 09 Feb 2017 01:52:32 GMT
]0;kevin@kevin-desktop: ~/catkin_ws/src/romans_stack/dcnns/romans/stage3kevin@kevin-desktop:~/catkin_ws/src/romans_stack/dcnns/romans/stage3$ python solve.py 
/home/kevin/caffeplus/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/kevin/caffeplus/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/kevin/caffeplus/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0209 01:52:50.986137 14948 solver.cpp:48] Initializing solver from parameters: 
train_net: "train.prototxt"
test_net: "test.prototxt"
test_iter: 1
test_interval: 999999999
base_lr: 0.001
display: 50
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 10000
snapshot: 1000
snapshot_prefix: "/home/kevin/snapshot/romans_stage3"
solver_mode: GPU
average_loss: 1000
I0209 01:52:50.986279 14948 solver.cpp:81] Creating training net from train_net file: train.prototxt
I0209 01:52:50.987251 14948 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "rgb"
  top: "depth"
  top: "label"
  python_param {
    module: "data_layers.rgbd_data_layer"
    layer: "RGBDDataLayer"
    param_str: "{\'img_size\': (224, 224), \'split\': \'train\', \'dataset_dir\': \'/home/kevin/dataset/rgbd\', \'randomize\': True, \'mean\': (104.00698793, 116.66876762, 122.67891434), \'seed\': 1337, \'batch_size\': 64, \'crop_size\': (224, 224, 224, 224)}"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "rgb"
  top: "conv1_1"
  param {
    name: "conv1_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    name: "conv1_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "rgb_pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "rgb_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "rgb_pool1"
  top: "conv2_1"
  param {
    name: "conv2_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    name: "conv2_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "rgb_pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "rgb_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "rgb_pool2"
  top: "conv3_1"
  param {
    name: "conv3_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    name: "conv3_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    name: "conv3_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "rgb_pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "rgb_pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "rgb_pool3"
  top: "conv4_1"
  param {
    name: "conv4_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    name: "conv4_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    name: "conv4_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "rgb_pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "rgb_pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "rgb_pool4"
  top: "conv5_1"
  param {
    name: "conv5_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    name: "conv5_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    name: "conv5_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rgb_pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "rgb_pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "rgb_fc6"
  type: "InnerProduct"
  bottom: "rgb_pool5"
  top: "rgb_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_relu6"
  type: "ReLU"
  bottom: "rgb_fc6"
  top: "rgb_fc6"
}
layer {
  name: "rgb_drop6"
  type: "Dropout"
  bottom: "rgb_fc6"
  top: "rgb_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "rgb_fc7"
  type: "InnerProduct"
  bottom: "rgb_fc6"
  top: "rgb_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_relu7"
  type: "ReLU"
  bottom: "rgb_fc7"
  top: "rgb_fc7"
}
layer {
  name: "rgb_drop7"
  type: "Dropout"
  bottom: "rgb_fc7"
  top: "rgb_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "depth"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "depth_pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "depth_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "depth_pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "depth_pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "depth_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "depth_pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "depth_pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "depth_pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "depth_pool3"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "depth_pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "depth_pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "depth_fc6"
  type: "InnerProduct"
  bottom: "depth_pool5"
  top: "depth_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "depth_relu6"
  type: "ReLU"
  bottom: "depth_fc6"
  top: "depth_fc6"
}
layer {
  name: "depth_drop6"
  type: "Dropout"
  bottom: "depth_fc6"
  top: "depth_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "depth_fc7"
  type: "InnerProduct"
  bottom: "depth_fc6"
  top: "depth_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "depth_relu7"
  type: "ReLU"
  bottom: "depth_fc7"
  top: "depth_fc7"
}
layer {
  name: "depth_drop7"
  type: "Dropout"
  bottom: "depth_fc7"
  top: "depth_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "rgb_fc7"
  bottom: "depth_fc7"
  top: "concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fuse_fc1"
  type: "InnerProduct"
  bottom: "concat"
  top: "fuse_fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fuse_relu1"
  type: "ReLU"
  bottom: "fuse_fc1"
  top: "fuse_fc1"
}
layer {
  name: "fuse_drop1"
  type: "Dropout"
  bottom: "fuse_fc1"
  top: "fuse_fc1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fuse_fc2"
  type: "InnerProduct"
  bottom: "fuse_fc1"
  top: "fuse_fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fuse_relu2"
  type: "ReLU"
  bottom: "fuse_fc2"
  top: "fuse_fc2"
}
layer {
  name: "fuse_drop2"
  type: "Dropout"
  bottom: "fuse_fc2"
  top: "fuse_fc2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "rgbd_fc8"
  type: "InnerProduct"
  bottom: "fuse_fc2"
  top: "rgbd_fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgbd_accuracy"
  type: "Accuracy"
  bottom: "rgbd_fc8"
  bottom: "label"
  top: "rgbd_accuracy"
}
layer {
  name: "rgbd_loss"
  type: "SoftmaxWithLoss"
  bottom: "rgbd_fc8"
  bottom: "label"
  top: "rgbd_loss"
}
I0209 01:52:50.989475 14948 layer_factory.hpp:77] Creating layer data
I0209 01:52:51.157369 14948 net.cpp:91] Creating Layer data
I0209 01:52:51.157398 14948 net.cpp:399] data -> rgb
I0209 01:52:51.157407 14948 net.cpp:399] data -> depth
I0209 01:52:51.157413 14948 net.cpp:399] data -> label
{'img_size': (224, 224), 'split': 'train', 'dataset_dir': '/home/kevin/dataset/rgbd', 'crop_size': (224, 224, 224, 224), 'randomize': True, 'seed': 1337, 'batch_size': 64, 'mean': (104.00698793, 116.66876762, 122.67891434)}
I0209 01:52:51.435160 14948 net.cpp:141] Setting up data
I0209 01:52:51.435187 14948 net.cpp:148] Top shape: 64 3 224 224 (9633792)
I0209 01:52:51.435194 14948 net.cpp:148] Top shape: 64 1 224 224 (3211264)
I0209 01:52:51.435197 14948 net.cpp:148] Top shape: 64 1 (64)
I0209 01:52:51.435201 14948 net.cpp:156] Memory required for data: 51380480
I0209 01:52:51.435220 14948 layer_factory.hpp:77] Creating layer label_data_2_split
I0209 01:52:51.435243 14948 net.cpp:91] Creating Layer label_data_2_split
I0209 01:52:51.435248 14948 net.cpp:425] label_data_2_split <- label
I0209 01:52:51.435266 14948 net.cpp:399] label_data_2_split -> label_data_2_split_0
I0209 01:52:51.435274 14948 net.cpp:399] label_data_2_split -> label_data_2_split_1
I0209 01:52:51.435319 14948 net.cpp:141] Setting up label_data_2_split
I0209 01:52:51.435334 14948 net.cpp:148] Top shape: 64 1 (64)
I0209 01:52:51.435338 14948 net.cpp:148] Top shape: 64 1 (64)
I0209 01:52:51.435341 14948 net.cpp:156] Memory required for data: 51380992
I0209 01:52:51.435355 14948 layer_factory.hpp:77] Creating layer conv1_1
I0209 01:52:51.435375 14948 net.cpp:91] Creating Layer conv1_1
I0209 01:52:51.435390 14948 net.cpp:425] conv1_1 <- rgb
I0209 01:52:51.435396 14948 net.cpp:399] conv1_1 -> conv1_1
I0209 01:52:51.436228 14948 net.cpp:141] Setting up conv1_1
I0209 01:52:51.436240 14948 net.cpp:148] Top shape: 64 64 224 224 (205520896)
I0209 01:52:51.436244 14948 net.cpp:156] Memory required for data: 873464576
I0209 01:52:51.436252 14948 layer_factory.hpp:77] Creating layer relu1_1
I0209 01:52:51.436269 14948 net.cpp:91] Creating Layer relu1_1
I0209 01:52:51.436274 14948 net.cpp:425] relu1_1 <- conv1_1
I0209 01:52:51.436278 14948 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0209 01:52:51.436293 14948 net.cpp:141] Setting up relu1_1
I0209 01:52:51.436308 14948 net.cpp:148] Top shape: 64 64 224 224 (205520896)
I0209 01:52:51.436312 14948 net.cpp:156] Memory required for data: 1695548160
I0209 01:52:51.436316 14948 layer_factory.hpp:77] Creating layer conv1_2
I0209 01:52:51.436336 14948 net.cpp:91] Creating Layer conv1_2
I0209 01:52:51.436341 14948 net.cpp:425] conv1_2 <- conv1_1
I0209 01:52:51.436357 14948 net.cpp:399] conv1_2 -> conv1_2
I0209 01:52:51.436621 14948 net.cpp:141] Setting up conv1_2
I0209 01:52:51.436628 14948 net.cpp:148] Top shape: 64 64 224 224 (205520896)
I0209 01:52:51.436632 14948 net.cpp:156] Memory required for data: 2517631744
I0209 01:52:51.436638 14948 layer_factory.hpp:77] Creating layer relu1_2
I0209 01:52:51.436643 14948 net.cpp:91] Creating Layer relu1_2
I0209 01:52:51.436648 14948 net.cpp:425] relu1_2 <- conv1_2
I0209 01:52:51.436662 14948 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0209 01:52:51.436667 14948 net.cpp:141] Setting up relu1_2
I0209 01:52:51.436673 14948 net.cpp:148] Top shape: 64 64 224 224 (205520896)
I0209 01:52:51.436687 14948 net.cpp:156] Memory required for data: 3339715328
I0209 01:52:51.436691 14948 layer_factory.hpp:77] Creating layer rgb_pool1
I0209 01:52:51.436697 14948 net.cpp:91] Creating Layer rgb_pool1
I0209 01:52:51.436713 14948 net.cpp:425] rgb_pool1 <- conv1_2
I0209 01:52:51.436728 14948 net.cpp:399] rgb_pool1 -> rgb_pool1
I0209 01:52:51.436771 14948 net.cpp:141] Setting up rgb_pool1
I0209 01:52:51.436776 14948 net.cpp:148] Top shape: 64 64 112 112 (51380224)
I0209 01:52:51.436789 14948 net.cpp:156] Memory required for data: 3545236224
I0209 01:52:51.436794 14948 layer_factory.hpp:77] Creating layer conv2_1
I0209 01:52:51.436800 14948 net.cpp:91] Creating Layer conv2_1
I0209 01:52:51.436813 14948 net.cpp:425] conv2_1 <- rgb_pool1
I0209 01:52:51.436818 14948 net.cpp:399] conv2_1 -> conv2_1
I0209 01:52:51.437664 14948 net.cpp:141] Setting up conv2_1
I0209 01:52:51.437675 14948 net.cpp:148] Top shape: 64 128 112 112 (102760448)
I0209 01:52:51.437680 14948 net.cpp:156] Memory required for data: 3956278016
I0209 01:52:51.437697 14948 layer_factory.hpp:77] Creating layer relu2_1
I0209 01:52:51.437703 14948 net.cpp:91] Creating Layer relu2_1
I0209 01:52:51.437708 14948 net.cpp:425] relu2_1 <- conv2_1
I0209 01:52:51.437727 14948 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0209 01:52:51.437743 14948 net.cpp:141] Setting up relu2_1
I0209 01:52:51.437748 14948 net.cpp:148] Top shape: 64 128 112 112 (102760448)
I0209 01:52:51.437762 14948 net.cpp:156] Memory required for data: 4367319808
I0209 01:52:51.437767 14948 layer_factory.hpp:77] Creating layer conv2_2
I0209 01:52:51.437774 14948 net.cpp:91] Creating Layer conv2_2
I0209 01:52:51.437778 14948 net.cpp:425] conv2_2 <- conv2_1
I0209 01:52:51.437784 14948 net.cpp:399] conv2_2 -> conv2_2
I0209 01:52:51.438462 14948 net.cpp:141] Setting up conv2_2
I0209 01:52:51.438470 14948 net.cpp:148] Top shape: 64 128 112 112 (102760448)
I0209 01:52:51.438474 14948 net.cpp:156] Memory required for data: 4778361600
I0209 01:52:51.438479 14948 layer_factory.hpp:77] Creating layer relu2_2
I0209 01:52:51.438485 14948 net.cpp:91] Creating Layer relu2_2
I0209 01:52:51.438489 14948 net.cpp:425] relu2_2 <- conv2_2
I0209 01:52:51.438495 14948 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0209 01:52:51.438500 14948 net.cpp:141] Setting up relu2_2
I0209 01:52:51.438505 14948 net.cpp:148] Top shape: 64 128 112 112 (102760448)
I0209 01:52:51.438509 14948 net.cpp:156] Memory required for data: 5189403392
I0209 01:52:51.438514 14948 layer_factory.hpp:77] Creating layer rgb_pool2
I0209 01:52:51.438519 14948 net.cpp:91] Creating Layer rgb_pool2
I0209 01:52:51.438534 14948 net.cpp:425] rgb_pool2 <- conv2_2
I0209 01:52:51.438539 14948 net.cpp:399] rgb_pool2 -> rgb_pool2
I0209 01:52:51.438558 14948 net.cpp:141] Setting up rgb_pool2
I0209 01:52:51.438565 14948 net.cpp:148] Top shape: 64 128 56 56 (25690112)
I0209 01:52:51.438568 14948 net.cpp:156] Memory required for data: 5292163840
I0209 01:52:51.438573 14948 layer_factory.hpp:77] Creating layer conv3_1
I0209 01:52:51.438581 14948 net.cpp:91] Creating Layer conv3_1
I0209 01:52:51.438585 14948 net.cpp:425] conv3_1 <- rgb_pool2
I0209 01:52:51.438601 14948 net.cpp:399] conv3_1 -> conv3_1
I0209 01:52:51.440035 14948 net.cpp:141] Setting up conv3_1
I0209 01:52:51.440047 14948 net.cpp:148] Top shape: 64 256 56 56 (51380224)
I0209 01:52:51.440050 14948 net.cpp:156] Memory required for data: 5497684736
I0209 01:52:51.440058 14948 layer_factory.hpp:77] Creating layer relu3_1
I0209 01:52:51.440064 14948 net.cpp:91] Creating Layer relu3_1
I0209 01:52:51.440068 14948 net.cpp:425] relu3_1 <- conv3_1
I0209 01:52:51.440074 14948 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0209 01:52:51.440080 14948 net.cpp:141] Setting up relu3_1
I0209 01:52:51.440085 14948 net.cpp:148] Top shape: 64 256 56 56 (51380224)
I0209 01:52:51.440089 14948 net.cpp:156] Memory required for data: 5703205632
I0209 01:52:51.440093 14948 layer_factory.hpp:77] Creating layer conv3_2
I0209 01:52:51.440101 14948 net.cpp:91] Creating Layer conv3_2
I0209 01:52:51.440105 14948 net.cpp:425] conv3_2 <- conv3_1
I0209 01:52:51.440111 14948 net.cpp:399] conv3_2 -> conv3_2
I0209 01:52:51.442896 14948 net.cpp:141] Setting up conv3_2
I0209 01:52:51.442909 14948 net.cpp:148] Top shape: 64 256 56 56 (51380224)
I0209 01:52:51.442912 14948 net.cpp:156] Memory required for data: 5908726528
I0209 01:52:51.442919 14948 layer_factory.hpp:77] Creating layer relu3_2
I0209 01:52:51.442924 14948 net.cpp:91] Creating Layer relu3_2
I0209 01:52:51.442929 14948 net.cpp:425] relu3_2 <- conv3_2
I0209 01:52:51.442934 14948 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0209 01:52:51.442940 14948 net.cpp:141] Setting up relu3_2
I0209 01:52:51.442945 14948 net.cpp:148] Top shape: 64 256 56 56 (51380224)
I0209 01:52:51.442960 14948 net.cpp:156] Memory required for data: 6114247424
I0209 01:52:51.442965 14948 layer_factory.hpp:77] Creating layer conv3_3
I0209 01:52:51.442972 14948 net.cpp:91] Creating Layer conv3_3
I0209 01:52:51.442977 14948 net.cpp:425] conv3_3 <- conv3_2
I0209 01:52:51.442982 14948 net.cpp:399] conv3_3 -> conv3_3
I0209 01:52:51.445886 14948 net.cpp:141] Setting up conv3_3
I0209 01:52:51.445899 14948 net.cpp:148] Top shape: 64 256 56 56 (51380224)
I0209 01:52:51.445904 14948 net.cpp:156] Memory required for data: 6319768320
I0209 01:52:51.445920 14948 layer_factory.hpp:77] Creating layer relu3_3
I0209 01:52:51.445926 14948 net.cpp:91] Creating Layer relu3_3
I0209 01:52:51.445931 14948 net.cpp:425] relu3_3 <- conv3_3
I0209 01:52:51.445947 14948 net.cpp:386] relu3_3 -> conv3_3 (in-place)
I0209 01:52:51.445963 14948 net.cpp:141] Setting up relu3_3
I0209 01:52:51.445968 14948 net.cpp:148] Top shape: 64 256 56 56 (51380224)
I0209 01:52:51.445986 14948 net.cpp:156] Memory required for data: 6525289216
I0209 01:52:51.445989 14948 layer_factory.hpp:77] Creating layer rgb_pool3
I0209 01:52:51.446004 14948 net.cpp:91] Creating Layer rgb_pool3
I0209 01:52:51.446008 14948 net.cpp:425] rgb_pool3 <- conv3_3
I0209 01:52:51.446027 14948 net.cpp:399] rgb_pool3 -> rgb_pool3
I0209 01:52:51.446058 14948 net.cpp:141] Setting up rgb_pool3
I0209 01:52:51.446072 14948 net.cpp:148] Top shape: 64 256 28 28 (12845056)
I0209 01:52:51.446076 14948 net.cpp:156] Memory required for data: 6576669440
I0209 01:52:51.446090 14948 layer_factory.hpp:77] Creating layer conv4_1
I0209 01:52:51.446097 14948 net.cpp:91] Creating Layer conv4_1
I0209 01:52:51.446101 14948 net.cpp:425] conv4_1 <- rgb_pool3
I0209 01:52:51.446121 14948 net.cpp:399] conv4_1 -> conv4_1
I0209 01:52:51.452383 14948 net.cpp:141] Setting up conv4_1
I0209 01:52:51.452407 14948 net.cpp:148] Top shape: 64 512 28 28 (25690112)
I0209 01:52:51.452412 14948 net.cpp:156] Memory required for data: 6679429888
I0209 01:52:51.452421 14948 layer_factory.hpp:77] Creating layer relu4_1
I0209 01:52:51.452441 14948 net.cpp:91] Creating Layer relu4_1
I0209 01:52:51.452446 14948 net.cpp:425] relu4_1 <- conv4_1
I0209 01:52:51.452466 14948 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0209 01:52:51.452482 14948 net.cpp:141] Setting up relu4_1
I0209 01:52:51.452497 14948 net.cpp:148] Top shape: 64 512 28 28 (25690112)
I0209 01:52:51.452500 14948 net.cpp:156] Memory required for data: 6782190336
I0209 01:52:51.452513 14948 layer_factory.hpp:77] Creating layer conv4_2
I0209 01:52:51.452533 14948 net.cpp:91] Creating Layer conv4_2
I0209 01:52:51.452536 14948 net.cpp:425] conv4_2 <- conv4_1
I0209 01:52:51.452551 14948 net.cpp:399] conv4_2 -> conv4_2
I0209 01:52:51.463881 14948 net.cpp:141] Setting up conv4_2
I0209 01:52:51.463907 14948 net.cpp:148] Top shape: 64 512 28 28 (25690112)
I0209 01:52:51.463912 14948 net.cpp:156] Memory required for data: 6884950784
I0209 01:52:51.463925 14948 layer_factory.hpp:77] Creating layer relu4_2
I0209 01:52:51.463945 14948 net.cpp:91] Creating Layer relu4_2
I0209 01:52:51.463950 14948 net.cpp:425] relu4_2 <- conv4_2
I0209 01:52:51.463956 14948 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0209 01:52:51.463964 14948 net.cpp:141] Setting up relu4_2
I0209 01:52:51.463969 14948 net.cpp:148] Top shape: 64 512 28 28 (25690112)
I0209 01:52:51.463973 14948 net.cpp:156] Memory required for data: 6987711232
I0209 01:52:51.463989 14948 layer_factory.hpp:77] Creating layer conv4_3
I0209 01:52:51.464007 14948 net.cpp:91] Creating Layer conv4_3
I0209 01:52:51.464011 14948 net.cpp:425] conv4_3 <- conv4_2
I0209 01:52:51.464027 14948 net.cpp:399] conv4_3 -> conv4_3
I0209 01:52:51.475417 14948 net.cpp:141] Setting up conv4_3
I0209 01:52:51.475450 14948 net.cpp:148] Top shape: 64 512 28 28 (25690112)
I0209 01:52:51.475455 14948 net.cpp:156] Memory required for data: 7090471680
I0209 01:52:51.475463 14948 layer_factory.hpp:77] Creating layer relu4_3
I0209 01:52:51.475473 14948 net.cpp:91] Creating Layer relu4_3
I0209 01:52:51.475478 14948 net.cpp:425] relu4_3 <- conv4_3
I0209 01:52:51.475484 14948 net.cpp:386] relu4_3 -> conv4_3 (in-place)
I0209 01:52:51.475504 14948 net.cpp:141] Setting up relu4_3
I0209 01:52:51.475519 14948 net.cpp:148] Top shape: 64 512 28 28 (25690112)
I0209 01:52:51.475522 14948 net.cpp:156] Memory required for data: 7193232128
I0209 01:52:51.475538 14948 layer_factory.hpp:77] Creating layer rgb_pool4
I0209 01:52:51.475559 14948 net.cpp:91] Creating Layer rgb_pool4
I0209 01:52:51.475564 14948 net.cpp:425] rgb_pool4 <- conv4_3
I0209 01:52:51.475577 14948 net.cpp:399] rgb_pool4 -> rgb_pool4
I0209 01:52:51.475628 14948 net.cpp:141] Setting up rgb_pool4
I0209 01:52:51.475646 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:51.475659 14948 net.cpp:156] Memory required for data: 7218922240
I0209 01:52:51.475663 14948 layer_factory.hpp:77] Creating layer conv5_1
I0209 01:52:51.475697 14948 net.cpp:91] Creating Layer conv5_1
I0209 01:52:51.475702 14948 net.cpp:425] conv5_1 <- rgb_pool4
I0209 01:52:51.475708 14948 net.cpp:399] conv5_1 -> conv5_1
I0209 01:52:51.486774 14948 net.cpp:141] Setting up conv5_1
I0209 01:52:51.486800 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:51.486805 14948 net.cpp:156] Memory required for data: 7244612352
I0209 01:52:51.486814 14948 layer_factory.hpp:77] Creating layer relu5_1
I0209 01:52:51.486835 14948 net.cpp:91] Creating Layer relu5_1
I0209 01:52:51.486840 14948 net.cpp:425] relu5_1 <- conv5_1
I0209 01:52:51.486857 14948 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0209 01:52:51.486876 14948 net.cpp:141] Setting up relu5_1
I0209 01:52:51.486889 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:51.486893 14948 net.cpp:156] Memory required for data: 7270302464
I0209 01:52:51.486907 14948 layer_factory.hpp:77] Creating layer conv5_2
I0209 01:52:51.486925 14948 net.cpp:91] Creating Layer conv5_2
I0209 01:52:51.486929 14948 net.cpp:425] conv5_2 <- conv5_1
I0209 01:52:51.486944 14948 net.cpp:399] conv5_2 -> conv5_2
I0209 01:52:51.501210 14948 net.cpp:141] Setting up conv5_2
I0209 01:52:51.501238 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:51.501243 14948 net.cpp:156] Memory required for data: 7295992576
I0209 01:52:51.501252 14948 layer_factory.hpp:77] Creating layer relu5_2
I0209 01:52:51.501273 14948 net.cpp:91] Creating Layer relu5_2
I0209 01:52:51.501278 14948 net.cpp:425] relu5_2 <- conv5_2
I0209 01:52:51.501287 14948 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0209 01:52:51.501305 14948 net.cpp:141] Setting up relu5_2
I0209 01:52:51.501310 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:51.501324 14948 net.cpp:156] Memory required for data: 7321682688
I0209 01:52:51.501328 14948 layer_factory.hpp:77] Creating layer conv5_3
I0209 01:52:51.501348 14948 net.cpp:91] Creating Layer conv5_3
I0209 01:52:51.501363 14948 net.cpp:425] conv5_3 <- conv5_2
I0209 01:52:51.501379 14948 net.cpp:399] conv5_3 -> conv5_3
I0209 01:52:51.512547 14948 net.cpp:141] Setting up conv5_3
I0209 01:52:51.512576 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:51.512581 14948 net.cpp:156] Memory required for data: 7347372800
I0209 01:52:51.512590 14948 layer_factory.hpp:77] Creating layer relu5_3
I0209 01:52:51.512611 14948 net.cpp:91] Creating Layer relu5_3
I0209 01:52:51.512625 14948 net.cpp:425] relu5_3 <- conv5_3
I0209 01:52:51.512632 14948 net.cpp:386] relu5_3 -> conv5_3 (in-place)
I0209 01:52:51.512662 14948 net.cpp:141] Setting up relu5_3
I0209 01:52:51.512667 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:51.512671 14948 net.cpp:156] Memory required for data: 7373062912
I0209 01:52:51.512686 14948 layer_factory.hpp:77] Creating layer rgb_pool5
I0209 01:52:51.512704 14948 net.cpp:91] Creating Layer rgb_pool5
I0209 01:52:51.512709 14948 net.cpp:425] rgb_pool5 <- conv5_3
I0209 01:52:51.512724 14948 net.cpp:399] rgb_pool5 -> rgb_pool5
I0209 01:52:51.512780 14948 net.cpp:141] Setting up rgb_pool5
I0209 01:52:51.512799 14948 net.cpp:148] Top shape: 64 512 7 7 (1605632)
I0209 01:52:51.512804 14948 net.cpp:156] Memory required for data: 7379485440
I0209 01:52:51.512816 14948 layer_factory.hpp:77] Creating layer rgb_fc6
I0209 01:52:51.512837 14948 net.cpp:91] Creating Layer rgb_fc6
I0209 01:52:51.512841 14948 net.cpp:425] rgb_fc6 <- rgb_pool5
I0209 01:52:51.512848 14948 net.cpp:399] rgb_fc6 -> rgb_fc6
I0209 01:52:51.993975 14948 net.cpp:141] Setting up rgb_fc6
I0209 01:52:51.994006 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:51.994011 14948 net.cpp:156] Memory required for data: 7380534016
I0209 01:52:51.994021 14948 layer_factory.hpp:77] Creating layer rgb_relu6
I0209 01:52:51.994045 14948 net.cpp:91] Creating Layer rgb_relu6
I0209 01:52:51.994062 14948 net.cpp:425] rgb_relu6 <- rgb_fc6
I0209 01:52:51.994079 14948 net.cpp:386] rgb_relu6 -> rgb_fc6 (in-place)
I0209 01:52:51.994099 14948 net.cpp:141] Setting up rgb_relu6
I0209 01:52:51.994107 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:51.994112 14948 net.cpp:156] Memory required for data: 7381582592
I0209 01:52:51.994118 14948 layer_factory.hpp:77] Creating layer rgb_drop6
I0209 01:52:51.994132 14948 net.cpp:91] Creating Layer rgb_drop6
I0209 01:52:51.994138 14948 net.cpp:425] rgb_drop6 <- rgb_fc6
I0209 01:52:51.994143 14948 net.cpp:386] rgb_drop6 -> rgb_fc6 (in-place)
I0209 01:52:51.994174 14948 net.cpp:141] Setting up rgb_drop6
I0209 01:52:51.994181 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:51.994195 14948 net.cpp:156] Memory required for data: 7382631168
I0209 01:52:51.994199 14948 layer_factory.hpp:77] Creating layer rgb_fc7
I0209 01:52:51.994218 14948 net.cpp:91] Creating Layer rgb_fc7
I0209 01:52:51.994235 14948 net.cpp:425] rgb_fc7 <- rgb_fc6
I0209 01:52:51.994241 14948 net.cpp:399] rgb_fc7 -> rgb_fc7
I0209 01:52:52.073426 14948 net.cpp:141] Setting up rgb_fc7
I0209 01:52:52.073457 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.073462 14948 net.cpp:156] Memory required for data: 7383679744
I0209 01:52:52.073472 14948 layer_factory.hpp:77] Creating layer rgb_relu7
I0209 01:52:52.073494 14948 net.cpp:91] Creating Layer rgb_relu7
I0209 01:52:52.073515 14948 net.cpp:425] rgb_relu7 <- rgb_fc7
I0209 01:52:52.073532 14948 net.cpp:386] rgb_relu7 -> rgb_fc7 (in-place)
I0209 01:52:52.073542 14948 net.cpp:141] Setting up rgb_relu7
I0209 01:52:52.073549 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.073552 14948 net.cpp:156] Memory required for data: 7384728320
I0209 01:52:52.073557 14948 layer_factory.hpp:77] Creating layer rgb_drop7
I0209 01:52:52.073580 14948 net.cpp:91] Creating Layer rgb_drop7
I0209 01:52:52.073596 14948 net.cpp:425] rgb_drop7 <- rgb_fc7
I0209 01:52:52.073611 14948 net.cpp:386] rgb_drop7 -> rgb_fc7 (in-place)
I0209 01:52:52.073642 14948 net.cpp:141] Setting up rgb_drop7
I0209 01:52:52.073657 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.073660 14948 net.cpp:156] Memory required for data: 7385776896
I0209 01:52:52.073673 14948 layer_factory.hpp:77] Creating layer conv1
I0209 01:52:52.073684 14948 net.cpp:91] Creating Layer conv1
I0209 01:52:52.073698 14948 net.cpp:425] conv1 <- depth
I0209 01:52:52.073714 14948 net.cpp:399] conv1 -> conv1
I0209 01:52:52.073886 14948 net.cpp:141] Setting up conv1
I0209 01:52:52.073894 14948 net.cpp:148] Top shape: 64 128 112 112 (102760448)
I0209 01:52:52.073897 14948 net.cpp:156] Memory required for data: 7796818688
I0209 01:52:52.073904 14948 layer_factory.hpp:77] Creating layer relu1
I0209 01:52:52.073909 14948 net.cpp:91] Creating Layer relu1
I0209 01:52:52.073925 14948 net.cpp:425] relu1 <- conv1
I0209 01:52:52.073930 14948 net.cpp:386] relu1 -> conv1 (in-place)
I0209 01:52:52.073945 14948 net.cpp:141] Setting up relu1
I0209 01:52:52.073949 14948 net.cpp:148] Top shape: 64 128 112 112 (102760448)
I0209 01:52:52.073962 14948 net.cpp:156] Memory required for data: 8207860480
I0209 01:52:52.073966 14948 layer_factory.hpp:77] Creating layer depth_pool1
I0209 01:52:52.073973 14948 net.cpp:91] Creating Layer depth_pool1
I0209 01:52:52.073985 14948 net.cpp:425] depth_pool1 <- conv1
I0209 01:52:52.073990 14948 net.cpp:399] depth_pool1 -> depth_pool1
I0209 01:52:52.074048 14948 net.cpp:141] Setting up depth_pool1
I0209 01:52:52.074054 14948 net.cpp:148] Top shape: 64 128 56 56 (25690112)
I0209 01:52:52.074069 14948 net.cpp:156] Memory required for data: 8310620928
I0209 01:52:52.074072 14948 layer_factory.hpp:77] Creating layer norm1
I0209 01:52:52.074079 14948 net.cpp:91] Creating Layer norm1
I0209 01:52:52.074092 14948 net.cpp:425] norm1 <- depth_pool1
I0209 01:52:52.074108 14948 net.cpp:399] norm1 -> norm1
I0209 01:52:52.074141 14948 net.cpp:141] Setting up norm1
I0209 01:52:52.074146 14948 net.cpp:148] Top shape: 64 128 56 56 (25690112)
I0209 01:52:52.074160 14948 net.cpp:156] Memory required for data: 8413381376
I0209 01:52:52.074163 14948 layer_factory.hpp:77] Creating layer conv2
I0209 01:52:52.074173 14948 net.cpp:91] Creating Layer conv2
I0209 01:52:52.074177 14948 net.cpp:425] conv2 <- norm1
I0209 01:52:52.074193 14948 net.cpp:399] conv2 -> conv2
I0209 01:52:52.078254 14948 net.cpp:141] Setting up conv2
I0209 01:52:52.078266 14948 net.cpp:148] Top shape: 64 256 56 56 (51380224)
I0209 01:52:52.078269 14948 net.cpp:156] Memory required for data: 8618902272
I0209 01:52:52.078281 14948 layer_factory.hpp:77] Creating layer relu2
I0209 01:52:52.078299 14948 net.cpp:91] Creating Layer relu2
I0209 01:52:52.078303 14948 net.cpp:425] relu2 <- conv2
I0209 01:52:52.078318 14948 net.cpp:386] relu2 -> conv2 (in-place)
I0209 01:52:52.078333 14948 net.cpp:141] Setting up relu2
I0209 01:52:52.078339 14948 net.cpp:148] Top shape: 64 256 56 56 (51380224)
I0209 01:52:52.078352 14948 net.cpp:156] Memory required for data: 8824423168
I0209 01:52:52.078356 14948 layer_factory.hpp:77] Creating layer depth_pool2
I0209 01:52:52.078372 14948 net.cpp:91] Creating Layer depth_pool2
I0209 01:52:52.078377 14948 net.cpp:425] depth_pool2 <- conv2
I0209 01:52:52.078393 14948 net.cpp:399] depth_pool2 -> depth_pool2
I0209 01:52:52.078436 14948 net.cpp:141] Setting up depth_pool2
I0209 01:52:52.078452 14948 net.cpp:148] Top shape: 64 256 28 28 (12845056)
I0209 01:52:52.078456 14948 net.cpp:156] Memory required for data: 8875803392
I0209 01:52:52.078460 14948 layer_factory.hpp:77] Creating layer norm2
I0209 01:52:52.078476 14948 net.cpp:91] Creating Layer norm2
I0209 01:52:52.078480 14948 net.cpp:425] norm2 <- depth_pool2
I0209 01:52:52.078485 14948 net.cpp:399] norm2 -> norm2
I0209 01:52:52.078505 14948 net.cpp:141] Setting up norm2
I0209 01:52:52.078511 14948 net.cpp:148] Top shape: 64 256 28 28 (12845056)
I0209 01:52:52.078516 14948 net.cpp:156] Memory required for data: 8927183616
I0209 01:52:52.078519 14948 layer_factory.hpp:77] Creating layer conv3
I0209 01:52:52.078527 14948 net.cpp:91] Creating Layer conv3
I0209 01:52:52.078531 14948 net.cpp:425] conv3 <- norm2
I0209 01:52:52.078537 14948 net.cpp:399] conv3 -> conv3
I0209 01:52:52.081066 14948 net.cpp:141] Setting up conv3
I0209 01:52:52.081080 14948 net.cpp:148] Top shape: 64 384 28 28 (19267584)
I0209 01:52:52.081084 14948 net.cpp:156] Memory required for data: 9004253952
I0209 01:52:52.081090 14948 layer_factory.hpp:77] Creating layer relu3
I0209 01:52:52.081095 14948 net.cpp:91] Creating Layer relu3
I0209 01:52:52.081100 14948 net.cpp:425] relu3 <- conv3
I0209 01:52:52.081106 14948 net.cpp:386] relu3 -> conv3 (in-place)
I0209 01:52:52.081112 14948 net.cpp:141] Setting up relu3
I0209 01:52:52.081117 14948 net.cpp:148] Top shape: 64 384 28 28 (19267584)
I0209 01:52:52.081121 14948 net.cpp:156] Memory required for data: 9081324288
I0209 01:52:52.081126 14948 layer_factory.hpp:77] Creating layer depth_pool3
I0209 01:52:52.081131 14948 net.cpp:91] Creating Layer depth_pool3
I0209 01:52:52.081136 14948 net.cpp:425] depth_pool3 <- conv3
I0209 01:52:52.081141 14948 net.cpp:399] depth_pool3 -> depth_pool3
I0209 01:52:52.081181 14948 net.cpp:141] Setting up depth_pool3
I0209 01:52:52.081187 14948 net.cpp:148] Top shape: 64 384 14 14 (4816896)
I0209 01:52:52.081190 14948 net.cpp:156] Memory required for data: 9100591872
I0209 01:52:52.081194 14948 layer_factory.hpp:77] Creating layer conv4
I0209 01:52:52.081203 14948 net.cpp:91] Creating Layer conv4
I0209 01:52:52.081208 14948 net.cpp:425] conv4 <- depth_pool3
I0209 01:52:52.081223 14948 net.cpp:399] conv4 -> conv4
I0209 01:52:52.090328 14948 net.cpp:141] Setting up conv4
I0209 01:52:52.090353 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:52.090358 14948 net.cpp:156] Memory required for data: 9126281984
I0209 01:52:52.090366 14948 layer_factory.hpp:77] Creating layer relu4
I0209 01:52:52.090389 14948 net.cpp:91] Creating Layer relu4
I0209 01:52:52.090394 14948 net.cpp:425] relu4 <- conv4
I0209 01:52:52.090410 14948 net.cpp:386] relu4 -> conv4 (in-place)
I0209 01:52:52.090427 14948 net.cpp:141] Setting up relu4
I0209 01:52:52.090432 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:52.090445 14948 net.cpp:156] Memory required for data: 9151972096
I0209 01:52:52.090450 14948 layer_factory.hpp:77] Creating layer conv5
I0209 01:52:52.090483 14948 net.cpp:91] Creating Layer conv5
I0209 01:52:52.090487 14948 net.cpp:425] conv5 <- conv4
I0209 01:52:52.090507 14948 net.cpp:399] conv5 -> conv5
I0209 01:52:52.102098 14948 net.cpp:141] Setting up conv5
I0209 01:52:52.102136 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:52.102141 14948 net.cpp:156] Memory required for data: 9177662208
I0209 01:52:52.102166 14948 layer_factory.hpp:77] Creating layer relu5
I0209 01:52:52.102185 14948 net.cpp:91] Creating Layer relu5
I0209 01:52:52.102191 14948 net.cpp:425] relu5 <- conv5
I0209 01:52:52.102207 14948 net.cpp:386] relu5 -> conv5 (in-place)
I0209 01:52:52.102217 14948 net.cpp:141] Setting up relu5
I0209 01:52:52.102222 14948 net.cpp:148] Top shape: 64 512 14 14 (6422528)
I0209 01:52:52.102227 14948 net.cpp:156] Memory required for data: 9203352320
I0209 01:52:52.102232 14948 layer_factory.hpp:77] Creating layer depth_pool5
I0209 01:52:52.102241 14948 net.cpp:91] Creating Layer depth_pool5
I0209 01:52:52.102246 14948 net.cpp:425] depth_pool5 <- conv5
I0209 01:52:52.102252 14948 net.cpp:399] depth_pool5 -> depth_pool5
I0209 01:52:52.102304 14948 net.cpp:141] Setting up depth_pool5
I0209 01:52:52.102310 14948 net.cpp:148] Top shape: 64 512 7 7 (1605632)
I0209 01:52:52.102324 14948 net.cpp:156] Memory required for data: 9209774848
I0209 01:52:52.102327 14948 layer_factory.hpp:77] Creating layer depth_fc6
I0209 01:52:52.102346 14948 net.cpp:91] Creating Layer depth_fc6
I0209 01:52:52.102355 14948 net.cpp:425] depth_fc6 <- depth_pool5
I0209 01:52:52.102360 14948 net.cpp:399] depth_fc6 -> depth_fc6
I0209 01:52:52.582017 14948 net.cpp:141] Setting up depth_fc6
I0209 01:52:52.582049 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.582056 14948 net.cpp:156] Memory required for data: 9210823424
I0209 01:52:52.582065 14948 layer_factory.hpp:77] Creating layer depth_relu6
I0209 01:52:52.582089 14948 net.cpp:91] Creating Layer depth_relu6
I0209 01:52:52.582106 14948 net.cpp:425] depth_relu6 <- depth_fc6
I0209 01:52:52.582123 14948 net.cpp:386] depth_relu6 -> depth_fc6 (in-place)
I0209 01:52:52.582144 14948 net.cpp:141] Setting up depth_relu6
I0209 01:52:52.582150 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.582157 14948 net.cpp:156] Memory required for data: 9211872000
I0209 01:52:52.582162 14948 layer_factory.hpp:77] Creating layer depth_drop6
I0209 01:52:52.582171 14948 net.cpp:91] Creating Layer depth_drop6
I0209 01:52:52.582187 14948 net.cpp:425] depth_drop6 <- depth_fc6
I0209 01:52:52.582192 14948 net.cpp:386] depth_drop6 -> depth_fc6 (in-place)
I0209 01:52:52.582242 14948 net.cpp:141] Setting up depth_drop6
I0209 01:52:52.582247 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.582260 14948 net.cpp:156] Memory required for data: 9212920576
I0209 01:52:52.582264 14948 layer_factory.hpp:77] Creating layer depth_fc7
I0209 01:52:52.582283 14948 net.cpp:91] Creating Layer depth_fc7
I0209 01:52:52.582285 14948 net.cpp:425] depth_fc7 <- depth_fc6
I0209 01:52:52.582300 14948 net.cpp:399] depth_fc7 -> depth_fc7
I0209 01:52:52.661034 14948 net.cpp:141] Setting up depth_fc7
I0209 01:52:52.661064 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.661070 14948 net.cpp:156] Memory required for data: 9213969152
I0209 01:52:52.661080 14948 layer_factory.hpp:77] Creating layer depth_relu7
I0209 01:52:52.661101 14948 net.cpp:91] Creating Layer depth_relu7
I0209 01:52:52.661118 14948 net.cpp:425] depth_relu7 <- depth_fc7
I0209 01:52:52.661124 14948 net.cpp:386] depth_relu7 -> depth_fc7 (in-place)
I0209 01:52:52.661156 14948 net.cpp:141] Setting up depth_relu7
I0209 01:52:52.661164 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.661176 14948 net.cpp:156] Memory required for data: 9215017728
I0209 01:52:52.661180 14948 layer_factory.hpp:77] Creating layer depth_drop7
I0209 01:52:52.661197 14948 net.cpp:91] Creating Layer depth_drop7
I0209 01:52:52.661212 14948 net.cpp:425] depth_drop7 <- depth_fc7
I0209 01:52:52.661217 14948 net.cpp:386] depth_drop7 -> depth_fc7 (in-place)
I0209 01:52:52.661269 14948 net.cpp:141] Setting up depth_drop7
I0209 01:52:52.661275 14948 net.cpp:148] Top shape: 64 4096 (262144)
I0209 01:52:52.661289 14948 net.cpp:156] Memory required for data: 9216066304
I0209 01:52:52.661294 14948 layer_factory.hpp:77] Creating layer concat
I0209 01:52:52.661324 14948 net.cpp:91] Creating Layer concat
I0209 01:52:52.661329 14948 net.cpp:425] concat <- rgb_fc7
I0209 01:52:52.661342 14948 net.cpp:425] concat <- depth_fc7
I0209 01:52:52.661350 14948 net.cpp:399] concat -> concat
I0209 01:52:52.661379 14948 net.cpp:141] Setting up concat
I0209 01:52:52.661384 14948 net.cpp:148] Top shape: 64 8192 (524288)
I0209 01:52:52.661389 14948 net.cpp:156] Memory required for data: 9218163456
I0209 01:52:52.661402 14948 layer_factory.hpp:77] Creating layer fuse_fc1
I0209 01:52:52.661411 14948 net.cpp:91] Creating Layer fuse_fc1
I0209 01:52:52.661414 14948 net.cpp:425] fuse_fc1 <- concat
I0209 01:52:52.661420 14948 net.cpp:399] fuse_fc1 -> fuse_fc1
I0209 01:52:52.701534 14948 net.cpp:141] Setting up fuse_fc1
I0209 01:52:52.701588 14948 net.cpp:148] Top shape: 64 1024 (65536)
I0209 01:52:52.701594 14948 net.cpp:156] Memory required for data: 9218425600
I0209 01:52:52.701604 14948 layer_factory.hpp:77] Creating layer fuse_relu1
I0209 01:52:52.701614 14948 net.cpp:91] Creating Layer fuse_relu1
I0209 01:52:52.701622 14948 net.cpp:425] fuse_relu1 <- fuse_fc1
I0209 01:52:52.701644 14948 net.cpp:386] fuse_relu1 -> fuse_fc1 (in-place)
I0209 01:52:52.701661 14948 net.cpp:141] Setting up fuse_relu1
I0209 01:52:52.701668 14948 net.cpp:148] Top shape: 64 1024 (65536)
I0209 01:52:52.701673 14948 net.cpp:156] Memory required for data: 9218687744
I0209 01:52:52.701678 14948 layer_factory.hpp:77] Creating layer fuse_drop1
I0209 01:52:52.701712 14948 net.cpp:91] Creating Layer fuse_drop1
I0209 01:52:52.701717 14948 net.cpp:425] fuse_drop1 <- fuse_fc1
I0209 01:52:52.701722 14948 net.cpp:386] fuse_drop1 -> fuse_fc1 (in-place)
I0209 01:52:52.701743 14948 net.cpp:141] Setting up fuse_drop1
I0209 01:52:52.701750 14948 net.cpp:148] Top shape: 64 1024 (65536)
I0209 01:52:52.701752 14948 net.cpp:156] Memory required for data: 9218949888
I0209 01:52:52.701756 14948 layer_factory.hpp:77] Creating layer fuse_fc2
I0209 01:52:52.701763 14948 net.cpp:91] Creating Layer fuse_fc2
I0209 01:52:52.701768 14948 net.cpp:425] fuse_fc2 <- fuse_fc1
I0209 01:52:52.701774 14948 net.cpp:399] fuse_fc2 -> fuse_fc2
I0209 01:52:52.706965 14948 net.cpp:141] Setting up fuse_fc2
I0209 01:52:52.706979 14948 net.cpp:148] Top shape: 64 1024 (65536)
I0209 01:52:52.706982 14948 net.cpp:156] Memory required for data: 9219212032
I0209 01:52:52.706990 14948 layer_factory.hpp:77] Creating layer fuse_relu2
I0209 01:52:52.707007 14948 net.cpp:91] Creating Layer fuse_relu2
I0209 01:52:52.707012 14948 net.cpp:425] fuse_relu2 <- fuse_fc2
I0209 01:52:52.707028 14948 net.cpp:386] fuse_relu2 -> fuse_fc2 (in-place)
I0209 01:52:52.707034 14948 net.cpp:141] Setting up fuse_relu2
I0209 01:52:52.707048 14948 net.cpp:148] Top shape: 64 1024 (65536)
I0209 01:52:52.707051 14948 net.cpp:156] Memory required for data: 9219474176
I0209 01:52:52.707068 14948 layer_factory.hpp:77] Creating layer fuse_drop2
I0209 01:52:52.707074 14948 net.cpp:91] Creating Layer fuse_drop2
I0209 01:52:52.707079 14948 net.cpp:425] fuse_drop2 <- fuse_fc2
I0209 01:52:52.707084 14948 net.cpp:386] fuse_drop2 -> fuse_fc2 (in-place)
I0209 01:52:52.707103 14948 net.cpp:141] Setting up fuse_drop2
I0209 01:52:52.707121 14948 net.cpp:148] Top shape: 64 1024 (65536)
I0209 01:52:52.707125 14948 net.cpp:156] Memory required for data: 9219736320
I0209 01:52:52.707137 14948 layer_factory.hpp:77] Creating layer rgbd_fc8
I0209 01:52:52.707154 14948 net.cpp:91] Creating Layer rgbd_fc8
I0209 01:52:52.707157 14948 net.cpp:425] rgbd_fc8 <- fuse_fc2
I0209 01:52:52.707164 14948 net.cpp:399] rgbd_fc8 -> rgbd_fc8
I0209 01:52:52.707309 14948 net.cpp:141] Setting up rgbd_fc8
I0209 01:52:52.707315 14948 net.cpp:148] Top shape: 64 11 (704)
I0209 01:52:52.707319 14948 net.cpp:156] Memory required for data: 9219739136
I0209 01:52:52.707324 14948 layer_factory.hpp:77] Creating layer rgbd_fc8_rgbd_fc8_0_split
I0209 01:52:52.707329 14948 net.cpp:91] Creating Layer rgbd_fc8_rgbd_fc8_0_split
I0209 01:52:52.707334 14948 net.cpp:425] rgbd_fc8_rgbd_fc8_0_split <- rgbd_fc8
I0209 01:52:52.707350 14948 net.cpp:399] rgbd_fc8_rgbd_fc8_0_split -> rgbd_fc8_rgbd_fc8_0_split_0
I0209 01:52:52.707356 14948 net.cpp:399] rgbd_fc8_rgbd_fc8_0_split -> rgbd_fc8_rgbd_fc8_0_split_1
I0209 01:52:52.707408 14948 net.cpp:141] Setting up rgbd_fc8_rgbd_fc8_0_split
I0209 01:52:52.707414 14948 net.cpp:148] Top shape: 64 11 (704)
I0209 01:52:52.707418 14948 net.cpp:148] Top shape: 64 11 (704)
I0209 01:52:52.707423 14948 net.cpp:156] Memory required for data: 9219744768
I0209 01:52:52.707440 14948 layer_factory.hpp:77] Creating layer rgbd_accuracy
I0209 01:52:52.707464 14948 net.cpp:91] Creating Layer rgbd_accuracy
I0209 01:52:52.707468 14948 net.cpp:425] rgbd_accuracy <- rgbd_fc8_rgbd_fc8_0_split_0
I0209 01:52:52.707484 14948 net.cpp:425] rgbd_accuracy <- label_data_2_split_0
I0209 01:52:52.707487 14948 net.cpp:399] rgbd_accuracy -> rgbd_accuracy
I0209 01:52:52.707504 14948 net.cpp:141] Setting up rgbd_accuracy
I0209 01:52:52.707509 14948 net.cpp:148] Top shape: (1)
I0209 01:52:52.707512 14948 net.cpp:156] Memory required for data: 9219744772
I0209 01:52:52.707516 14948 layer_factory.hpp:77] Creating layer rgbd_loss
I0209 01:52:52.707535 14948 net.cpp:91] Creating Layer rgbd_loss
I0209 01:52:52.707540 14948 net.cpp:425] rgbd_loss <- rgbd_fc8_rgbd_fc8_0_split_1
I0209 01:52:52.707552 14948 net.cpp:425] rgbd_loss <- label_data_2_split_1
I0209 01:52:52.707557 14948 net.cpp:399] rgbd_loss -> rgbd_loss
I0209 01:52:52.707573 14948 layer_factory.hpp:77] Creating layer rgbd_loss
I0209 01:52:52.707624 14948 net.cpp:141] Setting up rgbd_loss
I0209 01:52:52.707631 14948 net.cpp:148] Top shape: (1)
I0209 01:52:52.707634 14948 net.cpp:151]     with loss weight 1
I0209 01:52:52.707644 14948 net.cpp:156] Memory required for data: 9219744776
I0209 01:52:52.707659 14948 net.cpp:217] rgbd_loss needs backward computation.
I0209 01:52:52.707664 14948 net.cpp:219] rgbd_accuracy does not need backward computation.
I0209 01:52:52.707677 14948 net.cpp:217] rgbd_fc8_rgbd_fc8_0_split needs backward computation.
I0209 01:52:52.707681 14948 net.cpp:217] rgbd_fc8 needs backward computation.
I0209 01:52:52.707695 14948 net.cpp:217] fuse_drop2 needs backward computation.
I0209 01:52:52.707698 14948 net.cpp:217] fuse_relu2 needs backward computation.
I0209 01:52:52.707702 14948 net.cpp:217] fuse_fc2 needs backward computation.
I0209 01:52:52.707715 14948 net.cpp:217] fuse_drop1 needs backward computation.
I0209 01:52:52.707720 14948 net.cpp:217] fuse_relu1 needs backward computation.
I0209 01:52:52.707722 14948 net.cpp:217] fuse_fc1 needs backward computation.
I0209 01:52:52.707726 14948 net.cpp:217] concat needs backward computation.
I0209 01:52:52.707731 14948 net.cpp:217] depth_drop7 needs backward computation.
I0209 01:52:52.707736 14948 net.cpp:217] depth_relu7 needs backward computation.
I0209 01:52:52.707739 14948 net.cpp:217] depth_fc7 needs backward computation.
I0209 01:52:52.707743 14948 net.cpp:217] depth_drop6 needs backward computation.
I0209 01:52:52.707747 14948 net.cpp:217] depth_relu6 needs backward computation.
I0209 01:52:52.707751 14948 net.cpp:217] depth_fc6 needs backward computation.
I0209 01:52:52.707756 14948 net.cpp:219] depth_pool5 does not need backward computation.
I0209 01:52:52.707761 14948 net.cpp:219] relu5 does not need backward computation.
I0209 01:52:52.707765 14948 net.cpp:219] conv5 does not need backward computation.
I0209 01:52:52.707770 14948 net.cpp:219] relu4 does not need backward computation.
I0209 01:52:52.707773 14948 net.cpp:219] conv4 does not need backward computation.
I0209 01:52:52.707777 14948 net.cpp:219] depth_pool3 does not need backward computation.
I0209 01:52:52.707782 14948 net.cpp:219] relu3 does not need backward computation.
I0209 01:52:52.707787 14948 net.cpp:219] conv3 does not need backward computation.
I0209 01:52:52.707792 14948 net.cpp:219] norm2 does not need backward computation.
I0209 01:52:52.707797 14948 net.cpp:219] depth_pool2 does not need backward computation.
I0209 01:52:52.707800 14948 net.cpp:219] relu2 does not need backward computation.
I0209 01:52:52.707805 14948 net.cpp:219] conv2 does not need backward computation.
I0209 01:52:52.707809 14948 net.cpp:219] norm1 does not need backward computation.
I0209 01:52:52.707814 14948 net.cpp:219] depth_pool1 does not need backward computation.
I0209 01:52:52.707819 14948 net.cpp:219] relu1 does not need backward computation.
I0209 01:52:52.707823 14948 net.cpp:219] conv1 does not need backward computation.
I0209 01:52:52.707828 14948 net.cpp:217] rgb_drop7 needs backward computation.
I0209 01:52:52.707833 14948 net.cpp:217] rgb_relu7 needs backward computation.
I0209 01:52:52.707836 14948 net.cpp:217] rgb_fc7 needs backward computation.
I0209 01:52:52.707840 14948 net.cpp:217] rgb_drop6 needs backward computation.
I0209 01:52:52.707845 14948 net.cpp:217] rgb_relu6 needs backward computation.
I0209 01:52:52.707849 14948 net.cpp:217] rgb_fc6 needs backward computation.
I0209 01:52:52.707854 14948 net.cpp:219] rgb_pool5 does not need backward computation.
I0209 01:52:52.707859 14948 net.cpp:219] relu5_3 does not need backward computation.
I0209 01:52:52.707864 14948 net.cpp:219] conv5_3 does not need backward computation.
I0209 01:52:52.707868 14948 net.cpp:219] relu5_2 does not need backward computation.
I0209 01:52:52.707872 14948 net.cpp:219] conv5_2 does not need backward computation.
I0209 01:52:52.707876 14948 net.cpp:219] relu5_1 does not need backward computation.
I0209 01:52:52.707880 14948 net.cpp:219] conv5_1 does not need backward computation.
I0209 01:52:52.707885 14948 net.cpp:219] rgb_pool4 does not need backward computation.
I0209 01:52:52.707890 14948 net.cpp:219] relu4_3 does not need backward computation.
I0209 01:52:52.707895 14948 net.cpp:219] conv4_3 does not need backward computation.
I0209 01:52:52.707898 14948 net.cpp:219] relu4_2 does not need backward computation.
I0209 01:52:52.707903 14948 net.cpp:219] conv4_2 does not need backward computation.
I0209 01:52:52.707908 14948 net.cpp:219] relu4_1 does not need backward computation.
I0209 01:52:52.707912 14948 net.cpp:219] conv4_1 does not need backward computation.
I0209 01:52:52.707917 14948 net.cpp:219] rgb_pool3 does not need backward computation.
I0209 01:52:52.707922 14948 net.cpp:219] relu3_3 does not need backward computation.
I0209 01:52:52.707926 14948 net.cpp:219] conv3_3 does not need backward computation.
I0209 01:52:52.707931 14948 net.cpp:219] relu3_2 does not need backward computation.
I0209 01:52:52.707936 14948 net.cpp:219] conv3_2 does not need backward computation.
I0209 01:52:52.707939 14948 net.cpp:219] relu3_1 does not need backward computation.
I0209 01:52:52.707944 14948 net.cpp:219] conv3_1 does not need backward computation.
I0209 01:52:52.707958 14948 net.cpp:219] rgb_pool2 does not need backward computation.
I0209 01:52:52.707963 14948 net.cpp:219] relu2_2 does not need backward computation.
I0209 01:52:52.707979 14948 net.cpp:219] conv2_2 does not need backward computation.
I0209 01:52:52.707983 14948 net.cpp:219] relu2_1 does not need backward computation.
I0209 01:52:52.707996 14948 net.cpp:219] conv2_1 does not need backward computation.
I0209 01:52:52.708001 14948 net.cpp:219] rgb_pool1 does not need backward computation.
I0209 01:52:52.708006 14948 net.cpp:219] relu1_2 does not need backward computation.
I0209 01:52:52.708010 14948 net.cpp:219] conv1_2 does not need backward computation.
I0209 01:52:52.708024 14948 net.cpp:219] relu1_1 does not need backward computation.
I0209 01:52:52.708029 14948 net.cpp:219] conv1_1 does not need backward computation.
I0209 01:52:52.708034 14948 net.cpp:219] label_data_2_split does not need backward computation.
I0209 01:52:52.708039 14948 net.cpp:219] data does not need backward computation.
I0209 01:52:52.708042 14948 net.cpp:261] This network produces output rgbd_accuracy
I0209 01:52:52.708047 14948 net.cpp:261] This network produces output rgbd_loss
I0209 01:52:52.708072 14948 net.cpp:274] Network initialization done.
I0209 01:52:52.708933 14948 solver.cpp:181] Creating test net (#0) specified by test_net file: test.prototxt
I0209 01:52:52.709208 14948 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Python"
  top: "rgb"
  top: "depth"
  top: "label"
  python_param {
    module: "data_layers.rgbd_data_layer"
    layer: "RGBDDataLayer"
    param_str: "{\'img_size\': (224, 224), \'split\': \'test\', \'dataset_dir\': \'/home/kevin/dataset/rgbd\', \'randomize\': False, \'mean\': (104.00698793, 116.66876762, 122.67891434), \'seed\': 1337, \'batch_size\': 1, \'crop_size\': (224, 224, 224, 224)}"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "rgb"
  top: "conv1_1"
  param {
    name: "conv1_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    name: "conv1_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "rgb_pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "rgb_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "rgb_pool1"
  top: "conv2_1"
  param {
    name: "conv2_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    name: "conv2_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "rgb_pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "rgb_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "rgb_pool2"
  top: "conv3_1"
  param {
    name: "conv3_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    name: "conv3_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    name: "conv3_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "rgb_pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "rgb_pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "rgb_pool3"
  top: "conv4_1"
  param {
    name: "conv4_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    name: "conv4_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    name: "conv4_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "rgb_pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "rgb_pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "rgb_pool4"
  top: "conv5_1"
  param {
    name: "conv5_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    name: "conv5_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    name: "conv5_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rgb_pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "rgb_pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "rgb_fc6"
  type: "InnerProduct"
  bottom: "rgb_pool5"
  top: "rgb_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_relu6"
  type: "ReLU"
  bottom: "rgb_fc6"
  top: "rgb_fc6"
}
layer {
  name: "rgb_drop6"
  type: "Dropout"
  bottom: "rgb_fc6"
  top: "rgb_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "rgb_fc7"
  type: "InnerProduct"
  bottom: "rgb_fc6"
  top: "rgb_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_relu7"
  type: "ReLU"
  bottom: "rgb_fc7"
  top: "rgb_fc7"
}
layer {
  name: "rgb_drop7"
  type: "Dropout"
  bottom: "rgb_fc7"
  top: "rgb_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "depth"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "depth_pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "depth_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "depth_pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "depth_pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "depth_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "depth_pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "depth_pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "depth_pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "depth_pool3"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "depth_pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "depth_pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "depth_fc6"
  type: "InnerProduct"
  bottom: "depth_pool5"
  top: "depth_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "depth_relu6"
  type: "ReLU"
  bottom: "depth_fc6"
  top: "depth_fc6"
}
layer {
  name: "depth_drop6"
  type: "Dropout"
  bottom: "depth_fc6"
  top: "depth_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "depth_fc7"
  type: "InnerProduct"
  bottom: "depth_fc6"
  top: "depth_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "depth_relu7"
  type: "ReLU"
  bottom: "depth_fc7"
  top: "depth_fc7"
}
layer {
  name: "depth_drop7"
  type: "Dropout"
  bottom: "depth_fc7"
  top: "depth_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "rgb_fc7"
  bottom: "depth_fc7"
  top: "concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fuse_fc1"
  type: "InnerProduct"
  bottom: "concat"
  top: "fuse_fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fuse_relu1"
  type: "ReLU"
  bottom: "fuse_fc1"
  top: "fuse_fc1"
}
layer {
  name: "fuse_drop1"
  type: "Dropout"
  bottom: "fuse_fc1"
  top: "fuse_fc1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fuse_fc2"
  type: "InnerProduct"
  bottom: "fuse_fc1"
  top: "fuse_fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fuse_relu2"
  type: "ReLU"
  bottom: "fuse_fc2"
  top: "fuse_fc2"
}
layer {
  name: "fuse_drop2"
  type: "Dropout"
  bottom: "fuse_fc2"
  top: "fuse_fc2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "rgbd_fc8"
  type: "InnerProduct"
  bottom: "fuse_fc2"
  top: "rgbd_fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgbd_accuracy"
  type: "Accuracy"
  bottom: "rgbd_fc8"
  bottom: "label"
  top: "rgbd_accuracy"
}
layer {
  name: "rgbd_loss"
  type: "SoftmaxWithLoss"
  bottom: "rgbd_fc8"
  bottom: "label"
  top: "rgbd_loss"
}
I0209 01:52:52.712394 14948 layer_factory.hpp:77] Creating layer data
I0209 01:52:52.712487 14948 net.cpp:91] Creating Layer data
I0209 01:52:52.712498 14948 net.cpp:399] data -> rgb
I0209 01:52:52.712510 14948 net.cpp:399] data -> depth
I0209 01:52:52.712518 14948 net.cpp:399] data -> label
{'img_size': (224, 224), 'split': 'test', 'dataset_dir': '/home/kevin/dataset/rgbd', 'crop_size': (224, 224, 224, 224), 'randomize': False, 'seed': 1337, 'batch_size': 1, 'mean': (104.00698793, 116.66876762, 122.67891434)}
I0209 01:52:52.749716 14948 net.cpp:141] Setting up data
I0209 01:52:52.749748 14948 net.cpp:148] Top shape: 1 3 224 224 (150528)
I0209 01:52:52.749758 14948 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0209 01:52:52.749778 14948 net.cpp:148] Top shape: 1 1 (1)
I0209 01:52:52.749799 14948 net.cpp:156] Memory required for data: 802820
I0209 01:52:52.749825 14948 layer_factory.hpp:77] Creating layer label_data_2_split
I0209 01:52:52.749871 14948 net.cpp:91] Creating Layer label_data_2_split
I0209 01:52:52.749893 14948 net.cpp:425] label_data_2_split <- label
I0209 01:52:52.749918 14948 net.cpp:399] label_data_2_split -> label_data_2_split_0
I0209 01:52:52.749941 14948 net.cpp:399] label_data_2_split -> label_data_2_split_1
I0209 01:52:52.750032 14948 net.cpp:141] Setting up label_data_2_split
I0209 01:52:52.750049 14948 net.cpp:148] Top shape: 1 1 (1)
I0209 01:52:52.750061 14948 net.cpp:148] Top shape: 1 1 (1)
I0209 01:52:52.750072 14948 net.cpp:156] Memory required for data: 802828
I0209 01:52:52.750083 14948 layer_factory.hpp:77] Creating layer conv1_1
I0209 01:52:52.750109 14948 net.cpp:91] Creating Layer conv1_1
I0209 01:52:52.750133 14948 net.cpp:425] conv1_1 <- rgb
I0209 01:52:52.750146 14948 net.cpp:399] conv1_1 -> conv1_1
I0209 01:52:52.750598 14948 net.cpp:141] Setting up conv1_1
I0209 01:52:52.750627 14948 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0209 01:52:52.750639 14948 net.cpp:156] Memory required for data: 13647884
I0209 01:52:52.750677 14948 layer_factory.hpp:77] Creating layer relu1_1
I0209 01:52:52.750702 14948 net.cpp:91] Creating Layer relu1_1
I0209 01:52:52.750722 14948 net.cpp:425] relu1_1 <- conv1_1
I0209 01:52:52.750751 14948 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0209 01:52:52.750777 14948 net.cpp:141] Setting up relu1_1
I0209 01:52:52.750799 14948 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0209 01:52:52.750818 14948 net.cpp:156] Memory required for data: 26492940
I0209 01:52:52.750828 14948 layer_factory.hpp:77] Creating layer conv1_2
I0209 01:52:52.750847 14948 net.cpp:91] Creating Layer conv1_2
I0209 01:52:52.750867 14948 net.cpp:425] conv1_2 <- conv1_1
I0209 01:52:52.750890 14948 net.cpp:399] conv1_2 -> conv1_2
I0209 01:52:52.751989 14948 net.cpp:141] Setting up conv1_2
I0209 01:52:52.752018 14948 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0209 01:52:52.752023 14948 net.cpp:156] Memory required for data: 39337996
I0209 01:52:52.752034 14948 layer_factory.hpp:77] Creating layer relu1_2
I0209 01:52:52.752043 14948 net.cpp:91] Creating Layer relu1_2
I0209 01:52:52.752049 14948 net.cpp:425] relu1_2 <- conv1_2
I0209 01:52:52.752058 14948 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0209 01:52:52.752065 14948 net.cpp:141] Setting up relu1_2
I0209 01:52:52.752071 14948 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0209 01:52:52.752075 14948 net.cpp:156] Memory required for data: 52183052
I0209 01:52:52.752079 14948 layer_factory.hpp:77] Creating layer rgb_pool1
I0209 01:52:52.752089 14948 net.cpp:91] Creating Layer rgb_pool1
I0209 01:52:52.752094 14948 net.cpp:425] rgb_pool1 <- conv1_2
I0209 01:52:52.752099 14948 net.cpp:399] rgb_pool1 -> rgb_pool1
I0209 01:52:52.752140 14948 net.cpp:141] Setting up rgb_pool1
I0209 01:52:52.752147 14948 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0209 01:52:52.752152 14948 net.cpp:156] Memory required for data: 55394316
I0209 01:52:52.752157 14948 layer_factory.hpp:77] Creating layer conv2_1
I0209 01:52:52.752171 14948 net.cpp:91] Creating Layer conv2_1
I0209 01:52:52.752177 14948 net.cpp:425] conv2_1 <- rgb_pool1
I0209 01:52:52.752182 14948 net.cpp:399] conv2_1 -> conv2_1
I0209 01:52:52.753108 14948 net.cpp:141] Setting up conv2_1
I0209 01:52:52.753131 14948 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0209 01:52:52.753139 14948 net.cpp:156] Memory required for data: 61816844
I0209 01:52:52.753151 14948 layer_factory.hpp:77] Creating layer relu2_1
I0209 01:52:52.753163 14948 net.cpp:91] Creating Layer relu2_1
I0209 01:52:52.753170 14948 net.cpp:425] relu2_1 <- conv2_1
I0209 01:52:52.753177 14948 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0209 01:52:52.753185 14948 net.cpp:141] Setting up relu2_1
I0209 01:52:52.753191 14948 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0209 01:52:52.753196 14948 net.cpp:156] Memory required for data: 68239372
I0209 01:52:52.753201 14948 layer_factory.hpp:77] Creating layer conv2_2
I0209 01:52:52.753211 14948 net.cpp:91] Creating Layer conv2_2
I0209 01:52:52.753216 14948 net.cpp:425] conv2_2 <- conv2_1
I0209 01:52:52.753222 14948 net.cpp:399] conv2_2 -> conv2_2
I0209 01:52:52.754098 14948 net.cpp:141] Setting up conv2_2
I0209 01:52:52.754124 14948 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0209 01:52:52.754132 14948 net.cpp:156] Memory required for data: 74661900
I0209 01:52:52.754142 14948 layer_factory.hpp:77] Creating layer relu2_2
I0209 01:52:52.754155 14948 net.cpp:91] Creating Layer relu2_2
I0209 01:52:52.754161 14948 net.cpp:425] relu2_2 <- conv2_2
I0209 01:52:52.754170 14948 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0209 01:52:52.754179 14948 net.cpp:141] Setting up relu2_2
I0209 01:52:52.754186 14948 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0209 01:52:52.754190 14948 net.cpp:156] Memory required for data: 81084428
I0209 01:52:52.754194 14948 layer_factory.hpp:77] Creating layer rgb_pool2
I0209 01:52:52.754204 14948 net.cpp:91] Creating Layer rgb_pool2
I0209 01:52:52.754209 14948 net.cpp:425] rgb_pool2 <- conv2_2
I0209 01:52:52.754215 14948 net.cpp:399] rgb_pool2 -> rgb_pool2
I0209 01:52:52.754252 14948 net.cpp:141] Setting up rgb_pool2
I0209 01:52:52.754261 14948 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0209 01:52:52.754266 14948 net.cpp:156] Memory required for data: 82690060
I0209 01:52:52.754271 14948 layer_factory.hpp:77] Creating layer conv3_1
I0209 01:52:52.754282 14948 net.cpp:91] Creating Layer conv3_1
I0209 01:52:52.754288 14948 net.cpp:425] conv3_1 <- rgb_pool2
I0209 01:52:52.754295 14948 net.cpp:399] conv3_1 -> conv3_1
I0209 01:52:52.756412 14948 net.cpp:141] Setting up conv3_1
I0209 01:52:52.756438 14948 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0209 01:52:52.756446 14948 net.cpp:156] Memory required for data: 85901324
I0209 01:52:52.756463 14948 layer_factory.hpp:77] Creating layer relu3_1
I0209 01:52:52.756474 14948 net.cpp:91] Creating Layer relu3_1
I0209 01:52:52.756481 14948 net.cpp:425] relu3_1 <- conv3_1
I0209 01:52:52.756491 14948 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0209 01:52:52.756501 14948 net.cpp:141] Setting up relu3_1
I0209 01:52:52.756511 14948 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0209 01:52:52.756518 14948 net.cpp:156] Memory required for data: 89112588
I0209 01:52:52.756526 14948 layer_factory.hpp:77] Creating layer conv3_2
I0209 01:52:52.756539 14948 net.cpp:91] Creating Layer conv3_2
I0209 01:52:52.756546 14948 net.cpp:425] conv3_2 <- conv3_1
I0209 01:52:52.756556 14948 net.cpp:399] conv3_2 -> conv3_2
I0209 01:52:52.760329 14948 net.cpp:141] Setting up conv3_2
I0209 01:52:52.760360 14948 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0209 01:52:52.760366 14948 net.cpp:156] Memory required for data: 92323852
I0209 01:52:52.760377 14948 layer_factory.hpp:77] Creating layer relu3_2
I0209 01:52:52.760388 14948 net.cpp:91] Creating Layer relu3_2
I0209 01:52:52.760396 14948 net.cpp:425] relu3_2 <- conv3_2
I0209 01:52:52.760401 14948 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0209 01:52:52.760411 14948 net.cpp:141] Setting up relu3_2
I0209 01:52:52.760419 14948 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0209 01:52:52.760423 14948 net.cpp:156] Memory required for data: 95535116
I0209 01:52:52.760429 14948 layer_factory.hpp:77] Creating layer conv3_3
I0209 01:52:52.760442 14948 net.cpp:91] Creating Layer conv3_3
I0209 01:52:52.760447 14948 net.cpp:425] conv3_3 <- conv3_2
I0209 01:52:52.760453 14948 net.cpp:399] conv3_3 -> conv3_3
I0209 01:52:52.763640 14948 net.cpp:141] Setting up conv3_3
I0209 01:52:52.763654 14948 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0209 01:52:52.763659 14948 net.cpp:156] Memory required for data: 98746380
I0209 01:52:52.763666 14948 layer_factory.hpp:77] Creating layer relu3_3
I0209 01:52:52.763674 14948 net.cpp:91] Creating Layer relu3_3
I0209 01:52:52.763679 14948 net.cpp:425] relu3_3 <- conv3_3
I0209 01:52:52.763684 14948 net.cpp:386] relu3_3 -> conv3_3 (in-place)
I0209 01:52:52.763691 14948 net.cpp:141] Setting up relu3_3
I0209 01:52:52.763696 14948 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0209 01:52:52.763701 14948 net.cpp:156] Memory required for data: 101957644
I0209 01:52:52.763705 14948 layer_factory.hpp:77] Creating layer rgb_pool3
I0209 01:52:52.763722 14948 net.cpp:91] Creating Layer rgb_pool3
I0209 01:52:52.763736 14948 net.cpp:425] rgb_pool3 <- conv3_3
I0209 01:52:52.763741 14948 net.cpp:399] rgb_pool3 -> rgb_pool3
I0209 01:52:52.763777 14948 net.cpp:141] Setting up rgb_pool3
I0209 01:52:52.763782 14948 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0209 01:52:52.763787 14948 net.cpp:156] Memory required for data: 102760460
I0209 01:52:52.763790 14948 layer_factory.hpp:77] Creating layer conv4_1
I0209 01:52:52.763798 14948 net.cpp:91] Creating Layer conv4_1
I0209 01:52:52.763803 14948 net.cpp:425] conv4_1 <- rgb_pool3
I0209 01:52:52.763809 14948 net.cpp:399] conv4_1 -> conv4_1
I0209 01:52:52.769642 14948 net.cpp:141] Setting up conv4_1
I0209 01:52:52.769667 14948 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0209 01:52:52.769671 14948 net.cpp:156] Memory required for data: 104366092
I0209 01:52:52.769677 14948 layer_factory.hpp:77] Creating layer relu4_1
I0209 01:52:52.769685 14948 net.cpp:91] Creating Layer relu4_1
I0209 01:52:52.769701 14948 net.cpp:425] relu4_1 <- conv4_1
I0209 01:52:52.769706 14948 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0209 01:52:52.769722 14948 net.cpp:141] Setting up relu4_1
I0209 01:52:52.769726 14948 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0209 01:52:52.769731 14948 net.cpp:156] Memory required for data: 105971724
I0209 01:52:52.769748 14948 layer_factory.hpp:77] Creating layer conv4_2
I0209 01:52:52.769767 14948 net.cpp:91] Creating Layer conv4_2
I0209 01:52:52.769770 14948 net.cpp:425] conv4_2 <- conv4_1
I0209 01:52:52.769776 14948 net.cpp:399] conv4_2 -> conv4_2
I0209 01:52:52.781054 14948 net.cpp:141] Setting up conv4_2
I0209 01:52:52.781080 14948 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0209 01:52:52.781085 14948 net.cpp:156] Memory required for data: 107577356
I0209 01:52:52.781096 14948 layer_factory.hpp:77] Creating layer relu4_2
I0209 01:52:52.781105 14948 net.cpp:91] Creating Layer relu4_2
I0209 01:52:52.781111 14948 net.cpp:425] relu4_2 <- conv4_2
I0209 01:52:52.781117 14948 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0209 01:52:52.781124 14948 net.cpp:141] Setting up relu4_2
I0209 01:52:52.781129 14948 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0209 01:52:52.781133 14948 net.cpp:156] Memory required for data: 109182988
I0209 01:52:52.781137 14948 layer_factory.hpp:77] Creating layer conv4_3
I0209 01:52:52.781147 14948 net.cpp:91] Creating Layer conv4_3
I0209 01:52:52.781150 14948 net.cpp:425] conv4_3 <- conv4_2
I0209 01:52:52.781157 14948 net.cpp:399] conv4_3 -> conv4_3
I0209 01:52:52.792932 14948 net.cpp:141] Setting up conv4_3
I0209 01:52:52.792986 14948 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0209 01:52:52.792991 14948 net.cpp:156] Memory required for data: 110788620
I0209 01:52:52.793005 14948 layer_factory.hpp:77] Creating layer relu4_3
I0209 01:52:52.793020 14948 net.cpp:91] Creating Layer relu4_3
I0209 01:52:52.793025 14948 net.cpp:425] relu4_3 <- conv4_3
I0209 01:52:52.793031 14948 net.cpp:386] relu4_3 -> conv4_3 (in-place)
I0209 01:52:52.793053 14948 net.cpp:141] Setting up relu4_3
I0209 01:52:52.793058 14948 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0209 01:52:52.793062 14948 net.cpp:156] Memory required for data: 112394252
I0209 01:52:52.793066 14948 layer_factory.hpp:77] Creating layer rgb_pool4
I0209 01:52:52.793077 14948 net.cpp:91] Creating Layer rgb_pool4
I0209 01:52:52.793082 14948 net.cpp:425] rgb_pool4 <- conv4_3
I0209 01:52:52.793088 14948 net.cpp:399] rgb_pool4 -> rgb_pool4
I0209 01:52:52.793128 14948 net.cpp:141] Setting up rgb_pool4
I0209 01:52:52.793143 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:52.793148 14948 net.cpp:156] Memory required for data: 112795660
I0209 01:52:52.793160 14948 layer_factory.hpp:77] Creating layer conv5_1
I0209 01:52:52.793171 14948 net.cpp:91] Creating Layer conv5_1
I0209 01:52:52.793176 14948 net.cpp:425] conv5_1 <- rgb_pool4
I0209 01:52:52.793181 14948 net.cpp:399] conv5_1 -> conv5_1
I0209 01:52:52.805455 14948 net.cpp:141] Setting up conv5_1
I0209 01:52:52.805487 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:52.805496 14948 net.cpp:156] Memory required for data: 113197068
I0209 01:52:52.805516 14948 layer_factory.hpp:77] Creating layer relu5_1
I0209 01:52:52.805529 14948 net.cpp:91] Creating Layer relu5_1
I0209 01:52:52.805536 14948 net.cpp:425] relu5_1 <- conv5_1
I0209 01:52:52.805543 14948 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0209 01:52:52.805562 14948 net.cpp:141] Setting up relu5_1
I0209 01:52:52.805579 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:52.805584 14948 net.cpp:156] Memory required for data: 113598476
I0209 01:52:52.805593 14948 layer_factory.hpp:77] Creating layer conv5_2
I0209 01:52:52.805603 14948 net.cpp:91] Creating Layer conv5_2
I0209 01:52:52.805608 14948 net.cpp:425] conv5_2 <- conv5_1
I0209 01:52:52.805625 14948 net.cpp:399] conv5_2 -> conv5_2
I0209 01:52:52.817458 14948 net.cpp:141] Setting up conv5_2
I0209 01:52:52.817487 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:52.817492 14948 net.cpp:156] Memory required for data: 113999884
I0209 01:52:52.817502 14948 layer_factory.hpp:77] Creating layer relu5_2
I0209 01:52:52.817539 14948 net.cpp:91] Creating Layer relu5_2
I0209 01:52:52.817548 14948 net.cpp:425] relu5_2 <- conv5_2
I0209 01:52:52.817556 14948 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0209 01:52:52.817574 14948 net.cpp:141] Setting up relu5_2
I0209 01:52:52.817581 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:52.817595 14948 net.cpp:156] Memory required for data: 114401292
I0209 01:52:52.817600 14948 layer_factory.hpp:77] Creating layer conv5_3
I0209 01:52:52.817631 14948 net.cpp:91] Creating Layer conv5_3
I0209 01:52:52.817636 14948 net.cpp:425] conv5_3 <- conv5_2
I0209 01:52:52.817641 14948 net.cpp:399] conv5_3 -> conv5_3
I0209 01:52:52.829008 14948 net.cpp:141] Setting up conv5_3
I0209 01:52:52.829066 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:52.829077 14948 net.cpp:156] Memory required for data: 114802700
I0209 01:52:52.829105 14948 layer_factory.hpp:77] Creating layer relu5_3
I0209 01:52:52.829131 14948 net.cpp:91] Creating Layer relu5_3
I0209 01:52:52.829141 14948 net.cpp:425] relu5_3 <- conv5_3
I0209 01:52:52.829162 14948 net.cpp:386] relu5_3 -> conv5_3 (in-place)
I0209 01:52:52.829175 14948 net.cpp:141] Setting up relu5_3
I0209 01:52:52.829185 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:52.829191 14948 net.cpp:156] Memory required for data: 115204108
I0209 01:52:52.829197 14948 layer_factory.hpp:77] Creating layer rgb_pool5
I0209 01:52:52.829218 14948 net.cpp:91] Creating Layer rgb_pool5
I0209 01:52:52.829226 14948 net.cpp:425] rgb_pool5 <- conv5_3
I0209 01:52:52.829236 14948 net.cpp:399] rgb_pool5 -> rgb_pool5
I0209 01:52:52.829327 14948 net.cpp:141] Setting up rgb_pool5
I0209 01:52:52.829349 14948 net.cpp:148] Top shape: 1 512 7 7 (25088)
I0209 01:52:52.829355 14948 net.cpp:156] Memory required for data: 115304460
I0209 01:52:52.829368 14948 layer_factory.hpp:77] Creating layer rgb_fc6
I0209 01:52:52.829390 14948 net.cpp:91] Creating Layer rgb_fc6
I0209 01:52:52.829397 14948 net.cpp:425] rgb_fc6 <- rgb_pool5
I0209 01:52:52.829406 14948 net.cpp:399] rgb_fc6 -> rgb_fc6
I0209 01:52:53.307788 14948 net.cpp:141] Setting up rgb_fc6
I0209 01:52:53.307818 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.307824 14948 net.cpp:156] Memory required for data: 115320844
I0209 01:52:53.307835 14948 layer_factory.hpp:77] Creating layer rgb_relu6
I0209 01:52:53.307858 14948 net.cpp:91] Creating Layer rgb_relu6
I0209 01:52:53.307874 14948 net.cpp:425] rgb_relu6 <- rgb_fc6
I0209 01:52:53.307890 14948 net.cpp:386] rgb_relu6 -> rgb_fc6 (in-place)
I0209 01:52:53.307911 14948 net.cpp:141] Setting up rgb_relu6
I0209 01:52:53.307917 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.307931 14948 net.cpp:156] Memory required for data: 115337228
I0209 01:52:53.307935 14948 layer_factory.hpp:77] Creating layer rgb_drop6
I0209 01:52:53.307955 14948 net.cpp:91] Creating Layer rgb_drop6
I0209 01:52:53.307968 14948 net.cpp:425] rgb_drop6 <- rgb_fc6
I0209 01:52:53.307973 14948 net.cpp:386] rgb_drop6 -> rgb_fc6 (in-place)
I0209 01:52:53.308015 14948 net.cpp:141] Setting up rgb_drop6
I0209 01:52:53.308030 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.308034 14948 net.cpp:156] Memory required for data: 115353612
I0209 01:52:53.308048 14948 layer_factory.hpp:77] Creating layer rgb_fc7
I0209 01:52:53.308055 14948 net.cpp:91] Creating Layer rgb_fc7
I0209 01:52:53.308068 14948 net.cpp:425] rgb_fc7 <- rgb_fc6
I0209 01:52:53.308086 14948 net.cpp:399] rgb_fc7 -> rgb_fc7
I0209 01:52:53.388146 14948 net.cpp:141] Setting up rgb_fc7
I0209 01:52:53.388193 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.388201 14948 net.cpp:156] Memory required for data: 115369996
I0209 01:52:53.388217 14948 layer_factory.hpp:77] Creating layer rgb_relu7
I0209 01:52:53.388240 14948 net.cpp:91] Creating Layer rgb_relu7
I0209 01:52:53.388259 14948 net.cpp:425] rgb_relu7 <- rgb_fc7
I0209 01:52:53.388270 14948 net.cpp:386] rgb_relu7 -> rgb_fc7 (in-place)
I0209 01:52:53.388283 14948 net.cpp:141] Setting up rgb_relu7
I0209 01:52:53.388289 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.388294 14948 net.cpp:156] Memory required for data: 115386380
I0209 01:52:53.388301 14948 layer_factory.hpp:77] Creating layer rgb_drop7
I0209 01:52:53.388311 14948 net.cpp:91] Creating Layer rgb_drop7
I0209 01:52:53.388317 14948 net.cpp:425] rgb_drop7 <- rgb_fc7
I0209 01:52:53.388324 14948 net.cpp:386] rgb_drop7 -> rgb_fc7 (in-place)
I0209 01:52:53.388366 14948 net.cpp:141] Setting up rgb_drop7
I0209 01:52:53.388381 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.388386 14948 net.cpp:156] Memory required for data: 115402764
I0209 01:52:53.388389 14948 layer_factory.hpp:77] Creating layer conv1
I0209 01:52:53.388409 14948 net.cpp:91] Creating Layer conv1
I0209 01:52:53.388425 14948 net.cpp:425] conv1 <- depth
I0209 01:52:53.388432 14948 net.cpp:399] conv1 -> conv1
I0209 01:52:53.388669 14948 net.cpp:141] Setting up conv1
I0209 01:52:53.388687 14948 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0209 01:52:53.388691 14948 net.cpp:156] Memory required for data: 121825292
I0209 01:52:53.388698 14948 layer_factory.hpp:77] Creating layer relu1
I0209 01:52:53.388716 14948 net.cpp:91] Creating Layer relu1
I0209 01:52:53.388721 14948 net.cpp:425] relu1 <- conv1
I0209 01:52:53.388727 14948 net.cpp:386] relu1 -> conv1 (in-place)
I0209 01:52:53.388734 14948 net.cpp:141] Setting up relu1
I0209 01:52:53.388741 14948 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0209 01:52:53.388744 14948 net.cpp:156] Memory required for data: 128247820
I0209 01:52:53.388749 14948 layer_factory.hpp:77] Creating layer depth_pool1
I0209 01:52:53.388758 14948 net.cpp:91] Creating Layer depth_pool1
I0209 01:52:53.388762 14948 net.cpp:425] depth_pool1 <- conv1
I0209 01:52:53.388777 14948 net.cpp:399] depth_pool1 -> depth_pool1
I0209 01:52:53.388831 14948 net.cpp:141] Setting up depth_pool1
I0209 01:52:53.388839 14948 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0209 01:52:53.388844 14948 net.cpp:156] Memory required for data: 129853452
I0209 01:52:53.388849 14948 layer_factory.hpp:77] Creating layer norm1
I0209 01:52:53.388855 14948 net.cpp:91] Creating Layer norm1
I0209 01:52:53.388860 14948 net.cpp:425] norm1 <- depth_pool1
I0209 01:52:53.388866 14948 net.cpp:399] norm1 -> norm1
I0209 01:52:53.388903 14948 net.cpp:141] Setting up norm1
I0209 01:52:53.388908 14948 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0209 01:52:53.388912 14948 net.cpp:156] Memory required for data: 131459084
I0209 01:52:53.388926 14948 layer_factory.hpp:77] Creating layer conv2
I0209 01:52:53.388936 14948 net.cpp:91] Creating Layer conv2
I0209 01:52:53.388939 14948 net.cpp:425] conv2 <- norm1
I0209 01:52:53.388945 14948 net.cpp:399] conv2 -> conv2
I0209 01:52:53.393076 14948 net.cpp:141] Setting up conv2
I0209 01:52:53.393091 14948 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0209 01:52:53.393106 14948 net.cpp:156] Memory required for data: 134670348
I0209 01:52:53.393117 14948 layer_factory.hpp:77] Creating layer relu2
I0209 01:52:53.393124 14948 net.cpp:91] Creating Layer relu2
I0209 01:52:53.393128 14948 net.cpp:425] relu2 <- conv2
I0209 01:52:53.393134 14948 net.cpp:386] relu2 -> conv2 (in-place)
I0209 01:52:53.393141 14948 net.cpp:141] Setting up relu2
I0209 01:52:53.393146 14948 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0209 01:52:53.393160 14948 net.cpp:156] Memory required for data: 137881612
I0209 01:52:53.393164 14948 layer_factory.hpp:77] Creating layer depth_pool2
I0209 01:52:53.393170 14948 net.cpp:91] Creating Layer depth_pool2
I0209 01:52:53.393184 14948 net.cpp:425] depth_pool2 <- conv2
I0209 01:52:53.393189 14948 net.cpp:399] depth_pool2 -> depth_pool2
I0209 01:52:53.393224 14948 net.cpp:141] Setting up depth_pool2
I0209 01:52:53.393230 14948 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0209 01:52:53.393234 14948 net.cpp:156] Memory required for data: 138684428
I0209 01:52:53.393239 14948 layer_factory.hpp:77] Creating layer norm2
I0209 01:52:53.393245 14948 net.cpp:91] Creating Layer norm2
I0209 01:52:53.393259 14948 net.cpp:425] norm2 <- depth_pool2
I0209 01:52:53.393265 14948 net.cpp:399] norm2 -> norm2
I0209 01:52:53.393285 14948 net.cpp:141] Setting up norm2
I0209 01:52:53.393290 14948 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0209 01:52:53.393296 14948 net.cpp:156] Memory required for data: 139487244
I0209 01:52:53.393299 14948 layer_factory.hpp:77] Creating layer conv3
I0209 01:52:53.393306 14948 net.cpp:91] Creating Layer conv3
I0209 01:52:53.393311 14948 net.cpp:425] conv3 <- norm2
I0209 01:52:53.393316 14948 net.cpp:399] conv3 -> conv3
I0209 01:52:53.395558 14948 net.cpp:141] Setting up conv3
I0209 01:52:53.395570 14948 net.cpp:148] Top shape: 1 384 28 28 (301056)
I0209 01:52:53.395575 14948 net.cpp:156] Memory required for data: 140691468
I0209 01:52:53.395581 14948 layer_factory.hpp:77] Creating layer relu3
I0209 01:52:53.395588 14948 net.cpp:91] Creating Layer relu3
I0209 01:52:53.395592 14948 net.cpp:425] relu3 <- conv3
I0209 01:52:53.395598 14948 net.cpp:386] relu3 -> conv3 (in-place)
I0209 01:52:53.395604 14948 net.cpp:141] Setting up relu3
I0209 01:52:53.395609 14948 net.cpp:148] Top shape: 1 384 28 28 (301056)
I0209 01:52:53.395613 14948 net.cpp:156] Memory required for data: 141895692
I0209 01:52:53.395617 14948 layer_factory.hpp:77] Creating layer depth_pool3
I0209 01:52:53.395623 14948 net.cpp:91] Creating Layer depth_pool3
I0209 01:52:53.395627 14948 net.cpp:425] depth_pool3 <- conv3
I0209 01:52:53.395633 14948 net.cpp:399] depth_pool3 -> depth_pool3
I0209 01:52:53.395659 14948 net.cpp:141] Setting up depth_pool3
I0209 01:52:53.395665 14948 net.cpp:148] Top shape: 1 384 14 14 (75264)
I0209 01:52:53.395669 14948 net.cpp:156] Memory required for data: 142196748
I0209 01:52:53.395673 14948 layer_factory.hpp:77] Creating layer conv4
I0209 01:52:53.395680 14948 net.cpp:91] Creating Layer conv4
I0209 01:52:53.395684 14948 net.cpp:425] conv4 <- depth_pool3
I0209 01:52:53.395690 14948 net.cpp:399] conv4 -> conv4
I0209 01:52:53.404253 14948 net.cpp:141] Setting up conv4
I0209 01:52:53.404280 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:53.404285 14948 net.cpp:156] Memory required for data: 142598156
I0209 01:52:53.404294 14948 layer_factory.hpp:77] Creating layer relu4
I0209 01:52:53.404314 14948 net.cpp:91] Creating Layer relu4
I0209 01:52:53.404320 14948 net.cpp:425] relu4 <- conv4
I0209 01:52:53.404335 14948 net.cpp:386] relu4 -> conv4 (in-place)
I0209 01:52:53.404353 14948 net.cpp:141] Setting up relu4
I0209 01:52:53.404357 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:53.404371 14948 net.cpp:156] Memory required for data: 142999564
I0209 01:52:53.404376 14948 layer_factory.hpp:77] Creating layer conv5
I0209 01:52:53.404393 14948 net.cpp:91] Creating Layer conv5
I0209 01:52:53.404397 14948 net.cpp:425] conv5 <- conv4
I0209 01:52:53.404414 14948 net.cpp:399] conv5 -> conv5
I0209 01:52:53.415685 14948 net.cpp:141] Setting up conv5
I0209 01:52:53.415719 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:53.415735 14948 net.cpp:156] Memory required for data: 143400972
I0209 01:52:53.415745 14948 layer_factory.hpp:77] Creating layer relu5
I0209 01:52:53.415765 14948 net.cpp:91] Creating Layer relu5
I0209 01:52:53.415769 14948 net.cpp:425] relu5 <- conv5
I0209 01:52:53.415776 14948 net.cpp:386] relu5 -> conv5 (in-place)
I0209 01:52:53.415784 14948 net.cpp:141] Setting up relu5
I0209 01:52:53.415789 14948 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0209 01:52:53.415796 14948 net.cpp:156] Memory required for data: 143802380
I0209 01:52:53.415799 14948 layer_factory.hpp:77] Creating layer depth_pool5
I0209 01:52:53.415817 14948 net.cpp:91] Creating Layer depth_pool5
I0209 01:52:53.415819 14948 net.cpp:425] depth_pool5 <- conv5
I0209 01:52:53.415824 14948 net.cpp:399] depth_pool5 -> depth_pool5
I0209 01:52:53.415874 14948 net.cpp:141] Setting up depth_pool5
I0209 01:52:53.415879 14948 net.cpp:148] Top shape: 1 512 7 7 (25088)
I0209 01:52:53.415892 14948 net.cpp:156] Memory required for data: 143902732
I0209 01:52:53.415897 14948 layer_factory.hpp:77] Creating layer depth_fc6
I0209 01:52:53.415913 14948 net.cpp:91] Creating Layer depth_fc6
I0209 01:52:53.415931 14948 net.cpp:425] depth_fc6 <- depth_pool5
I0209 01:52:53.415937 14948 net.cpp:399] depth_fc6 -> depth_fc6
I0209 01:52:53.895623 14948 net.cpp:141] Setting up depth_fc6
I0209 01:52:53.895654 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.895660 14948 net.cpp:156] Memory required for data: 143919116
I0209 01:52:53.895671 14948 layer_factory.hpp:77] Creating layer depth_relu6
I0209 01:52:53.895694 14948 net.cpp:91] Creating Layer depth_relu6
I0209 01:52:53.895710 14948 net.cpp:425] depth_relu6 <- depth_fc6
I0209 01:52:53.895727 14948 net.cpp:386] depth_relu6 -> depth_fc6 (in-place)
I0209 01:52:53.895737 14948 net.cpp:141] Setting up depth_relu6
I0209 01:52:53.895743 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.895748 14948 net.cpp:156] Memory required for data: 143935500
I0209 01:52:53.895753 14948 layer_factory.hpp:77] Creating layer depth_drop6
I0209 01:52:53.895761 14948 net.cpp:91] Creating Layer depth_drop6
I0209 01:52:53.895766 14948 net.cpp:425] depth_drop6 <- depth_fc6
I0209 01:52:53.895782 14948 net.cpp:386] depth_drop6 -> depth_fc6 (in-place)
I0209 01:52:53.895825 14948 net.cpp:141] Setting up depth_drop6
I0209 01:52:53.895831 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.895849 14948 net.cpp:156] Memory required for data: 143951884
I0209 01:52:53.895853 14948 layer_factory.hpp:77] Creating layer depth_fc7
I0209 01:52:53.895869 14948 net.cpp:91] Creating Layer depth_fc7
I0209 01:52:53.895874 14948 net.cpp:425] depth_fc7 <- depth_fc6
I0209 01:52:53.895889 14948 net.cpp:399] depth_fc7 -> depth_fc7
I0209 01:52:53.974858 14948 net.cpp:141] Setting up depth_fc7
I0209 01:52:53.974934 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.974948 14948 net.cpp:156] Memory required for data: 143968268
I0209 01:52:53.974969 14948 layer_factory.hpp:77] Creating layer depth_relu7
I0209 01:52:53.974998 14948 net.cpp:91] Creating Layer depth_relu7
I0209 01:52:53.975011 14948 net.cpp:425] depth_relu7 <- depth_fc7
I0209 01:52:53.975033 14948 net.cpp:386] depth_relu7 -> depth_fc7 (in-place)
I0209 01:52:53.975049 14948 net.cpp:141] Setting up depth_relu7
I0209 01:52:53.975059 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.975065 14948 net.cpp:156] Memory required for data: 143984652
I0209 01:52:53.975073 14948 layer_factory.hpp:77] Creating layer depth_drop7
I0209 01:52:53.975085 14948 net.cpp:91] Creating Layer depth_drop7
I0209 01:52:53.975091 14948 net.cpp:425] depth_drop7 <- depth_fc7
I0209 01:52:53.975098 14948 net.cpp:386] depth_drop7 -> depth_fc7 (in-place)
I0209 01:52:53.975167 14948 net.cpp:141] Setting up depth_drop7
I0209 01:52:53.975185 14948 net.cpp:148] Top shape: 1 4096 (4096)
I0209 01:52:53.975190 14948 net.cpp:156] Memory required for data: 144001036
I0209 01:52:53.975194 14948 layer_factory.hpp:77] Creating layer concat
I0209 01:52:53.975214 14948 net.cpp:91] Creating Layer concat
I0209 01:52:53.975220 14948 net.cpp:425] concat <- rgb_fc7
I0209 01:52:53.975230 14948 net.cpp:425] concat <- depth_fc7
I0209 01:52:53.975237 14948 net.cpp:399] concat -> concat
I0209 01:52:53.975301 14948 net.cpp:141] Setting up concat
I0209 01:52:53.975307 14948 net.cpp:148] Top shape: 1 8192 (8192)
I0209 01:52:53.975322 14948 net.cpp:156] Memory required for data: 144033804
I0209 01:52:53.975327 14948 layer_factory.hpp:77] Creating layer fuse_fc1
I0209 01:52:53.975347 14948 net.cpp:91] Creating Layer fuse_fc1
I0209 01:52:53.975353 14948 net.cpp:425] fuse_fc1 <- concat
I0209 01:52:53.975368 14948 net.cpp:399] fuse_fc1 -> fuse_fc1
I0209 01:52:54.016680 14948 net.cpp:141] Setting up fuse_fc1
I0209 01:52:54.016732 14948 net.cpp:148] Top shape: 1 1024 (1024)
I0209 01:52:54.016737 14948 net.cpp:156] Memory required for data: 144037900
I0209 01:52:54.016746 14948 layer_factory.hpp:77] Creating layer fuse_relu1
I0209 01:52:54.016767 14948 net.cpp:91] Creating Layer fuse_relu1
I0209 01:52:54.016784 14948 net.cpp:425] fuse_relu1 <- fuse_fc1
I0209 01:52:54.016791 14948 net.cpp:386] fuse_relu1 -> fuse_fc1 (in-place)
I0209 01:52:54.016800 14948 net.cpp:141] Setting up fuse_relu1
I0209 01:52:54.016806 14948 net.cpp:148] Top shape: 1 1024 (1024)
I0209 01:52:54.016809 14948 net.cpp:156] Memory required for data: 144041996
I0209 01:52:54.016813 14948 layer_factory.hpp:77] Creating layer fuse_drop1
I0209 01:52:54.016827 14948 net.cpp:91] Creating Layer fuse_drop1
I0209 01:52:54.016831 14948 net.cpp:425] fuse_drop1 <- fuse_fc1
I0209 01:52:54.016845 14948 net.cpp:386] fuse_drop1 -> fuse_fc1 (in-place)
I0209 01:52:54.016907 14948 net.cpp:141] Setting up fuse_drop1
I0209 01:52:54.016922 14948 net.cpp:148] Top shape: 1 1024 (1024)
I0209 01:52:54.016927 14948 net.cpp:156] Memory required for data: 144046092
I0209 01:52:54.016930 14948 layer_factory.hpp:77] Creating layer fuse_fc2
I0209 01:52:54.016950 14948 net.cpp:91] Creating Layer fuse_fc2
I0209 01:52:54.016954 14948 net.cpp:425] fuse_fc2 <- fuse_fc1
I0209 01:52:54.016962 14948 net.cpp:399] fuse_fc2 -> fuse_fc2
I0209 01:52:54.023037 14948 net.cpp:141] Setting up fuse_fc2
I0209 01:52:54.023084 14948 net.cpp:148] Top shape: 1 1024 (1024)
I0209 01:52:54.023097 14948 net.cpp:156] Memory required for data: 144050188
I0209 01:52:54.023120 14948 layer_factory.hpp:77] Creating layer fuse_relu2
I0209 01:52:54.023134 14948 net.cpp:91] Creating Layer fuse_relu2
I0209 01:52:54.023152 14948 net.cpp:425] fuse_relu2 <- fuse_fc2
I0209 01:52:54.023170 14948 net.cpp:386] fuse_relu2 -> fuse_fc2 (in-place)
I0209 01:52:54.023182 14948 net.cpp:141] Setting up fuse_relu2
I0209 01:52:54.023197 14948 net.cpp:148] Top shape: 1 1024 (1024)
I0209 01:52:54.023201 14948 net.cpp:156] Memory required for data: 144054284
I0209 01:52:54.023216 14948 layer_factory.hpp:77] Creating layer fuse_drop2
I0209 01:52:54.023226 14948 net.cpp:91] Creating Layer fuse_drop2
I0209 01:52:54.023229 14948 net.cpp:425] fuse_drop2 <- fuse_fc2
I0209 01:52:54.023237 14948 net.cpp:386] fuse_drop2 -> fuse_fc2 (in-place)
I0209 01:52:54.023279 14948 net.cpp:141] Setting up fuse_drop2
I0209 01:52:54.023288 14948 net.cpp:148] Top shape: 1 1024 (1024)
I0209 01:52:54.023301 14948 net.cpp:156] Memory required for data: 144058380
I0209 01:52:54.023308 14948 layer_factory.hpp:77] Creating layer rgbd_fc8
I0209 01:52:54.023317 14948 net.cpp:91] Creating Layer rgbd_fc8
I0209 01:52:54.023324 14948 net.cpp:425] rgbd_fc8 <- fuse_fc2
I0209 01:52:54.023331 14948 net.cpp:399] rgbd_fc8 -> rgbd_fc8
I0209 01:52:54.023488 14948 net.cpp:141] Setting up rgbd_fc8
I0209 01:52:54.023496 14948 net.cpp:148] Top shape: 1 11 (11)
I0209 01:52:54.023509 14948 net.cpp:156] Memory required for data: 144058424
I0209 01:52:54.023517 14948 layer_factory.hpp:77] Creating layer rgbd_fc8_rgbd_fc8_0_split
I0209 01:52:54.023524 14948 net.cpp:91] Creating Layer rgbd_fc8_rgbd_fc8_0_split
I0209 01:52:54.023528 14948 net.cpp:425] rgbd_fc8_rgbd_fc8_0_split <- rgbd_fc8
I0209 01:52:54.023533 14948 net.cpp:399] rgbd_fc8_rgbd_fc8_0_split -> rgbd_fc8_rgbd_fc8_0_split_0
I0209 01:52:54.023541 14948 net.cpp:399] rgbd_fc8_rgbd_fc8_0_split -> rgbd_fc8_rgbd_fc8_0_split_1
I0209 01:52:54.023567 14948 net.cpp:141] Setting up rgbd_fc8_rgbd_fc8_0_split
I0209 01:52:54.023573 14948 net.cpp:148] Top shape: 1 11 (11)
I0209 01:52:54.023578 14948 net.cpp:148] Top shape: 1 11 (11)
I0209 01:52:54.023582 14948 net.cpp:156] Memory required for data: 144058512
I0209 01:52:54.023586 14948 layer_factory.hpp:77] Creating layer rgbd_accuracy
I0209 01:52:54.023593 14948 net.cpp:91] Creating Layer rgbd_accuracy
I0209 01:52:54.023597 14948 net.cpp:425] rgbd_accuracy <- rgbd_fc8_rgbd_fc8_0_split_0
I0209 01:52:54.023603 14948 net.cpp:425] rgbd_accuracy <- label_data_2_split_0
I0209 01:52:54.023608 14948 net.cpp:399] rgbd_accuracy -> rgbd_accuracy
I0209 01:52:54.023617 14948 net.cpp:141] Setting up rgbd_accuracy
I0209 01:52:54.023622 14948 net.cpp:148] Top shape: (1)
I0209 01:52:54.023627 14948 net.cpp:156] Memory required for data: 144058516
I0209 01:52:54.023630 14948 layer_factory.hpp:77] Creating layer rgbd_loss
I0209 01:52:54.023638 14948 net.cpp:91] Creating Layer rgbd_loss
I0209 01:52:54.023641 14948 net.cpp:425] rgbd_loss <- rgbd_fc8_rgbd_fc8_0_split_1
I0209 01:52:54.023646 14948 net.cpp:425] rgbd_loss <- label_data_2_split_1
I0209 01:52:54.023653 14948 net.cpp:399] rgbd_loss -> rgbd_loss
I0209 01:52:54.023659 14948 layer_factory.hpp:77] Creating layer rgbd_loss
I0209 01:52:54.023720 14948 net.cpp:141] Setting up rgbd_loss
I0209 01:52:54.023725 14948 net.cpp:148] Top shape: (1)
I0209 01:52:54.023730 14948 net.cpp:151]     with loss weight 1
I0209 01:52:54.023739 14948 net.cpp:156] Memory required for data: 144058520
I0209 01:52:54.023744 14948 net.cpp:217] rgbd_loss needs backward computation.
I0209 01:52:54.023749 14948 net.cpp:219] rgbd_accuracy does not need backward computation.
I0209 01:52:54.023754 14948 net.cpp:217] rgbd_fc8_rgbd_fc8_0_split needs backward computation.
I0209 01:52:54.023759 14948 net.cpp:217] rgbd_fc8 needs backward computation.
I0209 01:52:54.023763 14948 net.cpp:217] fuse_drop2 needs backward computation.
I0209 01:52:54.023768 14948 net.cpp:217] fuse_relu2 needs backward computation.
I0209 01:52:54.023772 14948 net.cpp:217] fuse_fc2 needs backward computation.
I0209 01:52:54.023777 14948 net.cpp:217] fuse_drop1 needs backward computation.
I0209 01:52:54.023782 14948 net.cpp:217] fuse_relu1 needs backward computation.
I0209 01:52:54.023787 14948 net.cpp:217] fuse_fc1 needs backward computation.
I0209 01:52:54.023792 14948 net.cpp:217] concat needs backward computation.
I0209 01:52:54.023795 14948 net.cpp:217] depth_drop7 needs backward computation.
I0209 01:52:54.023799 14948 net.cpp:217] depth_relu7 needs backward computation.
I0209 01:52:54.023813 14948 net.cpp:217] depth_fc7 needs backward computation.
I0209 01:52:54.023818 14948 net.cpp:217] depth_drop6 needs backward computation.
I0209 01:52:54.023823 14948 net.cpp:217] depth_relu6 needs backward computation.
I0209 01:52:54.023826 14948 net.cpp:217] depth_fc6 needs backward computation.
I0209 01:52:54.023831 14948 net.cpp:219] depth_pool5 does not need backward computation.
I0209 01:52:54.023835 14948 net.cpp:219] relu5 does not need backward computation.
I0209 01:52:54.023840 14948 net.cpp:219] conv5 does not need backward computation.
I0209 01:52:54.023845 14948 net.cpp:219] relu4 does not need backward computation.
I0209 01:52:54.023850 14948 net.cpp:219] conv4 does not need backward computation.
I0209 01:52:54.023855 14948 net.cpp:219] depth_pool3 does not need backward computation.
I0209 01:52:54.023860 14948 net.cpp:219] relu3 does not need backward computation.
I0209 01:52:54.023864 14948 net.cpp:219] conv3 does not need backward computation.
I0209 01:52:54.023869 14948 net.cpp:219] norm2 does not need backward computation.
I0209 01:52:54.023874 14948 net.cpp:219] depth_pool2 does not need backward computation.
I0209 01:52:54.023880 14948 net.cpp:219] relu2 does not need backward computation.
I0209 01:52:54.023883 14948 net.cpp:219] conv2 does not need backward computation.
I0209 01:52:54.023888 14948 net.cpp:219] norm1 does not need backward computation.
I0209 01:52:54.023893 14948 net.cpp:219] depth_pool1 does not need backward computation.
I0209 01:52:54.023898 14948 net.cpp:219] relu1 does not need backward computation.
I0209 01:52:54.023902 14948 net.cpp:219] conv1 does not need backward computation.
I0209 01:52:54.023907 14948 net.cpp:217] rgb_drop7 needs backward computation.
I0209 01:52:54.023912 14948 net.cpp:217] rgb_relu7 needs backward computation.
I0209 01:52:54.023916 14948 net.cpp:217] rgb_fc7 needs backward computation.
I0209 01:52:54.023921 14948 net.cpp:217] rgb_drop6 needs backward computation.
I0209 01:52:54.023926 14948 net.cpp:217] rgb_relu6 needs backward computation.
I0209 01:52:54.023931 14948 net.cpp:217] rgb_fc6 needs backward computation.
I0209 01:52:54.023936 14948 net.cpp:219] rgb_pool5 does not need backward computation.
I0209 01:52:54.023941 14948 net.cpp:219] relu5_3 does not need backward computation.
I0209 01:52:54.023946 14948 net.cpp:219] conv5_3 does not need backward computation.
I0209 01:52:54.023950 14948 net.cpp:219] relu5_2 does not need backward computation.
I0209 01:52:54.023954 14948 net.cpp:219] conv5_2 does not need backward computation.
I0209 01:52:54.023959 14948 net.cpp:219] relu5_1 does not need backward computation.
I0209 01:52:54.023964 14948 net.cpp:219] conv5_1 does not need backward computation.
I0209 01:52:54.023968 14948 net.cpp:219] rgb_pool4 does not need backward computation.
I0209 01:52:54.023974 14948 net.cpp:219] relu4_3 does not need backward computation.
I0209 01:52:54.023978 14948 net.cpp:219] conv4_3 does not need backward computation.
I0209 01:52:54.023983 14948 net.cpp:219] relu4_2 does not need backward computation.
I0209 01:52:54.023988 14948 net.cpp:219] conv4_2 does not need backward computation.
I0209 01:52:54.023993 14948 net.cpp:219] relu4_1 does not need backward computation.
I0209 01:52:54.023998 14948 net.cpp:219] conv4_1 does not need backward computation.
I0209 01:52:54.024003 14948 net.cpp:219] rgb_pool3 does not need backward computation.
I0209 01:52:54.024008 14948 net.cpp:219] relu3_3 does not need backward computation.
I0209 01:52:54.024011 14948 net.cpp:219] conv3_3 does not need backward computation.
I0209 01:52:54.024016 14948 net.cpp:219] relu3_2 does not need backward computation.
I0209 01:52:54.024021 14948 net.cpp:219] conv3_2 does not need backward computation.
I0209 01:52:54.024026 14948 net.cpp:219] relu3_1 does not need backward computation.
I0209 01:52:54.024030 14948 net.cpp:219] conv3_1 does not need backward computation.
I0209 01:52:54.024034 14948 net.cpp:219] rgb_pool2 does not need backward computation.
I0209 01:52:54.024039 14948 net.cpp:219] relu2_2 does not need backward computation.
I0209 01:52:54.024044 14948 net.cpp:219] conv2_2 does not need backward computation.
I0209 01:52:54.024049 14948 net.cpp:219] relu2_1 does not need backward computation.
I0209 01:52:54.024052 14948 net.cpp:219] conv2_1 does not need backward computation.
I0209 01:52:54.024057 14948 net.cpp:219] rgb_pool1 does not need backward computation.
I0209 01:52:54.024062 14948 net.cpp:219] relu1_2 does not need backward computation.
I0209 01:52:54.024067 14948 net.cpp:219] conv1_2 does not need backward computation.
I0209 01:52:54.024072 14948 net.cpp:219] relu1_1 does not need backward computation.
I0209 01:52:54.024076 14948 net.cpp:219] conv1_1 does not need backward computation.
I0209 01:52:54.024081 14948 net.cpp:219] label_data_2_split does not need backward computation.
I0209 01:52:54.024087 14948 net.cpp:219] data does not need backward computation.
I0209 01:52:54.024091 14948 net.cpp:261] This network produces output rgbd_accuracy
I0209 01:52:54.024096 14948 net.cpp:261] This network produces output rgbd_loss
I0209 01:52:54.024121 14948 net.cpp:274] Network initialization done.
I0209 01:52:54.024278 14948 solver.cpp:60] Solver scaffolding done.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 1037173505
I0209 01:53:04.925536 14948 net.cpp:752] Ignoring source layer rgb_fc8
I0209 01:53:04.925570 14948 net.cpp:752] Ignoring source layer rgb_fc8_rgb_fc8_0_split
I0209 01:53:05.005282 14948 net.cpp:752] Ignoring source layer depth_fc8
I0209 01:53:05.005313 14948 net.cpp:752] Ignoring source layer depth_fc8_depth_fc8_0_split
I0209 01:53:05.005318 14948 net.cpp:752] Ignoring source layer rgb_accuracy
I0209 01:53:05.005324 14948 net.cpp:752] Ignoring source layer rgb_loss
I0209 01:53:05.005328 14948 net.cpp:752] Ignoring source layer depth_accuracy
I0209 01:53:05.005333 14948 net.cpp:752] Ignoring source layer depth_loss
I0209 01:53:05.038489 14948 solver.cpp:337] Iteration 0, Testing net (#0)
I0209 01:53:05.251433 14948 solver.cpp:404]     Test net output #0: rgbd_accuracy = 0
I0209 01:53:05.251466 14948 solver.cpp:404]     Test net output #1: rgbd_loss = 2.34059 (* 1 = 2.34059 loss)
I0209 01:53:06.425393 14948 solver.cpp:228] Iteration 0, loss = 2.68205
I0209 01:53:06.425422 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.046875
I0209 01:53:06.425431 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 2.68205 (* 1 = 2.68205 loss)
I0209 01:53:06.425438 14948 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0209 01:54:00.581248 14948 solver.cpp:228] Iteration 50, loss = 1.02915
I0209 01:54:00.581279 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.890625
I0209 01:54:00.581300 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.368472 (* 1 = 0.368472 loss)
I0209 01:54:00.581317 14948 sgd_solver.cpp:106] Iteration 50, lr = 0.001
>>> 2017-02-09 01:54:54.647597 Begin model classification tests
>>> 2017-02-09 01:55:12.666852 Iteration 100 mean classification accuracy (rgb)  0.84222737819
>>> 2017-02-09 01:55:12.666883 Iteration 100 mean classification accuracy (depth) 0.84222737819
>>> 2017-02-09 01:55:12.666891 Iteration 100 mean classification accuracy (rgbd)  0.84222737819
>>> 2017-02-09 01:55:12.666897 Iteration 100 mean testing loss (rgb) 0.610567931038
>>> 2017-02-09 01:55:12.666908 Iteration 100 mean testing loss (depth) 0.610567931038
>>> 2017-02-09 01:55:12.666925 Iteration 100 mean testing loss (rgbd) 0.610567931038
>>> 2017-02-09 01:55:12.666941 Iteration 100 mean confusion matrix
[ 0.94285714  0.9826087   0.78571429  0.          0.6         0.91176471
  0.85185185  0.95        0.18181818  0.90909091  0.86666667]
I0209 01:55:13.764300 14948 solver.cpp:228] Iteration 100, loss = 0.130718
I0209 01:55:13.764331 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 01:55:13.764340 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.130718 (* 1 = 0.130718 loss)
I0209 01:55:13.764348 14948 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0209 01:56:08.000263 14948 solver.cpp:228] Iteration 150, loss = 0.115356
I0209 01:56:08.000299 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.921875
I0209 01:56:08.000315 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.167216 (* 1 = 0.167216 loss)
I0209 01:56:08.000337 14948 sgd_solver.cpp:106] Iteration 150, lr = 0.001
>>> 2017-02-09 01:57:00.601867 Begin model classification tests
>>> 2017-02-09 01:57:18.582292 Iteration 200 mean classification accuracy (rgb)  0.84222737819
>>> 2017-02-09 01:57:18.582324 Iteration 200 mean classification accuracy (depth) 0.84222737819
>>> 2017-02-09 01:57:18.582332 Iteration 200 mean classification accuracy (rgbd)  0.84222737819
>>> 2017-02-09 01:57:18.582338 Iteration 200 mean testing loss (rgb) 0.660561667666
>>> 2017-02-09 01:57:18.582350 Iteration 200 mean testing loss (depth) 0.660561667666
>>> 2017-02-09 01:57:18.582370 Iteration 200 mean testing loss (rgbd) 0.660561667666
>>> 2017-02-09 01:57:18.582389 Iteration 200 mean confusion matrix
[ 0.95714286  0.9826087   0.76785714  0.          0.6         0.94117647
  0.77777778  0.95        0.27272727  0.93939394  0.83333333]
I0209 01:57:19.669487 14948 solver.cpp:228] Iteration 200, loss = 0.0623059
I0209 01:57:19.669535 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 01:57:19.669544 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0623059 (* 1 = 0.0623059 loss)
I0209 01:57:19.669564 14948 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0209 01:58:13.488876 14948 solver.cpp:228] Iteration 250, loss = 0.0708701
I0209 01:58:13.488903 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 01:58:13.488912 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0658097 (* 1 = 0.0658097 loss)
I0209 01:58:13.488919 14948 sgd_solver.cpp:106] Iteration 250, lr = 0.001
>>> 2017-02-09 01:59:06.183429 Begin model classification tests
>>> 2017-02-09 01:59:24.145393 Iteration 300 mean classification accuracy (rgb)  0.849187935035
>>> 2017-02-09 01:59:24.145424 Iteration 300 mean classification accuracy (depth) 0.849187935035
>>> 2017-02-09 01:59:24.145432 Iteration 300 mean classification accuracy (rgbd)  0.849187935035
>>> 2017-02-09 01:59:24.145439 Iteration 300 mean testing loss (rgb) 0.699711366499
>>> 2017-02-09 01:59:24.145450 Iteration 300 mean testing loss (depth) 0.699711366499
>>> 2017-02-09 01:59:24.145467 Iteration 300 mean testing loss (rgbd) 0.699711366499
>>> 2017-02-09 01:59:24.145476 Iteration 300 mean confusion matrix
[ 0.97142857  0.9826087   0.78571429  0.          0.6         0.91176471
  0.85185185  0.95        0.27272727  0.93939394  0.83333333]
I0209 01:59:25.217049 14948 solver.cpp:228] Iteration 300, loss = 0.06956
I0209 01:59:25.217077 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 01:59:25.217084 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.06956 (* 1 = 0.06956 loss)
I0209 01:59:25.217092 14948 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0209 02:00:18.895264 14948 solver.cpp:228] Iteration 350, loss = 0.0579155
I0209 02:00:18.895294 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 02:00:18.895303 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0978983 (* 1 = 0.0978983 loss)
I0209 02:00:18.895309 14948 sgd_solver.cpp:106] Iteration 350, lr = 0.001
>>> 2017-02-09 02:01:11.113948 Begin model classification tests
>>> 2017-02-09 02:01:29.089306 Iteration 400 mean classification accuracy (rgb)  0.84686774942
>>> 2017-02-09 02:01:29.089337 Iteration 400 mean classification accuracy (depth) 0.84686774942
>>> 2017-02-09 02:01:29.089345 Iteration 400 mean classification accuracy (rgbd)  0.84686774942
>>> 2017-02-09 02:01:29.089351 Iteration 400 mean testing loss (rgb) 0.752793841744
>>> 2017-02-09 02:01:29.089363 Iteration 400 mean testing loss (depth) 0.752793841744
>>> 2017-02-09 02:01:29.089380 Iteration 400 mean testing loss (rgbd) 0.752793841744
>>> 2017-02-09 02:01:29.089398 Iteration 400 mean confusion matrix
[ 0.98571429  0.97391304  0.76785714  0.          0.6         0.91176471
  0.85185185  0.95        0.27272727  0.93939394  0.83333333]
I0209 02:01:30.138726 14948 solver.cpp:228] Iteration 400, loss = 0.118143
I0209 02:01:30.138754 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 02:01:30.138762 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.118143 (* 1 = 0.118143 loss)
I0209 02:01:30.138769 14948 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0209 02:02:23.839191 14948 solver.cpp:228] Iteration 450, loss = 0.0533334
I0209 02:02:23.839221 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:02:23.839228 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00639489 (* 1 = 0.00639489 loss)
I0209 02:02:23.839234 14948 sgd_solver.cpp:106] Iteration 450, lr = 0.001
>>> 2017-02-09 02:03:16.446873 Begin model classification tests
>>> 2017-02-09 02:03:34.427392 Iteration 500 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:03:34.427423 Iteration 500 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:03:34.427431 Iteration 500 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:03:34.427437 Iteration 500 mean testing loss (rgb) 0.779455809415
>>> 2017-02-09 02:03:34.427448 Iteration 500 mean testing loss (depth) 0.779455809415
>>> 2017-02-09 02:03:34.427465 Iteration 500 mean testing loss (rgbd) 0.779455809415
>>> 2017-02-09 02:03:34.427471 Iteration 500 mean confusion matrix
[ 0.98571429  0.97391304  0.76785714  0.          0.6         0.94117647
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:03:35.504573 14948 solver.cpp:228] Iteration 500, loss = 0.0336214
I0209 02:03:35.504601 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:03:35.504608 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0336214 (* 1 = 0.0336214 loss)
I0209 02:03:35.504616 14948 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0209 02:04:29.823781 14948 solver.cpp:228] Iteration 550, loss = 0.0548494
I0209 02:04:29.823808 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:04:29.823817 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0600197 (* 1 = 0.0600197 loss)
I0209 02:04:29.823822 14948 sgd_solver.cpp:106] Iteration 550, lr = 0.001
>>> 2017-02-09 02:05:23.376940 Begin model classification tests
>>> 2017-02-09 02:05:41.345355 Iteration 600 mean classification accuracy (rgb)  0.84686774942
>>> 2017-02-09 02:05:41.345387 Iteration 600 mean classification accuracy (depth) 0.84686774942
>>> 2017-02-09 02:05:41.345395 Iteration 600 mean classification accuracy (rgbd)  0.84686774942
>>> 2017-02-09 02:05:41.345401 Iteration 600 mean testing loss (rgb) 0.80728246163
>>> 2017-02-09 02:05:41.345413 Iteration 600 mean testing loss (depth) 0.80728246163
>>> 2017-02-09 02:05:41.345433 Iteration 600 mean testing loss (rgbd) 0.80728246163
>>> 2017-02-09 02:05:41.345453 Iteration 600 mean confusion matrix
[ 0.98571429  0.9826087   0.75        0.          0.6         0.94117647
  0.85185185  0.95        0.27272727  0.90909091  0.83333333]
I0209 02:05:42.420989 14948 solver.cpp:228] Iteration 600, loss = 0.0510613
I0209 02:05:42.421018 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:05:42.421026 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0510613 (* 1 = 0.0510613 loss)
I0209 02:05:42.421033 14948 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0209 02:06:37.379427 14948 solver.cpp:228] Iteration 650, loss = 0.0490183
I0209 02:06:37.379468 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:06:37.379477 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0506078 (* 1 = 0.0506078 loss)
I0209 02:06:37.379498 14948 sgd_solver.cpp:106] Iteration 650, lr = 0.001
>>> 2017-02-09 02:07:30.615388 Begin model classification tests
>>> 2017-02-09 02:07:48.574301 Iteration 700 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:07:48.574342 Iteration 700 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:07:48.574351 Iteration 700 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:07:48.574357 Iteration 700 mean testing loss (rgb) 0.815264254603
>>> 2017-02-09 02:07:48.574378 Iteration 700 mean testing loss (depth) 0.815264254603
>>> 2017-02-09 02:07:48.574387 Iteration 700 mean testing loss (rgbd) 0.815264254603
>>> 2017-02-09 02:07:48.574402 Iteration 700 mean confusion matrix
[ 0.98571429  0.9826087   0.76785714  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:07:49.713893 14948 solver.cpp:228] Iteration 700, loss = 0.0103969
I0209 02:07:49.713922 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:07:49.713929 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0103969 (* 1 = 0.0103969 loss)
I0209 02:07:49.713937 14948 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0209 02:08:44.043416 14948 solver.cpp:228] Iteration 750, loss = 0.0485632
I0209 02:08:44.043445 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 02:08:44.043453 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0440179 (* 1 = 0.0440179 loss)
I0209 02:08:44.043460 14948 sgd_solver.cpp:106] Iteration 750, lr = 0.001
>>> 2017-02-09 02:09:37.423928 Begin model classification tests
>>> 2017-02-09 02:09:55.379368 Iteration 800 mean classification accuracy (rgb)  0.849187935035
>>> 2017-02-09 02:09:55.379400 Iteration 800 mean classification accuracy (depth) 0.849187935035
>>> 2017-02-09 02:09:55.379408 Iteration 800 mean classification accuracy (rgbd)  0.849187935035
>>> 2017-02-09 02:09:55.379414 Iteration 800 mean testing loss (rgb) 0.819092498539
>>> 2017-02-09 02:09:55.379425 Iteration 800 mean testing loss (depth) 0.819092498539
>>> 2017-02-09 02:09:55.379441 Iteration 800 mean testing loss (rgbd) 0.819092498539
>>> 2017-02-09 02:09:55.379450 Iteration 800 mean confusion matrix
[ 0.98571429  0.97391304  0.76785714  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:09:56.532244 14948 solver.cpp:228] Iteration 800, loss = 0.0203275
I0209 02:09:56.532272 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:09:56.532280 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0203275 (* 1 = 0.0203275 loss)
I0209 02:09:56.532287 14948 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0209 02:10:52.649852 14948 solver.cpp:228] Iteration 850, loss = 0.0438347
I0209 02:10:52.649876 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:10:52.649896 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0189797 (* 1 = 0.0189797 loss)
I0209 02:10:52.649902 14948 sgd_solver.cpp:106] Iteration 850, lr = 0.001
>>> 2017-02-09 02:11:47.902229 Begin model classification tests
>>> 2017-02-09 02:12:05.855465 Iteration 900 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:12:05.855499 Iteration 900 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:12:05.855507 Iteration 900 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:12:05.855513 Iteration 900 mean testing loss (rgb) 0.833249731852
>>> 2017-02-09 02:12:05.855525 Iteration 900 mean testing loss (depth) 0.833249731852
>>> 2017-02-09 02:12:05.855545 Iteration 900 mean testing loss (rgbd) 0.833249731852
>>> 2017-02-09 02:12:05.855576 Iteration 900 mean confusion matrix
[ 0.98571429  0.9826087   0.76785714  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:12:06.999202 14948 solver.cpp:228] Iteration 900, loss = 0.0314027
I0209 02:12:06.999229 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:12:06.999238 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0314027 (* 1 = 0.0314027 loss)
I0209 02:12:06.999245 14948 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0209 02:13:02.889081 14948 solver.cpp:228] Iteration 950, loss = 0.0456268
I0209 02:13:02.889108 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:13:02.889117 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0424727 (* 1 = 0.0424727 loss)
I0209 02:13:02.889123 14948 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0209 02:13:56.800842 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_1000.caffemodel
I0209 02:14:12.297137 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_1000.solverstate
>>> 2017-02-09 02:14:19.732911 Begin model classification tests
>>> 2017-02-09 02:14:37.376543 Iteration 1000 mean classification accuracy (rgb)  0.849187935035
>>> 2017-02-09 02:14:37.376574 Iteration 1000 mean classification accuracy (depth) 0.849187935035
>>> 2017-02-09 02:14:37.376582 Iteration 1000 mean classification accuracy (rgbd)  0.849187935035
>>> 2017-02-09 02:14:37.376588 Iteration 1000 mean testing loss (rgb) 0.844830436734
>>> 2017-02-09 02:14:37.376599 Iteration 1000 mean testing loss (depth) 0.844830436734
>>> 2017-02-09 02:14:37.376616 Iteration 1000 mean testing loss (rgbd) 0.844830436734
>>> 2017-02-09 02:14:37.376622 Iteration 1000 mean confusion matrix
[ 0.98571429  0.96521739  0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:14:38.606818 14948 solver.cpp:228] Iteration 1000, loss = 0.00813324
I0209 02:14:38.606848 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:14:38.606856 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00813324 (* 1 = 0.00813324 loss)
I0209 02:14:38.606863 14948 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0209 02:15:35.278690 14948 solver.cpp:228] Iteration 1050, loss = 0.0384759
I0209 02:15:35.278719 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:15:35.278728 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0148643 (* 1 = 0.0148643 loss)
I0209 02:15:35.278734 14948 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
>>> 2017-02-09 02:16:30.208625 Begin model classification tests
>>> 2017-02-09 02:16:48.411628 Iteration 1100 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:16:48.411659 Iteration 1100 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:16:48.411667 Iteration 1100 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:16:48.411673 Iteration 1100 mean testing loss (rgb) 0.85559872597
>>> 2017-02-09 02:16:48.411685 Iteration 1100 mean testing loss (depth) 0.85559872597
>>> 2017-02-09 02:16:48.411691 Iteration 1100 mean testing loss (rgbd) 0.85559872597
>>> 2017-02-09 02:16:48.411697 Iteration 1100 mean confusion matrix
[ 0.98571429  0.97391304  0.76785714  0.          0.6         0.94117647
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:16:49.473294 14948 solver.cpp:228] Iteration 1100, loss = 0.0361864
I0209 02:16:49.473322 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 02:16:49.473331 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0361864 (* 1 = 0.0361864 loss)
I0209 02:16:49.473337 14948 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0209 02:17:45.595934 14948 solver.cpp:228] Iteration 1150, loss = 0.0491685
I0209 02:17:45.595960 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.9375
I0209 02:17:45.595969 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.112248 (* 1 = 0.112248 loss)
I0209 02:17:45.595975 14948 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
>>> 2017-02-09 02:18:40.367481 Begin model classification tests
>>> 2017-02-09 02:18:58.349693 Iteration 1200 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:18:58.349726 Iteration 1200 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:18:58.349741 Iteration 1200 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:18:58.349768 Iteration 1200 mean testing loss (rgb) 0.855774655268
>>> 2017-02-09 02:18:58.349780 Iteration 1200 mean testing loss (depth) 0.855774655268
>>> 2017-02-09 02:18:58.349786 Iteration 1200 mean testing loss (rgbd) 0.855774655268
>>> 2017-02-09 02:18:58.349793 Iteration 1200 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:18:59.495486 14948 solver.cpp:228] Iteration 1200, loss = 0.0310253
I0209 02:18:59.495517 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:18:59.495525 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0310253 (* 1 = 0.0310253 loss)
I0209 02:18:59.495532 14948 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0209 02:19:55.300588 14948 solver.cpp:228] Iteration 1250, loss = 0.0433839
I0209 02:19:55.300617 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:19:55.300626 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0205708 (* 1 = 0.0205708 loss)
I0209 02:19:55.300633 14948 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
>>> 2017-02-09 02:20:52.269916 Begin model classification tests
>>> 2017-02-09 02:21:10.284573 Iteration 1300 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:21:10.284604 Iteration 1300 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:21:10.284612 Iteration 1300 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:21:10.284618 Iteration 1300 mean testing loss (rgb) 0.86937533833
>>> 2017-02-09 02:21:10.284629 Iteration 1300 mean testing loss (depth) 0.86937533833
>>> 2017-02-09 02:21:10.284645 Iteration 1300 mean testing loss (rgbd) 0.86937533833
>>> 2017-02-09 02:21:10.284662 Iteration 1300 mean confusion matrix
[ 0.98571429  0.9826087   0.76785714  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:21:11.448992 14948 solver.cpp:228] Iteration 1300, loss = 0.0757242
I0209 02:21:11.449020 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 02:21:11.449029 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0757242 (* 1 = 0.0757242 loss)
I0209 02:21:11.449035 14948 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0209 02:22:09.289904 14948 solver.cpp:228] Iteration 1350, loss = 0.0459323
I0209 02:22:09.289930 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:22:09.289938 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0516261 (* 1 = 0.0516261 loss)
I0209 02:22:09.289945 14948 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
>>> 2017-02-09 02:23:05.820511 Begin model classification tests
>>> 2017-02-09 02:23:23.811566 Iteration 1400 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 02:23:23.811598 Iteration 1400 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 02:23:23.811606 Iteration 1400 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 02:23:23.811612 Iteration 1400 mean testing loss (rgb) 0.885173601837
>>> 2017-02-09 02:23:23.811623 Iteration 1400 mean testing loss (depth) 0.885173601837
>>> 2017-02-09 02:23:23.811640 Iteration 1400 mean testing loss (rgbd) 0.885173601837
>>> 2017-02-09 02:23:23.811656 Iteration 1400 mean confusion matrix
[ 0.98571429  0.9826087   0.76785714  0.          0.66666667  0.94117647
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:23:25.041146 14948 solver.cpp:228] Iteration 1400, loss = 0.0305417
I0209 02:23:25.041175 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:23:25.041184 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0305417 (* 1 = 0.0305417 loss)
I0209 02:23:25.041191 14948 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0209 02:24:22.544111 14948 solver.cpp:228] Iteration 1450, loss = 0.0456605
I0209 02:24:22.544137 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 02:24:22.544147 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0380652 (* 1 = 0.0380652 loss)
I0209 02:24:22.544152 14948 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
>>> 2017-02-09 02:25:15.912093 Begin model classification tests
>>> 2017-02-09 02:25:33.886790 Iteration 1500 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:25:33.886821 Iteration 1500 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:25:33.886829 Iteration 1500 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:25:33.886835 Iteration 1500 mean testing loss (rgb) 0.881183179777
>>> 2017-02-09 02:25:33.886846 Iteration 1500 mean testing loss (depth) 0.881183179777
>>> 2017-02-09 02:25:33.886863 Iteration 1500 mean testing loss (rgbd) 0.881183179777
>>> 2017-02-09 02:25:33.886879 Iteration 1500 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:25:34.922958 14948 solver.cpp:228] Iteration 1500, loss = 0.0315293
I0209 02:25:34.922986 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:25:34.922994 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0315293 (* 1 = 0.0315293 loss)
I0209 02:25:34.923001 14948 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0209 02:26:28.046514 14948 solver.cpp:228] Iteration 1550, loss = 0.037718
I0209 02:26:28.046543 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 02:26:28.046552 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0862245 (* 1 = 0.0862245 loss)
I0209 02:26:28.046560 14948 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
>>> 2017-02-09 02:27:20.131043 Begin model classification tests
>>> 2017-02-09 02:27:38.134095 Iteration 1600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 02:27:38.134125 Iteration 1600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 02:27:38.134133 Iteration 1600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 02:27:38.134139 Iteration 1600 mean testing loss (rgb) 0.892441739129
>>> 2017-02-09 02:27:38.134163 Iteration 1600 mean testing loss (depth) 0.892441739129
>>> 2017-02-09 02:27:38.134180 Iteration 1600 mean testing loss (rgbd) 0.892441739129
>>> 2017-02-09 02:27:38.134188 Iteration 1600 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.6         0.94117647
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:27:39.214203 14948 solver.cpp:228] Iteration 1600, loss = 0.0303497
I0209 02:27:39.214231 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:27:39.214241 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0303497 (* 1 = 0.0303497 loss)
I0209 02:27:39.214248 14948 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0209 02:28:32.765702 14948 solver.cpp:228] Iteration 1650, loss = 0.0434652
I0209 02:28:32.765732 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 02:28:32.765758 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0990034 (* 1 = 0.0990034 loss)
I0209 02:28:32.765765 14948 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
>>> 2017-02-09 02:29:25.335299 Begin model classification tests
>>> 2017-02-09 02:29:43.380595 Iteration 1700 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:29:43.380627 Iteration 1700 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:29:43.380634 Iteration 1700 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:29:43.380640 Iteration 1700 mean testing loss (rgb) 0.913958727978
>>> 2017-02-09 02:29:43.380650 Iteration 1700 mean testing loss (depth) 0.913958727978
>>> 2017-02-09 02:29:43.380656 Iteration 1700 mean testing loss (rgbd) 0.913958727978
>>> 2017-02-09 02:29:43.380662 Iteration 1700 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:29:44.420450 14948 solver.cpp:228] Iteration 1700, loss = 0.0286348
I0209 02:29:44.420480 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:29:44.420487 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0286348 (* 1 = 0.0286348 loss)
I0209 02:29:44.420493 14948 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0209 02:30:37.582790 14948 solver.cpp:228] Iteration 1750, loss = 0.0449646
I0209 02:30:37.582818 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 02:30:37.582834 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0651742 (* 1 = 0.0651742 loss)
I0209 02:30:37.582859 14948 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
>>> 2017-02-09 02:31:29.653697 Begin model classification tests
>>> 2017-02-09 02:31:47.623539 Iteration 1800 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 02:31:47.623570 Iteration 1800 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 02:31:47.623578 Iteration 1800 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 02:31:47.623584 Iteration 1800 mean testing loss (rgb) 0.915066755585
>>> 2017-02-09 02:31:47.623595 Iteration 1800 mean testing loss (depth) 0.915066755585
>>> 2017-02-09 02:31:47.623612 Iteration 1800 mean testing loss (rgbd) 0.915066755585
>>> 2017-02-09 02:31:47.623628 Iteration 1800 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.66666667  0.94117647
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:31:48.676407 14948 solver.cpp:228] Iteration 1800, loss = 0.0291497
I0209 02:31:48.676434 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:31:48.676443 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0291497 (* 1 = 0.0291497 loss)
I0209 02:31:48.676450 14948 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0209 02:32:41.897622 14948 solver.cpp:228] Iteration 1850, loss = 0.0369205
I0209 02:32:41.897650 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:32:41.897658 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.02956 (* 1 = 0.02956 loss)
I0209 02:32:41.897665 14948 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
>>> 2017-02-09 02:33:33.842882 Begin model classification tests
>>> 2017-02-09 02:33:51.812451 Iteration 1900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 02:33:51.812484 Iteration 1900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 02:33:51.812493 Iteration 1900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 02:33:51.812502 Iteration 1900 mean testing loss (rgb) 0.91465517975
>>> 2017-02-09 02:33:51.812528 Iteration 1900 mean testing loss (depth) 0.91465517975
>>> 2017-02-09 02:33:51.812549 Iteration 1900 mean testing loss (rgbd) 0.91465517975
>>> 2017-02-09 02:33:51.812569 Iteration 1900 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.66666667  0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:33:52.841774 14948 solver.cpp:228] Iteration 1900, loss = 0.106977
I0209 02:33:52.841802 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.90625
I0209 02:33:52.841811 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.106977 (* 1 = 0.106977 loss)
I0209 02:33:52.841817 14948 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0209 02:34:45.916304 14948 solver.cpp:228] Iteration 1950, loss = 0.052741
I0209 02:34:45.916332 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:34:45.916342 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00896041 (* 1 = 0.00896041 loss)
I0209 02:34:45.916347 14948 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0209 02:35:37.699362 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_2000.caffemodel
I0209 02:36:14.883203 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_2000.solverstate
>>> 2017-02-09 02:36:21.778015 Begin model classification tests
>>> 2017-02-09 02:36:39.398480 Iteration 2000 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:36:39.398511 Iteration 2000 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:36:39.398520 Iteration 2000 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:36:39.398529 Iteration 2000 mean testing loss (rgb) 0.923882933825
>>> 2017-02-09 02:36:39.398560 Iteration 2000 mean testing loss (depth) 0.923882933825
>>> 2017-02-09 02:36:39.398567 Iteration 2000 mean testing loss (rgbd) 0.923882933825
>>> 2017-02-09 02:36:39.398575 Iteration 2000 mean confusion matrix
[ 0.98571429  0.96521739  0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.96969697  0.83333333]
I0209 02:36:40.603674 14948 solver.cpp:228] Iteration 2000, loss = 0.0907349
I0209 02:36:40.603704 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 02:36:40.603714 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0907349 (* 1 = 0.0907349 loss)
I0209 02:36:40.603721 14948 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0209 02:37:38.865842 14948 solver.cpp:228] Iteration 2050, loss = 0.049426
I0209 02:37:38.865870 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:37:38.865878 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0132502 (* 1 = 0.0132502 loss)
I0209 02:37:38.865885 14948 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
>>> 2017-02-09 02:38:35.720246 Begin model classification tests
>>> 2017-02-09 02:38:53.913476 Iteration 2100 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:38:53.913513 Iteration 2100 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:38:53.913539 Iteration 2100 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:38:53.913548 Iteration 2100 mean testing loss (rgb) 0.945560783628
>>> 2017-02-09 02:38:53.913559 Iteration 2100 mean testing loss (depth) 0.945560783628
>>> 2017-02-09 02:38:53.913575 Iteration 2100 mean testing loss (rgbd) 0.945560783628
>>> 2017-02-09 02:38:53.913591 Iteration 2100 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:38:55.080142 14948 solver.cpp:228] Iteration 2100, loss = 0.0109373
I0209 02:38:55.080170 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:38:55.080178 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0109373 (* 1 = 0.0109373 loss)
I0209 02:38:55.080185 14948 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0209 02:39:52.432555 14948 solver.cpp:228] Iteration 2150, loss = 0.0438726
I0209 02:39:52.432584 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:39:52.432592 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0135052 (* 1 = 0.0135052 loss)
I0209 02:39:52.432598 14948 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
>>> 2017-02-09 02:40:48.607763 Begin model classification tests
>>> 2017-02-09 02:41:06.667491 Iteration 2200 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:41:06.667523 Iteration 2200 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:41:06.667531 Iteration 2200 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:41:06.667537 Iteration 2200 mean testing loss (rgb) 0.939560662786
>>> 2017-02-09 02:41:06.667546 Iteration 2200 mean testing loss (depth) 0.939560662786
>>> 2017-02-09 02:41:06.667552 Iteration 2200 mean testing loss (rgbd) 0.939560662786
>>> 2017-02-09 02:41:06.667558 Iteration 2200 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:41:07.770704 14948 solver.cpp:228] Iteration 2200, loss = 0.0168117
I0209 02:41:07.770737 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:41:07.770746 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0168117 (* 1 = 0.0168117 loss)
I0209 02:41:07.770764 14948 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0209 02:42:05.601783 14948 solver.cpp:228] Iteration 2250, loss = 0.0344105
I0209 02:42:05.601810 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:42:05.601819 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0324992 (* 1 = 0.0324992 loss)
I0209 02:42:05.601825 14948 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
>>> 2017-02-09 02:43:02.526234 Begin model classification tests
>>> 2017-02-09 02:43:20.457389 Iteration 2300 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:43:20.457422 Iteration 2300 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:43:20.457430 Iteration 2300 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:43:20.457436 Iteration 2300 mean testing loss (rgb) 0.940905080889
>>> 2017-02-09 02:43:20.457449 Iteration 2300 mean testing loss (depth) 0.940905080889
>>> 2017-02-09 02:43:20.457469 Iteration 2300 mean testing loss (rgbd) 0.940905080889
>>> 2017-02-09 02:43:20.457489 Iteration 2300 mean confusion matrix
[ 0.98571429  0.97391304  0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:43:21.611398 14948 solver.cpp:228] Iteration 2300, loss = 0.0246436
I0209 02:43:21.611426 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:43:21.611434 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0246436 (* 1 = 0.0246436 loss)
I0209 02:43:21.611440 14948 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0209 02:44:20.459512 14948 solver.cpp:228] Iteration 2350, loss = 0.0346036
I0209 02:44:20.459540 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:44:20.459549 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0406923 (* 1 = 0.0406923 loss)
I0209 02:44:20.459555 14948 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
>>> 2017-02-09 02:45:13.800455 Begin model classification tests
>>> 2017-02-09 02:45:31.830715 Iteration 2400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 02:45:31.830746 Iteration 2400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 02:45:31.830753 Iteration 2400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 02:45:31.830760 Iteration 2400 mean testing loss (rgb) 0.948827777015
>>> 2017-02-09 02:45:31.830771 Iteration 2400 mean testing loss (depth) 0.948827777015
>>> 2017-02-09 02:45:31.830788 Iteration 2400 mean testing loss (rgbd) 0.948827777015
>>> 2017-02-09 02:45:31.830805 Iteration 2400 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 02:45:32.884582 14948 solver.cpp:228] Iteration 2400, loss = 0.0464632
I0209 02:45:32.884608 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:45:32.884616 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0464632 (* 1 = 0.0464632 loss)
I0209 02:45:32.884623 14948 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0209 02:46:27.248796 14948 solver.cpp:228] Iteration 2450, loss = 0.0429482
I0209 02:46:27.248826 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:46:27.248834 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0294997 (* 1 = 0.0294997 loss)
I0209 02:46:27.248841 14948 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
>>> 2017-02-09 02:47:23.653981 Begin model classification tests
>>> 2017-02-09 02:47:41.686424 Iteration 2500 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:47:41.686456 Iteration 2500 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:47:41.686465 Iteration 2500 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:47:41.686471 Iteration 2500 mean testing loss (rgb) 0.947883236349
>>> 2017-02-09 02:47:41.686482 Iteration 2500 mean testing loss (depth) 0.947883236349
>>> 2017-02-09 02:47:41.686499 Iteration 2500 mean testing loss (rgbd) 0.947883236349
>>> 2017-02-09 02:47:41.686516 Iteration 2500 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:47:42.721560 14948 solver.cpp:228] Iteration 2500, loss = 0.0463364
I0209 02:47:42.721587 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:47:42.721596 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0463364 (* 1 = 0.0463364 loss)
I0209 02:47:42.721602 14948 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0209 02:48:36.400457 14948 solver.cpp:228] Iteration 2550, loss = 0.0398867
I0209 02:48:36.400487 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:48:36.400496 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0467639 (* 1 = 0.0467639 loss)
I0209 02:48:36.400502 14948 sgd_solver.cpp:106] Iteration 2550, lr = 0.001
>>> 2017-02-09 02:49:28.585801 Begin model classification tests
>>> 2017-02-09 02:49:46.566704 Iteration 2600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 02:49:46.566735 Iteration 2600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 02:49:46.566743 Iteration 2600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 02:49:46.566749 Iteration 2600 mean testing loss (rgb) 0.954153689487
>>> 2017-02-09 02:49:46.566760 Iteration 2600 mean testing loss (depth) 0.954153689487
>>> 2017-02-09 02:49:46.566777 Iteration 2600 mean testing loss (rgbd) 0.954153689487
>>> 2017-02-09 02:49:46.566794 Iteration 2600 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.66666667  0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:49:47.600268 14948 solver.cpp:228] Iteration 2600, loss = 0.00781968
I0209 02:49:47.600296 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:49:47.600316 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00781968 (* 1 = 0.00781968 loss)
I0209 02:49:47.600322 14948 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0209 02:50:40.904582 14948 solver.cpp:228] Iteration 2650, loss = 0.0332906
I0209 02:50:40.904610 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:50:40.904619 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0143431 (* 1 = 0.0143431 loss)
I0209 02:50:40.904625 14948 sgd_solver.cpp:106] Iteration 2650, lr = 0.001
>>> 2017-02-09 02:51:32.985134 Begin model classification tests
>>> 2017-02-09 02:51:50.936630 Iteration 2700 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:51:50.936660 Iteration 2700 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:51:50.936668 Iteration 2700 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:51:50.936674 Iteration 2700 mean testing loss (rgb) 0.95313196806
>>> 2017-02-09 02:51:50.936685 Iteration 2700 mean testing loss (depth) 0.95313196806
>>> 2017-02-09 02:51:50.936702 Iteration 2700 mean testing loss (rgbd) 0.95313196806
>>> 2017-02-09 02:51:50.936710 Iteration 2700 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:51:51.995893 14948 solver.cpp:228] Iteration 2700, loss = 0.0169075
I0209 02:51:51.995920 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:51:51.995929 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0169075 (* 1 = 0.0169075 loss)
I0209 02:51:51.995934 14948 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0209 02:52:45.377837 14948 solver.cpp:228] Iteration 2750, loss = 0.0347861
I0209 02:52:45.377866 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:52:45.377873 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0167574 (* 1 = 0.0167574 loss)
I0209 02:52:45.377879 14948 sgd_solver.cpp:106] Iteration 2750, lr = 0.001
>>> 2017-02-09 02:53:38.877850 Begin model classification tests
>>> 2017-02-09 02:53:56.830789 Iteration 2800 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:53:56.830819 Iteration 2800 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:53:56.830827 Iteration 2800 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:53:56.830833 Iteration 2800 mean testing loss (rgb) 0.953042469649
>>> 2017-02-09 02:53:56.830845 Iteration 2800 mean testing loss (depth) 0.953042469649
>>> 2017-02-09 02:53:56.830862 Iteration 2800 mean testing loss (rgbd) 0.953042469649
>>> 2017-02-09 02:53:56.830878 Iteration 2800 mean confusion matrix
[ 1.          0.9826087   0.76785714  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:53:57.867929 14948 solver.cpp:228] Iteration 2800, loss = 0.0306644
I0209 02:53:57.867959 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:53:57.867980 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0306644 (* 1 = 0.0306644 loss)
I0209 02:53:57.867986 14948 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0209 02:54:51.625864 14948 solver.cpp:228] Iteration 2850, loss = 0.0381133
I0209 02:54:51.625891 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 02:54:51.625900 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0864325 (* 1 = 0.0864325 loss)
I0209 02:54:51.625906 14948 sgd_solver.cpp:106] Iteration 2850, lr = 0.001
>>> 2017-02-09 02:55:44.480743 Begin model classification tests
>>> 2017-02-09 02:56:02.355920 Iteration 2900 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:56:02.355971 Iteration 2900 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:56:02.355978 Iteration 2900 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:56:02.355984 Iteration 2900 mean testing loss (rgb) 0.953816122257
>>> 2017-02-09 02:56:02.355997 Iteration 2900 mean testing loss (depth) 0.953816122257
>>> 2017-02-09 02:56:02.356017 Iteration 2900 mean testing loss (rgbd) 0.953816122257
>>> 2017-02-09 02:56:02.356037 Iteration 2900 mean confusion matrix
[ 1.          0.9826087   0.76785714  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:56:03.391273 14948 solver.cpp:228] Iteration 2900, loss = 0.0253573
I0209 02:56:03.391304 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:56:03.391311 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0253573 (* 1 = 0.0253573 loss)
I0209 02:56:03.391317 14948 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0209 02:56:56.643106 14948 solver.cpp:228] Iteration 2950, loss = 0.0332636
I0209 02:56:56.643133 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 02:56:56.643142 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0533411 (* 1 = 0.0533411 loss)
I0209 02:56:56.643148 14948 sgd_solver.cpp:106] Iteration 2950, lr = 0.001
I0209 02:57:48.379990 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_3000.caffemodel
I0209 02:58:37.571674 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_3000.solverstate
>>> 2017-02-09 02:58:45.432016 Begin model classification tests
>>> 2017-02-09 02:59:03.052460 Iteration 3000 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 02:59:03.052490 Iteration 3000 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 02:59:03.052498 Iteration 3000 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 02:59:03.052504 Iteration 3000 mean testing loss (rgb) 0.947970763396
>>> 2017-02-09 02:59:03.052515 Iteration 3000 mean testing loss (depth) 0.947970763396
>>> 2017-02-09 02:59:03.052532 Iteration 3000 mean testing loss (rgbd) 0.947970763396
>>> 2017-02-09 02:59:03.052549 Iteration 3000 mean confusion matrix
[ 0.98571429  0.9826087   0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 02:59:04.083089 14948 solver.cpp:228] Iteration 3000, loss = 0.01551
I0209 02:59:04.083119 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:59:04.083127 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.01551 (* 1 = 0.01551 loss)
I0209 02:59:04.083134 14948 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0209 02:59:57.110265 14948 solver.cpp:228] Iteration 3050, loss = 0.0402367
I0209 02:59:57.110296 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 02:59:57.110303 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0221619 (* 1 = 0.0221619 loss)
I0209 02:59:57.110311 14948 sgd_solver.cpp:106] Iteration 3050, lr = 0.001
>>> 2017-02-09 03:00:48.928133 Begin model classification tests
>>> 2017-02-09 03:01:06.913893 Iteration 3100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:01:06.913923 Iteration 3100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:01:06.913931 Iteration 3100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:01:06.913937 Iteration 3100 mean testing loss (rgb) 0.945329422756
>>> 2017-02-09 03:01:06.913948 Iteration 3100 mean testing loss (depth) 0.945329422756
>>> 2017-02-09 03:01:06.913965 Iteration 3100 mean testing loss (rgbd) 0.945329422756
>>> 2017-02-09 03:01:06.913974 Iteration 3100 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.96969697  0.83333333]
I0209 03:01:07.949579 14948 solver.cpp:228] Iteration 3100, loss = 0.0407533
I0209 03:01:07.949609 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 03:01:07.949630 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0407533 (* 1 = 0.0407533 loss)
I0209 03:01:07.949637 14948 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0209 03:02:01.069936 14948 solver.cpp:228] Iteration 3150, loss = 0.0288497
I0209 03:02:01.069964 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:02:01.069973 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.015801 (* 1 = 0.015801 loss)
I0209 03:02:01.069979 14948 sgd_solver.cpp:106] Iteration 3150, lr = 0.001
>>> 2017-02-09 03:02:52.918423 Begin model classification tests
>>> 2017-02-09 03:03:10.884746 Iteration 3200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:03:10.884775 Iteration 3200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:03:10.884783 Iteration 3200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:03:10.884789 Iteration 3200 mean testing loss (rgb) 0.965168746128
>>> 2017-02-09 03:03:10.884801 Iteration 3200 mean testing loss (depth) 0.965168746128
>>> 2017-02-09 03:03:10.884818 Iteration 3200 mean testing loss (rgbd) 0.965168746128
>>> 2017-02-09 03:03:10.884834 Iteration 3200 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.96969697  0.83333333]
I0209 03:03:11.915279 14948 solver.cpp:228] Iteration 3200, loss = 0.0409782
I0209 03:03:11.915307 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:03:11.915315 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0409782 (* 1 = 0.0409782 loss)
I0209 03:03:11.915321 14948 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0209 03:04:04.877933 14948 solver.cpp:228] Iteration 3250, loss = 0.0350176
I0209 03:04:04.877961 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 03:04:04.877969 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0772396 (* 1 = 0.0772396 loss)
I0209 03:04:04.877976 14948 sgd_solver.cpp:106] Iteration 3250, lr = 0.001
>>> 2017-02-09 03:04:56.586924 Begin model classification tests
>>> 2017-02-09 03:05:14.561680 Iteration 3300 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:05:14.561710 Iteration 3300 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:05:14.561718 Iteration 3300 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:05:14.561724 Iteration 3300 mean testing loss (rgb) 0.964278204879
>>> 2017-02-09 03:05:14.561735 Iteration 3300 mean testing loss (depth) 0.964278204879
>>> 2017-02-09 03:05:14.561752 Iteration 3300 mean testing loss (rgbd) 0.964278204879
>>> 2017-02-09 03:05:14.561761 Iteration 3300 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:05:15.594413 14948 solver.cpp:228] Iteration 3300, loss = 0.0550023
I0209 03:05:15.594439 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 03:05:15.594447 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0550023 (* 1 = 0.0550023 loss)
I0209 03:05:15.594454 14948 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0209 03:06:08.399963 14948 solver.cpp:228] Iteration 3350, loss = 0.0340589
I0209 03:06:08.399991 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:06:08.400001 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0086126 (* 1 = 0.0086126 loss)
I0209 03:06:08.400007 14948 sgd_solver.cpp:106] Iteration 3350, lr = 0.001
>>> 2017-02-09 03:07:00.101120 Begin model classification tests
>>> 2017-02-09 03:07:18.083639 Iteration 3400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:07:18.083668 Iteration 3400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:07:18.083676 Iteration 3400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:07:18.083693 Iteration 3400 mean testing loss (rgb) 0.978242120094
>>> 2017-02-09 03:07:18.083714 Iteration 3400 mean testing loss (depth) 0.978242120094
>>> 2017-02-09 03:07:18.083721 Iteration 3400 mean testing loss (rgbd) 0.978242120094
>>> 2017-02-09 03:07:18.083728 Iteration 3400 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:07:19.117693 14948 solver.cpp:228] Iteration 3400, loss = 0.0400031
I0209 03:07:19.117722 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:07:19.117730 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0400031 (* 1 = 0.0400031 loss)
I0209 03:07:19.117736 14948 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0209 03:08:11.871109 14948 solver.cpp:228] Iteration 3450, loss = 0.0354001
I0209 03:08:11.871135 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 03:08:11.871145 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0584073 (* 1 = 0.0584073 loss)
I0209 03:08:11.871151 14948 sgd_solver.cpp:106] Iteration 3450, lr = 0.001
>>> 2017-02-09 03:09:03.836675 Begin model classification tests
>>> 2017-02-09 03:09:21.745832 Iteration 3500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:09:21.745872 Iteration 3500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:09:21.745883 Iteration 3500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:09:21.745889 Iteration 3500 mean testing loss (rgb) 0.983048097074
>>> 2017-02-09 03:09:21.745899 Iteration 3500 mean testing loss (depth) 0.983048097074
>>> 2017-02-09 03:09:21.745905 Iteration 3500 mean testing loss (rgbd) 0.983048097074
>>> 2017-02-09 03:09:21.745911 Iteration 3500 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:09:22.791649 14948 solver.cpp:228] Iteration 3500, loss = 0.0270935
I0209 03:09:22.791674 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:09:22.791683 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0270935 (* 1 = 0.0270935 loss)
I0209 03:09:22.791689 14948 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0209 03:10:15.575261 14948 solver.cpp:228] Iteration 3550, loss = 0.0383433
I0209 03:10:15.575297 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:10:15.575307 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0157956 (* 1 = 0.0157956 loss)
I0209 03:10:15.575331 14948 sgd_solver.cpp:106] Iteration 3550, lr = 0.001
>>> 2017-02-09 03:11:07.319004 Begin model classification tests
>>> 2017-02-09 03:11:25.216203 Iteration 3600 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:11:25.216232 Iteration 3600 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:11:25.216239 Iteration 3600 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:11:25.216246 Iteration 3600 mean testing loss (rgb) 0.988362057754
>>> 2017-02-09 03:11:25.216257 Iteration 3600 mean testing loss (depth) 0.988362057754
>>> 2017-02-09 03:11:25.216274 Iteration 3600 mean testing loss (rgbd) 0.988362057754
>>> 2017-02-09 03:11:25.216280 Iteration 3600 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.36363636  0.93939394  0.83333333]
I0209 03:11:26.249699 14948 solver.cpp:228] Iteration 3600, loss = 0.0114301
I0209 03:11:26.249728 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:11:26.249737 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0114301 (* 1 = 0.0114301 loss)
I0209 03:11:26.249743 14948 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0209 03:12:19.035493 14948 solver.cpp:228] Iteration 3650, loss = 0.0303992
I0209 03:12:19.035521 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:12:19.035529 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0296532 (* 1 = 0.0296532 loss)
I0209 03:12:19.035536 14948 sgd_solver.cpp:106] Iteration 3650, lr = 0.001
>>> 2017-02-09 03:13:10.642648 Begin model classification tests
>>> 2017-02-09 03:13:28.611835 Iteration 3700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:13:28.611866 Iteration 3700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:13:28.611874 Iteration 3700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:13:28.611881 Iteration 3700 mean testing loss (rgb) 0.990366408216
>>> 2017-02-09 03:13:28.611893 Iteration 3700 mean testing loss (depth) 0.990366408216
>>> 2017-02-09 03:13:28.611910 Iteration 3700 mean testing loss (rgbd) 0.990366408216
>>> 2017-02-09 03:13:28.611919 Iteration 3700 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:13:29.645974 14948 solver.cpp:228] Iteration 3700, loss = 0.00706575
I0209 03:13:29.646003 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:13:29.646010 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00706575 (* 1 = 0.00706575 loss)
I0209 03:13:29.646016 14948 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0209 03:14:22.380522 14948 solver.cpp:228] Iteration 3750, loss = 0.0340554
I0209 03:14:22.380560 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:14:22.380569 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0650316 (* 1 = 0.0650316 loss)
I0209 03:14:22.380578 14948 sgd_solver.cpp:106] Iteration 3750, lr = 0.001
>>> 2017-02-09 03:15:14.005505 Begin model classification tests
>>> 2017-02-09 03:15:31.979655 Iteration 3800 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:15:31.979686 Iteration 3800 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:15:31.979695 Iteration 3800 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:15:31.979701 Iteration 3800 mean testing loss (rgb) 0.984746031216
>>> 2017-02-09 03:15:31.979714 Iteration 3800 mean testing loss (depth) 0.984746031216
>>> 2017-02-09 03:15:31.979744 Iteration 3800 mean testing loss (rgbd) 0.984746031216
>>> 2017-02-09 03:15:31.979755 Iteration 3800 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.66666667  0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:15:33.015743 14948 solver.cpp:228] Iteration 3800, loss = 0.016012
I0209 03:15:33.015771 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:15:33.015779 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.016012 (* 1 = 0.016012 loss)
I0209 03:15:33.015785 14948 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0209 03:16:25.782687 14948 solver.cpp:228] Iteration 3850, loss = 0.0326132
I0209 03:16:25.782717 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:16:25.782727 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0264384 (* 1 = 0.0264384 loss)
I0209 03:16:25.782732 14948 sgd_solver.cpp:106] Iteration 3850, lr = 0.001
>>> 2017-02-09 03:17:17.540886 Begin model classification tests
>>> 2017-02-09 03:17:35.518803 Iteration 3900 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:17:35.518832 Iteration 3900 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:17:35.518840 Iteration 3900 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:17:35.518846 Iteration 3900 mean testing loss (rgb) 0.989571092111
>>> 2017-02-09 03:17:35.518857 Iteration 3900 mean testing loss (depth) 0.989571092111
>>> 2017-02-09 03:17:35.518874 Iteration 3900 mean testing loss (rgbd) 0.989571092111
>>> 2017-02-09 03:17:35.518890 Iteration 3900 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 03:17:36.584524 14948 solver.cpp:228] Iteration 3900, loss = 0.0209485
I0209 03:17:36.584553 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:17:36.584561 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0209485 (* 1 = 0.0209485 loss)
I0209 03:17:36.584568 14948 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0209 03:18:29.486604 14948 solver.cpp:228] Iteration 3950, loss = 0.032181
I0209 03:18:29.486632 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:18:29.486641 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0398519 (* 1 = 0.0398519 loss)
I0209 03:18:29.486647 14948 sgd_solver.cpp:106] Iteration 3950, lr = 0.001
I0209 03:19:21.157094 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_4000.caffemodel
I0209 03:20:19.796762 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_4000.solverstate
>>> 2017-02-09 03:20:27.203572 Begin model classification tests
>>> 2017-02-09 03:20:44.820311 Iteration 4000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:20:44.820341 Iteration 4000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:20:44.820355 Iteration 4000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:20:44.820367 Iteration 4000 mean testing loss (rgb) 0.994070977639
>>> 2017-02-09 03:20:44.820382 Iteration 4000 mean testing loss (depth) 0.994070977639
>>> 2017-02-09 03:20:44.820394 Iteration 4000 mean testing loss (rgbd) 0.994070977639
>>> 2017-02-09 03:20:44.820426 Iteration 4000 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:20:45.965116 14948 solver.cpp:228] Iteration 4000, loss = 0.0593406
I0209 03:20:45.965145 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:20:45.965153 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0593406 (* 1 = 0.0593406 loss)
I0209 03:20:45.965159 14948 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0209 03:21:41.987119 14948 solver.cpp:228] Iteration 4050, loss = 0.0365853
I0209 03:21:41.987149 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:21:41.987162 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0214477 (* 1 = 0.0214477 loss)
I0209 03:21:41.987170 14948 sgd_solver.cpp:106] Iteration 4050, lr = 0.001
>>> 2017-02-09 03:22:34.444271 Begin model classification tests
>>> 2017-02-09 03:22:52.577831 Iteration 4100 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 03:22:52.577862 Iteration 4100 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 03:22:52.577869 Iteration 4100 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 03:22:52.577875 Iteration 4100 mean testing loss (rgb) 0.991586454544
>>> 2017-02-09 03:22:52.577887 Iteration 4100 mean testing loss (depth) 0.991586454544
>>> 2017-02-09 03:22:52.577904 Iteration 4100 mean testing loss (rgbd) 0.991586454544
>>> 2017-02-09 03:22:52.577922 Iteration 4100 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.66666667  0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:22:53.623677 14948 solver.cpp:228] Iteration 4100, loss = 0.0158553
I0209 03:22:53.623715 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:22:53.623723 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0158553 (* 1 = 0.0158553 loss)
I0209 03:22:53.623731 14948 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0209 03:23:47.094899 14948 solver.cpp:228] Iteration 4150, loss = 0.0272262
I0209 03:23:47.094928 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:23:47.094935 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0039342 (* 1 = 0.0039342 loss)
I0209 03:23:47.094943 14948 sgd_solver.cpp:106] Iteration 4150, lr = 0.001
>>> 2017-02-09 03:24:39.161281 Begin model classification tests
>>> 2017-02-09 03:24:57.186756 Iteration 4200 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:24:57.186787 Iteration 4200 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:24:57.186795 Iteration 4200 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:24:57.186802 Iteration 4200 mean testing loss (rgb) 0.990814254668
>>> 2017-02-09 03:24:57.186815 Iteration 4200 mean testing loss (depth) 0.990814254668
>>> 2017-02-09 03:24:57.186838 Iteration 4200 mean testing loss (rgbd) 0.990814254668
>>> 2017-02-09 03:24:57.186857 Iteration 4200 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:24:58.242257 14948 solver.cpp:228] Iteration 4200, loss = 0.0109141
I0209 03:24:58.242285 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:24:58.242292 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0109141 (* 1 = 0.0109141 loss)
I0209 03:24:58.242298 14948 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0209 03:25:51.320611 14948 solver.cpp:228] Iteration 4250, loss = 0.0286588
I0209 03:25:51.320637 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:25:51.320662 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0135739 (* 1 = 0.0135739 loss)
I0209 03:25:51.320667 14948 sgd_solver.cpp:106] Iteration 4250, lr = 0.001
>>> 2017-02-09 03:26:43.146807 Begin model classification tests
>>> 2017-02-09 03:27:01.131556 Iteration 4300 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:27:01.131586 Iteration 4300 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:27:01.131594 Iteration 4300 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:27:01.131600 Iteration 4300 mean testing loss (rgb) 0.990716074132
>>> 2017-02-09 03:27:01.131611 Iteration 4300 mean testing loss (depth) 0.990716074132
>>> 2017-02-09 03:27:01.131628 Iteration 4300 mean testing loss (rgbd) 0.990716074132
>>> 2017-02-09 03:27:01.131647 Iteration 4300 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:27:02.164482 14948 solver.cpp:228] Iteration 4300, loss = 0.0254392
I0209 03:27:02.164508 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:27:02.164516 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0254392 (* 1 = 0.0254392 loss)
I0209 03:27:02.164523 14948 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0209 03:27:54.932026 14948 solver.cpp:228] Iteration 4350, loss = 0.0307846
I0209 03:27:54.932055 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:27:54.932070 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0263744 (* 1 = 0.0263744 loss)
I0209 03:27:54.932077 14948 sgd_solver.cpp:106] Iteration 4350, lr = 0.001
>>> 2017-02-09 03:28:46.599451 Begin model classification tests
>>> 2017-02-09 03:29:04.562604 Iteration 4400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:29:04.562634 Iteration 4400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:29:04.562642 Iteration 4400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:29:04.562648 Iteration 4400 mean testing loss (rgb) 0.990910145007
>>> 2017-02-09 03:29:04.562660 Iteration 4400 mean testing loss (depth) 0.990910145007
>>> 2017-02-09 03:29:04.562680 Iteration 4400 mean testing loss (rgbd) 0.990910145007
>>> 2017-02-09 03:29:04.562699 Iteration 4400 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:29:05.596143 14948 solver.cpp:228] Iteration 4400, loss = 0.016197
I0209 03:29:05.596170 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:29:05.596190 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.016197 (* 1 = 0.016197 loss)
I0209 03:29:05.596197 14948 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0209 03:29:58.399534 14948 solver.cpp:228] Iteration 4450, loss = 0.034904
I0209 03:29:58.399564 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 03:29:58.399574 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0732183 (* 1 = 0.0732183 loss)
I0209 03:29:58.399580 14948 sgd_solver.cpp:106] Iteration 4450, lr = 0.001
>>> 2017-02-09 03:30:49.965941 Begin model classification tests
>>> 2017-02-09 03:31:07.977381 Iteration 4500 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:31:07.977410 Iteration 4500 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:31:07.977418 Iteration 4500 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:31:07.977424 Iteration 4500 mean testing loss (rgb) 0.993682243678
>>> 2017-02-09 03:31:07.977435 Iteration 4500 mean testing loss (depth) 0.993682243678
>>> 2017-02-09 03:31:07.977456 Iteration 4500 mean testing loss (rgbd) 0.993682243678
>>> 2017-02-09 03:31:07.977475 Iteration 4500 mean confusion matrix
[ 1.          0.9826087   0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:31:09.012181 14948 solver.cpp:228] Iteration 4500, loss = 0.00696141
I0209 03:31:09.012208 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:31:09.012217 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00696141 (* 1 = 0.00696141 loss)
I0209 03:31:09.012223 14948 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0209 03:32:01.812731 14948 solver.cpp:228] Iteration 4550, loss = 0.0380594
I0209 03:32:01.812769 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:32:01.812777 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0179966 (* 1 = 0.0179966 loss)
I0209 03:32:01.812796 14948 sgd_solver.cpp:106] Iteration 4550, lr = 0.001
>>> 2017-02-09 03:32:53.411458 Begin model classification tests
>>> 2017-02-09 03:33:11.401065 Iteration 4600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:33:11.401096 Iteration 4600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:33:11.401104 Iteration 4600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:33:11.401111 Iteration 4600 mean testing loss (rgb) 0.98488437529
>>> 2017-02-09 03:33:11.401124 Iteration 4600 mean testing loss (depth) 0.98488437529
>>> 2017-02-09 03:33:11.401145 Iteration 4600 mean testing loss (rgbd) 0.98488437529
>>> 2017-02-09 03:33:11.401164 Iteration 4600 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 03:33:12.431768 14948 solver.cpp:228] Iteration 4600, loss = 0.0153265
I0209 03:33:12.431797 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:33:12.431805 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0153265 (* 1 = 0.0153265 loss)
I0209 03:33:12.431812 14948 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0209 03:34:05.214260 14948 solver.cpp:228] Iteration 4650, loss = 0.0313665
I0209 03:34:05.214287 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:34:05.214295 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.064054 (* 1 = 0.064054 loss)
I0209 03:34:05.214303 14948 sgd_solver.cpp:106] Iteration 4650, lr = 0.001
>>> 2017-02-09 03:34:56.866143 Begin model classification tests
>>> 2017-02-09 03:35:14.858082 Iteration 4700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:35:14.858111 Iteration 4700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:35:14.858119 Iteration 4700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:35:14.858125 Iteration 4700 mean testing loss (rgb) 1.0073350862
>>> 2017-02-09 03:35:14.858137 Iteration 4700 mean testing loss (depth) 1.0073350862
>>> 2017-02-09 03:35:14.858157 Iteration 4700 mean testing loss (rgbd) 1.0073350862
>>> 2017-02-09 03:35:14.858175 Iteration 4700 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 03:35:15.893987 14948 solver.cpp:228] Iteration 4700, loss = 0.129787
I0209 03:35:15.894014 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.921875
I0209 03:35:15.894023 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.129787 (* 1 = 0.129787 loss)
I0209 03:35:15.894029 14948 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0209 03:36:08.857311 14948 solver.cpp:228] Iteration 4750, loss = 0.0381077
I0209 03:36:08.857341 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.9375
I0209 03:36:08.857349 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0771998 (* 1 = 0.0771998 loss)
I0209 03:36:08.857355 14948 sgd_solver.cpp:106] Iteration 4750, lr = 0.001
>>> 2017-02-09 03:37:00.599704 Begin model classification tests
>>> 2017-02-09 03:37:18.583106 Iteration 4800 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:37:18.583135 Iteration 4800 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:37:18.583143 Iteration 4800 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:37:18.583149 Iteration 4800 mean testing loss (rgb) 1.00075243002
>>> 2017-02-09 03:37:18.583160 Iteration 4800 mean testing loss (depth) 1.00075243002
>>> 2017-02-09 03:37:18.583177 Iteration 4800 mean testing loss (rgbd) 1.00075243002
>>> 2017-02-09 03:37:18.583183 Iteration 4800 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 03:37:19.617590 14948 solver.cpp:228] Iteration 4800, loss = 0.0251434
I0209 03:37:19.617619 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:37:19.617626 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0251434 (* 1 = 0.0251434 loss)
I0209 03:37:19.617632 14948 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0209 03:38:12.456881 14948 solver.cpp:228] Iteration 4850, loss = 0.0311597
I0209 03:38:12.456908 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:38:12.456917 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0205703 (* 1 = 0.0205703 loss)
I0209 03:38:12.456923 14948 sgd_solver.cpp:106] Iteration 4850, lr = 0.001
>>> 2017-02-09 03:39:04.070482 Begin model classification tests
>>> 2017-02-09 03:39:21.992738 Iteration 4900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:39:21.992768 Iteration 4900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:39:21.992776 Iteration 4900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:39:21.992782 Iteration 4900 mean testing loss (rgb) 0.991280016352
>>> 2017-02-09 03:39:21.992794 Iteration 4900 mean testing loss (depth) 0.991280016352
>>> 2017-02-09 03:39:21.992814 Iteration 4900 mean testing loss (rgbd) 0.991280016352
>>> 2017-02-09 03:39:21.992833 Iteration 4900 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 03:39:23.026185 14948 solver.cpp:228] Iteration 4900, loss = 0.0881092
I0209 03:39:23.026213 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 03:39:23.026221 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0881092 (* 1 = 0.0881092 loss)
I0209 03:39:23.026228 14948 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0209 03:40:15.850495 14948 solver.cpp:228] Iteration 4950, loss = 0.0347125
I0209 03:40:15.850523 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:40:15.850531 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0243201 (* 1 = 0.0243201 loss)
I0209 03:40:15.850538 14948 sgd_solver.cpp:106] Iteration 4950, lr = 0.001
I0209 03:41:07.541067 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_5000.caffemodel
I0209 03:41:54.692078 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_5000.solverstate
>>> 2017-02-09 03:42:02.054341 Begin model classification tests
>>> 2017-02-09 03:42:19.675928 Iteration 5000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:42:19.675957 Iteration 5000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:42:19.675965 Iteration 5000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:42:19.675971 Iteration 5000 mean testing loss (rgb) 1.00509378848
>>> 2017-02-09 03:42:19.675984 Iteration 5000 mean testing loss (depth) 1.00509378848
>>> 2017-02-09 03:42:19.676001 Iteration 5000 mean testing loss (rgbd) 1.00509378848
>>> 2017-02-09 03:42:19.676017 Iteration 5000 mean confusion matrix
[ 1.          0.96521739  0.78571429  0.          0.66666667  0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 03:42:20.708266 14948 solver.cpp:228] Iteration 5000, loss = 0.00998726
I0209 03:42:20.708294 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:42:20.708302 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00998726 (* 1 = 0.00998726 loss)
I0209 03:42:20.708310 14948 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0209 03:43:16.620869 14948 solver.cpp:228] Iteration 5050, loss = 0.0313452
I0209 03:43:16.620899 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:43:16.620909 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0638868 (* 1 = 0.0638868 loss)
I0209 03:43:16.620915 14948 sgd_solver.cpp:106] Iteration 5050, lr = 0.001
>>> 2017-02-09 03:44:11.046067 Begin model classification tests
>>> 2017-02-09 03:44:29.163820 Iteration 5100 mean classification accuracy (rgb)  0.849187935035
>>> 2017-02-09 03:44:29.163852 Iteration 5100 mean classification accuracy (depth) 0.849187935035
>>> 2017-02-09 03:44:29.163865 Iteration 5100 mean classification accuracy (rgbd)  0.849187935035
>>> 2017-02-09 03:44:29.163893 Iteration 5100 mean testing loss (rgb) 1.00280416468
>>> 2017-02-09 03:44:29.163904 Iteration 5100 mean testing loss (depth) 1.00280416468
>>> 2017-02-09 03:44:29.163911 Iteration 5100 mean testing loss (rgbd) 1.00280416468
>>> 2017-02-09 03:44:29.163917 Iteration 5100 mean confusion matrix
[ 1.          0.96521739  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:44:30.293140 14948 solver.cpp:228] Iteration 5100, loss = 0.0502626
I0209 03:44:30.293170 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:44:30.293179 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0502626 (* 1 = 0.0502626 loss)
I0209 03:44:30.293185 14948 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0209 03:45:24.600231 14948 solver.cpp:228] Iteration 5150, loss = 0.0351802
I0209 03:45:24.600260 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:45:24.600268 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00828459 (* 1 = 0.00828459 loss)
I0209 03:45:24.600275 14948 sgd_solver.cpp:106] Iteration 5150, lr = 0.001
>>> 2017-02-09 03:46:16.842003 Begin model classification tests
>>> 2017-02-09 03:46:34.815375 Iteration 5200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:46:34.815405 Iteration 5200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:46:34.815414 Iteration 5200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:46:34.815420 Iteration 5200 mean testing loss (rgb) 0.987450838335
>>> 2017-02-09 03:46:34.815432 Iteration 5200 mean testing loss (depth) 0.987450838335
>>> 2017-02-09 03:46:34.815453 Iteration 5200 mean testing loss (rgbd) 0.987450838335
>>> 2017-02-09 03:46:34.815471 Iteration 5200 mean confusion matrix
[ 1.          0.96521739  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:46:35.854686 14948 solver.cpp:228] Iteration 5200, loss = 0.075192
I0209 03:46:35.854715 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 03:46:35.854724 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.075192 (* 1 = 0.075192 loss)
I0209 03:46:35.854730 14948 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0209 03:47:29.010149 14948 solver.cpp:228] Iteration 5250, loss = 0.0308977
I0209 03:47:29.010179 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 03:47:29.010192 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0530449 (* 1 = 0.0530449 loss)
I0209 03:47:29.010200 14948 sgd_solver.cpp:106] Iteration 5250, lr = 0.001
>>> 2017-02-09 03:48:21.061595 Begin model classification tests
>>> 2017-02-09 03:48:39.036095 Iteration 5300 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:48:39.036124 Iteration 5300 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:48:39.036132 Iteration 5300 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:48:39.036138 Iteration 5300 mean testing loss (rgb) 0.985540892762
>>> 2017-02-09 03:48:39.036149 Iteration 5300 mean testing loss (depth) 0.985540892762
>>> 2017-02-09 03:48:39.036165 Iteration 5300 mean testing loss (rgbd) 0.985540892762
>>> 2017-02-09 03:48:39.036172 Iteration 5300 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:48:40.086863 14948 solver.cpp:228] Iteration 5300, loss = 0.00669904
I0209 03:48:40.086892 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:48:40.086901 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00669904 (* 1 = 0.00669904 loss)
I0209 03:48:40.086907 14948 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I0209 03:49:32.932147 14948 solver.cpp:228] Iteration 5350, loss = 0.0312325
I0209 03:49:32.932175 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 03:49:32.932184 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0493945 (* 1 = 0.0493945 loss)
I0209 03:49:32.932190 14948 sgd_solver.cpp:106] Iteration 5350, lr = 0.001
>>> 2017-02-09 03:50:24.529328 Begin model classification tests
>>> 2017-02-09 03:50:42.521250 Iteration 5400 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 03:50:42.521282 Iteration 5400 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 03:50:42.521290 Iteration 5400 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 03:50:42.521296 Iteration 5400 mean testing loss (rgb) 0.990844743723
>>> 2017-02-09 03:50:42.521309 Iteration 5400 mean testing loss (depth) 0.990844743723
>>> 2017-02-09 03:50:42.521329 Iteration 5400 mean testing loss (rgbd) 0.990844743723
>>> 2017-02-09 03:50:42.521348 Iteration 5400 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:50:43.556006 14948 solver.cpp:228] Iteration 5400, loss = 0.0219179
I0209 03:50:43.556035 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:50:43.556042 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0219179 (* 1 = 0.0219179 loss)
I0209 03:50:43.556049 14948 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0209 03:51:36.413460 14948 solver.cpp:228] Iteration 5450, loss = 0.0310486
I0209 03:51:36.413491 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:51:36.413509 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0257622 (* 1 = 0.0257622 loss)
I0209 03:51:36.413544 14948 sgd_solver.cpp:106] Iteration 5450, lr = 0.001
>>> 2017-02-09 03:52:28.178661 Begin model classification tests
>>> 2017-02-09 03:52:46.138607 Iteration 5500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 03:52:46.138637 Iteration 5500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 03:52:46.138645 Iteration 5500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 03:52:46.138651 Iteration 5500 mean testing loss (rgb) 0.994811507476
>>> 2017-02-09 03:52:46.138662 Iteration 5500 mean testing loss (depth) 0.994811507476
>>> 2017-02-09 03:52:46.138679 Iteration 5500 mean testing loss (rgbd) 0.994811507476
>>> 2017-02-09 03:52:46.138695 Iteration 5500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:52:47.170342 14948 solver.cpp:228] Iteration 5500, loss = 0.0466589
I0209 03:52:47.170382 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:52:47.170390 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0466589 (* 1 = 0.0466589 loss)
I0209 03:52:47.170400 14948 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0209 03:53:39.955025 14948 solver.cpp:228] Iteration 5550, loss = 0.0330541
I0209 03:53:39.955051 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 03:53:39.955060 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0870047 (* 1 = 0.0870047 loss)
I0209 03:53:39.955065 14948 sgd_solver.cpp:106] Iteration 5550, lr = 0.001
>>> 2017-02-09 03:54:31.626084 Begin model classification tests
>>> 2017-02-09 03:54:49.604191 Iteration 5600 mean classification accuracy (rgb)  0.844547563805
>>> 2017-02-09 03:54:49.604221 Iteration 5600 mean classification accuracy (depth) 0.844547563805
>>> 2017-02-09 03:54:49.604229 Iteration 5600 mean classification accuracy (rgbd)  0.844547563805
>>> 2017-02-09 03:54:49.604235 Iteration 5600 mean testing loss (rgb) 1.02567442442
>>> 2017-02-09 03:54:49.604247 Iteration 5600 mean testing loss (depth) 1.02567442442
>>> 2017-02-09 03:54:49.604267 Iteration 5600 mean testing loss (rgbd) 1.02567442442
>>> 2017-02-09 03:54:49.604286 Iteration 5600 mean confusion matrix
[ 1.          0.96521739  0.78571429  0.          0.6         0.85294118
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:54:50.640322 14948 solver.cpp:228] Iteration 5600, loss = 0.00102418
I0209 03:54:50.640352 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:54:50.640359 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00102418 (* 1 = 0.00102418 loss)
I0209 03:54:50.640365 14948 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0209 03:55:43.330435 14948 solver.cpp:228] Iteration 5650, loss = 0.0325934
I0209 03:55:43.330463 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:55:43.330483 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0138772 (* 1 = 0.0138772 loss)
I0209 03:55:43.330490 14948 sgd_solver.cpp:106] Iteration 5650, lr = 0.001
>>> 2017-02-09 03:56:34.975376 Begin model classification tests
>>> 2017-02-09 03:56:52.848954 Iteration 5700 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 03:56:52.848988 Iteration 5700 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 03:56:52.848996 Iteration 5700 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 03:56:52.849002 Iteration 5700 mean testing loss (rgb) 1.02307248739
>>> 2017-02-09 03:56:52.849012 Iteration 5700 mean testing loss (depth) 1.02307248739
>>> 2017-02-09 03:56:52.849030 Iteration 5700 mean testing loss (rgbd) 1.02307248739
>>> 2017-02-09 03:56:52.849048 Iteration 5700 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.85294118
  0.81481481  1.          0.36363636  0.93939394  0.83333333]
I0209 03:56:53.883836 14948 solver.cpp:228] Iteration 5700, loss = 0.0503903
I0209 03:56:53.883864 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:56:53.883872 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0503903 (* 1 = 0.0503903 loss)
I0209 03:56:53.883879 14948 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I0209 03:57:46.543347 14948 solver.cpp:228] Iteration 5750, loss = 0.0360313
I0209 03:57:46.543375 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 03:57:46.543383 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0602871 (* 1 = 0.0602871 loss)
I0209 03:57:46.543390 14948 sgd_solver.cpp:106] Iteration 5750, lr = 0.001
>>> 2017-02-09 03:58:38.110987 Begin model classification tests
>>> 2017-02-09 03:58:56.004354 Iteration 5800 mean classification accuracy (rgb)  0.849187935035
>>> 2017-02-09 03:58:56.004384 Iteration 5800 mean classification accuracy (depth) 0.849187935035
>>> 2017-02-09 03:58:56.004393 Iteration 5800 mean classification accuracy (rgbd)  0.849187935035
>>> 2017-02-09 03:58:56.004399 Iteration 5800 mean testing loss (rgb) 1.02539002787
>>> 2017-02-09 03:58:56.004410 Iteration 5800 mean testing loss (depth) 1.02539002787
>>> 2017-02-09 03:58:56.004427 Iteration 5800 mean testing loss (rgbd) 1.02539002787
>>> 2017-02-09 03:58:56.004433 Iteration 5800 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.88235294
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 03:58:57.040375 14948 solver.cpp:228] Iteration 5800, loss = 0.0302384
I0209 03:58:57.040401 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 03:58:57.040410 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0302384 (* 1 = 0.0302384 loss)
I0209 03:58:57.040416 14948 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0209 03:59:49.764266 14948 solver.cpp:228] Iteration 5850, loss = 0.0356636
I0209 03:59:49.764297 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 03:59:49.764307 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00891044 (* 1 = 0.00891044 loss)
I0209 03:59:49.764325 14948 sgd_solver.cpp:106] Iteration 5850, lr = 0.001
>>> 2017-02-09 04:00:41.366657 Begin model classification tests
>>> 2017-02-09 04:00:59.345459 Iteration 5900 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 04:00:59.345489 Iteration 5900 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 04:00:59.345497 Iteration 5900 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 04:00:59.345503 Iteration 5900 mean testing loss (rgb) 1.00673775712
>>> 2017-02-09 04:00:59.345543 Iteration 5900 mean testing loss (depth) 1.00673775712
>>> 2017-02-09 04:00:59.345553 Iteration 5900 mean testing loss (rgbd) 1.00673775712
>>> 2017-02-09 04:00:59.345574 Iteration 5900 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.36363636  0.93939394  0.83333333]
I0209 04:01:00.384506 14948 solver.cpp:228] Iteration 5900, loss = 0.0621682
I0209 04:01:00.384534 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:01:00.384543 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0621682 (* 1 = 0.0621682 loss)
I0209 04:01:00.384549 14948 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
I0209 04:01:53.058029 14948 solver.cpp:228] Iteration 5950, loss = 0.0296251
I0209 04:01:53.058058 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:01:53.058066 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0145645 (* 1 = 0.0145645 loss)
I0209 04:01:53.058073 14948 sgd_solver.cpp:106] Iteration 5950, lr = 0.001
I0209 04:02:44.634075 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_6000.caffemodel
I0209 04:03:33.196766 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_6000.solverstate
>>> 2017-02-09 04:03:40.417822 Begin model classification tests
>>> 2017-02-09 04:03:58.048862 Iteration 6000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:03:58.048896 Iteration 6000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:03:58.048904 Iteration 6000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:03:58.048910 Iteration 6000 mean testing loss (rgb) 1.00461333392
>>> 2017-02-09 04:03:58.048921 Iteration 6000 mean testing loss (depth) 1.00461333392
>>> 2017-02-09 04:03:58.048938 Iteration 6000 mean testing loss (rgbd) 1.00461333392
>>> 2017-02-09 04:03:58.048944 Iteration 6000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:03:59.078675 14948 solver.cpp:228] Iteration 6000, loss = 0.00627379
I0209 04:03:59.078704 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:03:59.078718 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00627379 (* 1 = 0.00627379 loss)
I0209 04:03:59.078747 14948 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0209 04:04:53.937288 14948 solver.cpp:228] Iteration 6050, loss = 0.029937
I0209 04:04:53.937316 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:04:53.937325 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0349095 (* 1 = 0.0349095 loss)
I0209 04:04:53.937331 14948 sgd_solver.cpp:106] Iteration 6050, lr = 0.001
>>> 2017-02-09 04:05:48.101170 Begin model classification tests
>>> 2017-02-09 04:06:06.171540 Iteration 6100 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:06:06.171572 Iteration 6100 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:06:06.171580 Iteration 6100 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:06:06.171587 Iteration 6100 mean testing loss (rgb) 1.0161409099
>>> 2017-02-09 04:06:06.171597 Iteration 6100 mean testing loss (depth) 1.0161409099
>>> 2017-02-09 04:06:06.171604 Iteration 6100 mean testing loss (rgbd) 1.0161409099
>>> 2017-02-09 04:06:06.171610 Iteration 6100 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:06:07.295394 14948 solver.cpp:228] Iteration 6100, loss = 0.01209
I0209 04:06:07.295433 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:06:07.295440 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.01209 (* 1 = 0.01209 loss)
I0209 04:06:07.295450 14948 sgd_solver.cpp:106] Iteration 6100, lr = 0.001
I0209 04:07:02.328687 14948 solver.cpp:228] Iteration 6150, loss = 0.0309717
I0209 04:07:02.328714 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:07:02.328723 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0347419 (* 1 = 0.0347419 loss)
I0209 04:07:02.328729 14948 sgd_solver.cpp:106] Iteration 6150, lr = 0.001
>>> 2017-02-09 04:07:55.949685 Begin model classification tests
>>> 2017-02-09 04:08:13.968616 Iteration 6200 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:08:13.968646 Iteration 6200 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:08:13.968661 Iteration 6200 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:08:13.968672 Iteration 6200 mean testing loss (rgb) 1.01771187663
>>> 2017-02-09 04:08:13.968684 Iteration 6200 mean testing loss (depth) 1.01771187663
>>> 2017-02-09 04:08:13.968700 Iteration 6200 mean testing loss (rgbd) 1.01771187663
>>> 2017-02-09 04:08:13.968708 Iteration 6200 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:08:15.005326 14948 solver.cpp:228] Iteration 6200, loss = 0.000982504
I0209 04:08:15.005352 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:08:15.005362 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.000982504 (* 1 = 0.000982504 loss)
I0209 04:08:15.005367 14948 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0209 04:09:09.700780 14948 solver.cpp:228] Iteration 6250, loss = 0.0343617
I0209 04:09:09.700811 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:09:09.700824 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0304663 (* 1 = 0.0304663 loss)
I0209 04:09:09.700832 14948 sgd_solver.cpp:106] Iteration 6250, lr = 0.001
>>> 2017-02-09 04:10:03.072561 Begin model classification tests
>>> 2017-02-09 04:10:21.034284 Iteration 6300 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:10:21.034314 Iteration 6300 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:10:21.034322 Iteration 6300 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:10:21.034338 Iteration 6300 mean testing loss (rgb) 1.0183309739
>>> 2017-02-09 04:10:21.034350 Iteration 6300 mean testing loss (depth) 1.0183309739
>>> 2017-02-09 04:10:21.034370 Iteration 6300 mean testing loss (rgbd) 1.0183309739
>>> 2017-02-09 04:10:21.034389 Iteration 6300 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:10:22.111832 14948 solver.cpp:228] Iteration 6300, loss = 0.0462639
I0209 04:10:22.111860 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:10:22.111870 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0462639 (* 1 = 0.0462639 loss)
I0209 04:10:22.111876 14948 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
I0209 04:11:16.665449 14948 solver.cpp:228] Iteration 6350, loss = 0.0311272
I0209 04:11:16.665477 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 04:11:16.665484 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0338385 (* 1 = 0.0338385 loss)
I0209 04:11:16.665490 14948 sgd_solver.cpp:106] Iteration 6350, lr = 0.001
>>> 2017-02-09 04:12:10.193993 Begin model classification tests
>>> 2017-02-09 04:12:28.163465 Iteration 6400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:12:28.163495 Iteration 6400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:12:28.163503 Iteration 6400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:12:28.163509 Iteration 6400 mean testing loss (rgb) 1.00833521911
>>> 2017-02-09 04:12:28.163520 Iteration 6400 mean testing loss (depth) 1.00833521911
>>> 2017-02-09 04:12:28.163540 Iteration 6400 mean testing loss (rgbd) 1.00833521911
>>> 2017-02-09 04:12:28.163560 Iteration 6400 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:12:29.198046 14948 solver.cpp:228] Iteration 6400, loss = 0.0118943
I0209 04:12:29.198073 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:12:29.198081 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0118943 (* 1 = 0.0118943 loss)
I0209 04:12:29.198088 14948 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0209 04:13:23.501453 14948 solver.cpp:228] Iteration 6450, loss = 0.0244176
I0209 04:13:23.501480 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:13:23.501488 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0217918 (* 1 = 0.0217918 loss)
I0209 04:13:23.501495 14948 sgd_solver.cpp:106] Iteration 6450, lr = 0.001
>>> 2017-02-09 04:14:16.165005 Begin model classification tests
>>> 2017-02-09 04:14:34.120973 Iteration 6500 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:14:34.121002 Iteration 6500 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:14:34.121011 Iteration 6500 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:14:34.121017 Iteration 6500 mean testing loss (rgb) 1.01060749888
>>> 2017-02-09 04:14:34.121028 Iteration 6500 mean testing loss (depth) 1.01060749888
>>> 2017-02-09 04:14:34.121045 Iteration 6500 mean testing loss (rgbd) 1.01060749888
>>> 2017-02-09 04:14:34.121060 Iteration 6500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.88235294
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:14:35.156044 14948 solver.cpp:228] Iteration 6500, loss = 0.0144065
I0209 04:14:35.156074 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:14:35.156081 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0144065 (* 1 = 0.0144065 loss)
I0209 04:14:35.156087 14948 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
I0209 04:15:29.369938 14948 solver.cpp:228] Iteration 6550, loss = 0.0289744
I0209 04:15:29.369968 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:15:29.369987 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0328442 (* 1 = 0.0328442 loss)
I0209 04:15:29.369994 14948 sgd_solver.cpp:106] Iteration 6550, lr = 0.001
>>> 2017-02-09 04:16:22.321118 Begin model classification tests
>>> 2017-02-09 04:16:40.335265 Iteration 6600 mean classification accuracy (rgb)  0.84686774942
>>> 2017-02-09 04:16:40.335297 Iteration 6600 mean classification accuracy (depth) 0.84686774942
>>> 2017-02-09 04:16:40.335311 Iteration 6600 mean classification accuracy (rgbd)  0.84686774942
>>> 2017-02-09 04:16:40.335341 Iteration 6600 mean testing loss (rgb) 1.01855054902
>>> 2017-02-09 04:16:40.335362 Iteration 6600 mean testing loss (depth) 1.01855054902
>>> 2017-02-09 04:16:40.335370 Iteration 6600 mean testing loss (rgbd) 1.01855054902
>>> 2017-02-09 04:16:40.335376 Iteration 6600 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.85294118
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:16:41.383847 14948 solver.cpp:228] Iteration 6600, loss = 0.0311322
I0209 04:16:41.383877 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:16:41.383884 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0311322 (* 1 = 0.0311322 loss)
I0209 04:16:41.383891 14948 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0209 04:17:35.212817 14948 solver.cpp:228] Iteration 6650, loss = 0.0299615
I0209 04:17:35.212844 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:17:35.212852 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0177139 (* 1 = 0.0177139 loss)
I0209 04:17:35.212858 14948 sgd_solver.cpp:106] Iteration 6650, lr = 0.001
>>> 2017-02-09 04:18:27.854942 Begin model classification tests
>>> 2017-02-09 04:18:45.724860 Iteration 6700 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:18:45.724890 Iteration 6700 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:18:45.724901 Iteration 6700 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:18:45.724921 Iteration 6700 mean testing loss (rgb) 1.03191177017
>>> 2017-02-09 04:18:45.724936 Iteration 6700 mean testing loss (depth) 1.03191177017
>>> 2017-02-09 04:18:45.724948 Iteration 6700 mean testing loss (rgbd) 1.03191177017
>>> 2017-02-09 04:18:45.724960 Iteration 6700 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:18:46.795550 14948 solver.cpp:228] Iteration 6700, loss = 0.0293674
I0209 04:18:46.795578 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:18:46.795588 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0293674 (* 1 = 0.0293674 loss)
I0209 04:18:46.795593 14948 sgd_solver.cpp:106] Iteration 6700, lr = 0.001
I0209 04:19:40.528950 14948 solver.cpp:228] Iteration 6750, loss = 0.0305751
I0209 04:19:40.528977 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:19:40.528985 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0103004 (* 1 = 0.0103004 loss)
I0209 04:19:40.528991 14948 sgd_solver.cpp:106] Iteration 6750, lr = 0.001
>>> 2017-02-09 04:20:33.256780 Begin model classification tests
>>> 2017-02-09 04:20:51.217083 Iteration 6800 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:20:51.217113 Iteration 6800 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:20:51.217121 Iteration 6800 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:20:51.217127 Iteration 6800 mean testing loss (rgb) 1.03671683407
>>> 2017-02-09 04:20:51.217139 Iteration 6800 mean testing loss (depth) 1.03671683407
>>> 2017-02-09 04:20:51.217159 Iteration 6800 mean testing loss (rgbd) 1.03671683407
>>> 2017-02-09 04:20:51.217178 Iteration 6800 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:20:52.253667 14948 solver.cpp:228] Iteration 6800, loss = 0.0859111
I0209 04:20:52.253696 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 04:20:52.253705 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0859111 (* 1 = 0.0859111 loss)
I0209 04:20:52.253710 14948 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0209 04:21:46.227663 14948 solver.cpp:228] Iteration 6850, loss = 0.0350826
I0209 04:21:46.227700 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:21:46.227710 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0164104 (* 1 = 0.0164104 loss)
I0209 04:21:46.227717 14948 sgd_solver.cpp:106] Iteration 6850, lr = 0.001
>>> 2017-02-09 04:22:38.698721 Begin model classification tests
>>> 2017-02-09 04:22:56.658973 Iteration 6900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:22:56.659004 Iteration 6900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:22:56.659013 Iteration 6900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:22:56.659019 Iteration 6900 mean testing loss (rgb) 1.04955719434
>>> 2017-02-09 04:22:56.659029 Iteration 6900 mean testing loss (depth) 1.04955719434
>>> 2017-02-09 04:22:56.659036 Iteration 6900 mean testing loss (rgbd) 1.04955719434
>>> 2017-02-09 04:22:56.659043 Iteration 6900 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:22:57.708081 14948 solver.cpp:228] Iteration 6900, loss = 0.0392298
I0209 04:22:57.708112 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:22:57.708132 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0392298 (* 1 = 0.0392298 loss)
I0209 04:22:57.708139 14948 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
I0209 04:23:51.424619 14948 solver.cpp:228] Iteration 6950, loss = 0.027754
I0209 04:23:51.424646 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:23:51.424654 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0119355 (* 1 = 0.0119355 loss)
I0209 04:23:51.424661 14948 sgd_solver.cpp:106] Iteration 6950, lr = 0.001
I0209 04:24:43.550562 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_7000.caffemodel
I0209 04:25:37.800415 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_7000.solverstate
>>> 2017-02-09 04:25:45.313088 Begin model classification tests
>>> 2017-02-09 04:26:02.937662 Iteration 7000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:26:02.937691 Iteration 7000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:26:02.937699 Iteration 7000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:26:02.937705 Iteration 7000 mean testing loss (rgb) 1.03867479132
>>> 2017-02-09 04:26:02.937716 Iteration 7000 mean testing loss (depth) 1.03867479132
>>> 2017-02-09 04:26:02.937733 Iteration 7000 mean testing loss (rgbd) 1.03867479132
>>> 2017-02-09 04:26:02.937739 Iteration 7000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:26:03.973846 14948 solver.cpp:228] Iteration 7000, loss = 0.0429942
I0209 04:26:03.973883 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:26:03.973891 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0429942 (* 1 = 0.0429942 loss)
I0209 04:26:03.973899 14948 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0209 04:26:58.643687 14948 solver.cpp:228] Iteration 7050, loss = 0.0302878
I0209 04:26:58.643717 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:26:58.643724 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0182215 (* 1 = 0.0182215 loss)
I0209 04:26:58.643731 14948 sgd_solver.cpp:106] Iteration 7050, lr = 0.001
>>> 2017-02-09 04:27:52.436690 Begin model classification tests
>>> 2017-02-09 04:28:10.506866 Iteration 7100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:28:10.506896 Iteration 7100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:28:10.506903 Iteration 7100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:28:10.506910 Iteration 7100 mean testing loss (rgb) 1.03864285597
>>> 2017-02-09 04:28:10.506921 Iteration 7100 mean testing loss (depth) 1.03864285597
>>> 2017-02-09 04:28:10.506939 Iteration 7100 mean testing loss (rgbd) 1.03864285597
>>> 2017-02-09 04:28:10.506946 Iteration 7100 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:28:11.596597 14948 solver.cpp:228] Iteration 7100, loss = 0.035134
I0209 04:28:11.596626 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 04:28:11.596634 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.035134 (* 1 = 0.035134 loss)
I0209 04:28:11.596640 14948 sgd_solver.cpp:106] Iteration 7100, lr = 0.001
I0209 04:29:05.855620 14948 solver.cpp:228] Iteration 7150, loss = 0.0298037
I0209 04:29:05.855659 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:29:05.855671 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0399487 (* 1 = 0.0399487 loss)
I0209 04:29:05.855692 14948 sgd_solver.cpp:106] Iteration 7150, lr = 0.001
>>> 2017-02-09 04:29:58.915572 Begin model classification tests
>>> 2017-02-09 04:30:16.884629 Iteration 7200 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:30:16.884661 Iteration 7200 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:30:16.884669 Iteration 7200 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:30:16.884675 Iteration 7200 mean testing loss (rgb) 1.03815214187
>>> 2017-02-09 04:30:16.884687 Iteration 7200 mean testing loss (depth) 1.03815214187
>>> 2017-02-09 04:30:16.884706 Iteration 7200 mean testing loss (rgbd) 1.03815214187
>>> 2017-02-09 04:30:16.884726 Iteration 7200 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:30:17.995586 14948 solver.cpp:228] Iteration 7200, loss = 0.0709206
I0209 04:30:17.995615 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 04:30:17.995625 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0709206 (* 1 = 0.0709206 loss)
I0209 04:30:17.995630 14948 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0209 04:31:11.967866 14948 solver.cpp:228] Iteration 7250, loss = 0.03155
I0209 04:31:11.967897 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:31:11.967905 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0219694 (* 1 = 0.0219694 loss)
I0209 04:31:11.967912 14948 sgd_solver.cpp:106] Iteration 7250, lr = 0.001
>>> 2017-02-09 04:32:04.757550 Begin model classification tests
>>> 2017-02-09 04:32:22.715487 Iteration 7300 mean classification accuracy (rgb)  0.849187935035
>>> 2017-02-09 04:32:22.715519 Iteration 7300 mean classification accuracy (depth) 0.849187935035
>>> 2017-02-09 04:32:22.715532 Iteration 7300 mean classification accuracy (rgbd)  0.849187935035
>>> 2017-02-09 04:32:22.715559 Iteration 7300 mean testing loss (rgb) 1.04213509318
>>> 2017-02-09 04:32:22.715569 Iteration 7300 mean testing loss (depth) 1.04213509318
>>> 2017-02-09 04:32:22.715576 Iteration 7300 mean testing loss (rgbd) 1.04213509318
>>> 2017-02-09 04:32:22.715583 Iteration 7300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.85294118
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:32:23.746749 14948 solver.cpp:228] Iteration 7300, loss = 0.0139843
I0209 04:32:23.746778 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:32:23.746786 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0139843 (* 1 = 0.0139843 loss)
I0209 04:32:23.746793 14948 sgd_solver.cpp:106] Iteration 7300, lr = 0.001
I0209 04:33:17.570703 14948 solver.cpp:228] Iteration 7350, loss = 0.0247283
I0209 04:33:17.570732 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:33:17.570740 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0122701 (* 1 = 0.0122701 loss)
I0209 04:33:17.570747 14948 sgd_solver.cpp:106] Iteration 7350, lr = 0.001
>>> 2017-02-09 04:34:09.985532 Begin model classification tests
>>> 2017-02-09 04:34:27.968748 Iteration 7400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:34:27.968779 Iteration 7400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:34:27.968788 Iteration 7400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:34:27.968795 Iteration 7400 mean testing loss (rgb) 1.04627365312
>>> 2017-02-09 04:34:27.968805 Iteration 7400 mean testing loss (depth) 1.04627365312
>>> 2017-02-09 04:34:27.968812 Iteration 7400 mean testing loss (rgbd) 1.04627365312
>>> 2017-02-09 04:34:27.968818 Iteration 7400 mean confusion matrix
[ 1.          0.96521739  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:34:29.027070 14948 solver.cpp:228] Iteration 7400, loss = 0.0846312
I0209 04:34:29.027097 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 04:34:29.027107 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0846312 (* 1 = 0.0846312 loss)
I0209 04:34:29.027113 14948 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0209 04:35:22.453516 14948 solver.cpp:228] Iteration 7450, loss = 0.0365693
I0209 04:35:22.453543 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 04:35:22.453552 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0443043 (* 1 = 0.0443043 loss)
I0209 04:35:22.453558 14948 sgd_solver.cpp:106] Iteration 7450, lr = 0.001
>>> 2017-02-09 04:36:14.366067 Begin model classification tests
>>> 2017-02-09 04:36:32.243260 Iteration 7500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:36:32.243289 Iteration 7500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:36:32.243298 Iteration 7500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:36:32.243304 Iteration 7500 mean testing loss (rgb) 1.05067617376
>>> 2017-02-09 04:36:32.243315 Iteration 7500 mean testing loss (depth) 1.05067617376
>>> 2017-02-09 04:36:32.243335 Iteration 7500 mean testing loss (rgbd) 1.05067617376
>>> 2017-02-09 04:36:32.243354 Iteration 7500 mean confusion matrix
[ 1.          0.96521739  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:36:33.275542 14948 solver.cpp:228] Iteration 7500, loss = 0.0205132
I0209 04:36:33.275570 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:36:33.275578 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0205132 (* 1 = 0.0205132 loss)
I0209 04:36:33.275584 14948 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0209 04:37:26.787482 14948 solver.cpp:228] Iteration 7550, loss = 0.027881
I0209 04:37:26.787510 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:37:26.787518 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00514436 (* 1 = 0.00514436 loss)
I0209 04:37:26.787525 14948 sgd_solver.cpp:106] Iteration 7550, lr = 0.001
>>> 2017-02-09 04:38:18.784202 Begin model classification tests
>>> 2017-02-09 04:38:36.746299 Iteration 7600 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:38:36.746330 Iteration 7600 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:38:36.746338 Iteration 7600 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:38:36.746344 Iteration 7600 mean testing loss (rgb) 1.06372523293
>>> 2017-02-09 04:38:36.746355 Iteration 7600 mean testing loss (depth) 1.06372523293
>>> 2017-02-09 04:38:36.746375 Iteration 7600 mean testing loss (rgbd) 1.06372523293
>>> 2017-02-09 04:38:36.746395 Iteration 7600 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:38:37.778084 14948 solver.cpp:228] Iteration 7600, loss = 0.013485
I0209 04:38:37.778110 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:38:37.778118 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.013485 (* 1 = 0.013485 loss)
I0209 04:38:37.778126 14948 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0209 04:39:30.970486 14948 solver.cpp:228] Iteration 7650, loss = 0.0296971
I0209 04:39:30.970515 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:39:30.970523 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0153487 (* 1 = 0.0153487 loss)
I0209 04:39:30.970530 14948 sgd_solver.cpp:106] Iteration 7650, lr = 0.001
>>> 2017-02-09 04:40:23.056539 Begin model classification tests
>>> 2017-02-09 04:40:41.037076 Iteration 7700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:40:41.037108 Iteration 7700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:40:41.037123 Iteration 7700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:40:41.037150 Iteration 7700 mean testing loss (rgb) 1.0679919646
>>> 2017-02-09 04:40:41.037162 Iteration 7700 mean testing loss (depth) 1.0679919646
>>> 2017-02-09 04:40:41.037169 Iteration 7700 mean testing loss (rgbd) 1.0679919646
>>> 2017-02-09 04:40:41.037175 Iteration 7700 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:40:42.068641 14948 solver.cpp:228] Iteration 7700, loss = 0.0520663
I0209 04:40:42.068670 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 04:40:42.068677 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0520663 (* 1 = 0.0520663 loss)
I0209 04:40:42.068683 14948 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
I0209 04:41:35.391191 14948 solver.cpp:228] Iteration 7750, loss = 0.0293928
I0209 04:41:35.391221 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 04:41:35.391229 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0516018 (* 1 = 0.0516018 loss)
I0209 04:41:35.391235 14948 sgd_solver.cpp:106] Iteration 7750, lr = 0.001
>>> 2017-02-09 04:42:27.337833 Begin model classification tests
>>> 2017-02-09 04:42:45.271786 Iteration 7800 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 04:42:45.271816 Iteration 7800 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 04:42:45.271825 Iteration 7800 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 04:42:45.271831 Iteration 7800 mean testing loss (rgb) 1.05754101232
>>> 2017-02-09 04:42:45.271842 Iteration 7800 mean testing loss (depth) 1.05754101232
>>> 2017-02-09 04:42:45.271859 Iteration 7800 mean testing loss (rgbd) 1.05754101232
>>> 2017-02-09 04:42:45.271877 Iteration 7800 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:42:46.307421 14948 solver.cpp:228] Iteration 7800, loss = 0.0917371
I0209 04:42:46.307449 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 04:42:46.307457 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0917371 (* 1 = 0.0917371 loss)
I0209 04:42:46.307463 14948 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0209 04:43:39.460409 14948 solver.cpp:228] Iteration 7850, loss = 0.0226573
I0209 04:43:39.460438 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:43:39.460445 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00199774 (* 1 = 0.00199774 loss)
I0209 04:43:39.460451 14948 sgd_solver.cpp:106] Iteration 7850, lr = 0.001
>>> 2017-02-09 04:44:31.554901 Begin model classification tests
>>> 2017-02-09 04:44:49.461003 Iteration 7900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:44:49.461032 Iteration 7900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:44:49.461041 Iteration 7900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:44:49.461048 Iteration 7900 mean testing loss (rgb) 1.05495885053
>>> 2017-02-09 04:44:49.461059 Iteration 7900 mean testing loss (depth) 1.05495885053
>>> 2017-02-09 04:44:49.461077 Iteration 7900 mean testing loss (rgbd) 1.05495885053
>>> 2017-02-09 04:44:49.461093 Iteration 7900 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.53333333  0.94117647
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:44:50.493531 14948 solver.cpp:228] Iteration 7900, loss = 0.0948609
I0209 04:44:50.493558 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 04:44:50.493567 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0948609 (* 1 = 0.0948609 loss)
I0209 04:44:50.493573 14948 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
I0209 04:45:43.661870 14948 solver.cpp:228] Iteration 7950, loss = 0.0276739
I0209 04:45:43.661897 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 04:45:43.661906 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0295261 (* 1 = 0.0295261 loss)
I0209 04:45:43.661911 14948 sgd_solver.cpp:106] Iteration 7950, lr = 0.001
I0209 04:46:35.826418 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_8000.caffemodel
I0209 04:47:23.623950 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_8000.solverstate
>>> 2017-02-09 04:47:30.832479 Begin model classification tests
>>> 2017-02-09 04:47:48.443604 Iteration 8000 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:47:48.443632 Iteration 8000 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:47:48.443641 Iteration 8000 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:47:48.443647 Iteration 8000 mean testing loss (rgb) 1.05319835956
>>> 2017-02-09 04:47:48.443658 Iteration 8000 mean testing loss (depth) 1.05319835956
>>> 2017-02-09 04:47:48.443665 Iteration 8000 mean testing loss (rgbd) 1.05319835956
>>> 2017-02-09 04:47:48.443671 Iteration 8000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.53333333  0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:47:49.464820 14948 solver.cpp:228] Iteration 8000, loss = 0.00935682
I0209 04:47:49.464848 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:47:49.464856 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00935682 (* 1 = 0.00935682 loss)
I0209 04:47:49.464862 14948 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0209 04:48:42.891772 14948 solver.cpp:228] Iteration 8050, loss = 0.028544
I0209 04:48:42.891801 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:48:42.891815 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0165453 (* 1 = 0.0165453 loss)
I0209 04:48:42.891822 14948 sgd_solver.cpp:106] Iteration 8050, lr = 0.001
>>> 2017-02-09 04:49:35.443122 Begin model classification tests
>>> 2017-02-09 04:49:53.539396 Iteration 8100 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:49:53.539426 Iteration 8100 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:49:53.539435 Iteration 8100 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:49:53.539442 Iteration 8100 mean testing loss (rgb) 1.05458185178
>>> 2017-02-09 04:49:53.539454 Iteration 8100 mean testing loss (depth) 1.05458185178
>>> 2017-02-09 04:49:53.539474 Iteration 8100 mean testing loss (rgbd) 1.05458185178
>>> 2017-02-09 04:49:53.539494 Iteration 8100 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:49:54.609450 14948 solver.cpp:228] Iteration 8100, loss = 0.0320232
I0209 04:49:54.609478 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:49:54.609486 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0320232 (* 1 = 0.0320232 loss)
I0209 04:49:54.609493 14948 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I0209 04:50:48.320979 14948 solver.cpp:228] Iteration 8150, loss = 0.0290018
I0209 04:50:48.321007 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:50:48.321015 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.025237 (* 1 = 0.025237 loss)
I0209 04:50:48.321022 14948 sgd_solver.cpp:106] Iteration 8150, lr = 0.001
>>> 2017-02-09 04:51:40.743124 Begin model classification tests
>>> 2017-02-09 04:51:58.742864 Iteration 8200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:51:58.742894 Iteration 8200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:51:58.742902 Iteration 8200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:51:58.742908 Iteration 8200 mean testing loss (rgb) 1.04763019061
>>> 2017-02-09 04:51:58.742919 Iteration 8200 mean testing loss (depth) 1.04763019061
>>> 2017-02-09 04:51:58.742935 Iteration 8200 mean testing loss (rgbd) 1.04763019061
>>> 2017-02-09 04:51:58.742941 Iteration 8200 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:51:59.778811 14948 solver.cpp:228] Iteration 8200, loss = 0.0214529
I0209 04:51:59.778838 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:51:59.778847 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0214529 (* 1 = 0.0214529 loss)
I0209 04:51:59.778853 14948 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0209 04:52:53.421938 14948 solver.cpp:228] Iteration 8250, loss = 0.0286036
I0209 04:52:53.421967 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:52:53.421975 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0292134 (* 1 = 0.0292134 loss)
I0209 04:52:53.421982 14948 sgd_solver.cpp:106] Iteration 8250, lr = 0.001
>>> 2017-02-09 04:53:45.788847 Begin model classification tests
>>> 2017-02-09 04:54:03.705607 Iteration 8300 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 04:54:03.705649 Iteration 8300 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 04:54:03.705658 Iteration 8300 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 04:54:03.705664 Iteration 8300 mean testing loss (rgb) 1.04815712183
>>> 2017-02-09 04:54:03.705677 Iteration 8300 mean testing loss (depth) 1.04815712183
>>> 2017-02-09 04:54:03.705690 Iteration 8300 mean testing loss (rgbd) 1.04815712183
>>> 2017-02-09 04:54:03.705711 Iteration 8300 mean confusion matrix
[ 1.          0.97391304  0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:54:04.768390 14948 solver.cpp:228] Iteration 8300, loss = 0.0344334
I0209 04:54:04.768429 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:54:04.768436 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0344334 (* 1 = 0.0344334 loss)
I0209 04:54:04.768447 14948 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I0209 04:54:58.237503 14948 solver.cpp:228] Iteration 8350, loss = 0.0303362
I0209 04:54:58.237534 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:54:58.237541 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0193485 (* 1 = 0.0193485 loss)
I0209 04:54:58.237547 14948 sgd_solver.cpp:106] Iteration 8350, lr = 0.001
>>> 2017-02-09 04:55:50.490813 Begin model classification tests
>>> 2017-02-09 04:56:08.496588 Iteration 8400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 04:56:08.496618 Iteration 8400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 04:56:08.496626 Iteration 8400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 04:56:08.496632 Iteration 8400 mean testing loss (rgb) 1.03126523953
>>> 2017-02-09 04:56:08.496644 Iteration 8400 mean testing loss (depth) 1.03126523953
>>> 2017-02-09 04:56:08.496664 Iteration 8400 mean testing loss (rgbd) 1.03126523953
>>> 2017-02-09 04:56:08.496684 Iteration 8400 mean confusion matrix
[ 1.          0.9826087   0.78571429  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 04:56:09.531988 14948 solver.cpp:228] Iteration 8400, loss = 0.0215861
I0209 04:56:09.532014 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:56:09.532023 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0215861 (* 1 = 0.0215861 loss)
I0209 04:56:09.532029 14948 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0209 04:57:03.143543 14948 solver.cpp:228] Iteration 8450, loss = 0.0220055
I0209 04:57:03.143571 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:57:03.143580 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0261665 (* 1 = 0.0261665 loss)
I0209 04:57:03.143586 14948 sgd_solver.cpp:106] Iteration 8450, lr = 0.001
>>> 2017-02-09 04:57:55.140373 Begin model classification tests
>>> 2017-02-09 04:58:13.077839 Iteration 8500 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 04:58:13.077870 Iteration 8500 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 04:58:13.077877 Iteration 8500 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 04:58:13.077884 Iteration 8500 mean testing loss (rgb) 1.03121697566
>>> 2017-02-09 04:58:13.077895 Iteration 8500 mean testing loss (depth) 1.03121697566
>>> 2017-02-09 04:58:13.077915 Iteration 8500 mean testing loss (rgbd) 1.03121697566
>>> 2017-02-09 04:58:13.077934 Iteration 8500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.36363636  0.93939394  0.83333333]
I0209 04:58:14.127837 14948 solver.cpp:228] Iteration 8500, loss = 0.0160814
I0209 04:58:14.127876 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 04:58:14.127884 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0160814 (* 1 = 0.0160814 loss)
I0209 04:58:14.127894 14948 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I0209 04:59:07.248975 14948 solver.cpp:228] Iteration 8550, loss = 0.0361439
I0209 04:59:07.249003 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 04:59:07.249011 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0328879 (* 1 = 0.0328879 loss)
I0209 04:59:07.249017 14948 sgd_solver.cpp:106] Iteration 8550, lr = 0.001
>>> 2017-02-09 04:59:59.879431 Begin model classification tests
>>> 2017-02-09 05:00:17.847593 Iteration 8600 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:00:17.847623 Iteration 8600 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:00:17.847631 Iteration 8600 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:00:17.847637 Iteration 8600 mean testing loss (rgb) 1.02632239578
>>> 2017-02-09 05:00:17.847650 Iteration 8600 mean testing loss (depth) 1.02632239578
>>> 2017-02-09 05:00:17.847670 Iteration 8600 mean testing loss (rgbd) 1.02632239578
>>> 2017-02-09 05:00:17.847689 Iteration 8600 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.36363636  0.93939394  0.83333333]
I0209 05:00:18.882061 14948 solver.cpp:228] Iteration 8600, loss = 0.0528222
I0209 05:00:18.882091 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 05:00:18.882100 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0528222 (* 1 = 0.0528222 loss)
I0209 05:00:18.882107 14948 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0209 05:01:12.047164 14948 solver.cpp:228] Iteration 8650, loss = 0.0293508
I0209 05:01:12.047194 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:01:12.047202 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0140301 (* 1 = 0.0140301 loss)
I0209 05:01:12.047209 14948 sgd_solver.cpp:106] Iteration 8650, lr = 0.001
>>> 2017-02-09 05:02:04.044001 Begin model classification tests
>>> 2017-02-09 05:02:22.035203 Iteration 8700 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:02:22.035232 Iteration 8700 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:02:22.035240 Iteration 8700 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:02:22.035246 Iteration 8700 mean testing loss (rgb) 1.0399166063
>>> 2017-02-09 05:02:22.035258 Iteration 8700 mean testing loss (depth) 1.0399166063
>>> 2017-02-09 05:02:22.035279 Iteration 8700 mean testing loss (rgbd) 1.0399166063
>>> 2017-02-09 05:02:22.035297 Iteration 8700 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.36363636  0.96969697  0.83333333]
I0209 05:02:23.074151 14948 solver.cpp:228] Iteration 8700, loss = 0.0536822
I0209 05:02:23.074177 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 05:02:23.074187 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0536822 (* 1 = 0.0536822 loss)
I0209 05:02:23.074193 14948 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I0209 05:03:16.027130 14948 solver.cpp:228] Iteration 8750, loss = 0.0304551
I0209 05:03:16.027159 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:03:16.027168 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0272942 (* 1 = 0.0272942 loss)
I0209 05:03:16.027174 14948 sgd_solver.cpp:106] Iteration 8750, lr = 0.001
>>> 2017-02-09 05:04:08.032383 Begin model classification tests
>>> 2017-02-09 05:04:25.906433 Iteration 8800 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:04:25.906464 Iteration 8800 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:04:25.906473 Iteration 8800 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:04:25.906479 Iteration 8800 mean testing loss (rgb) 1.04052135538
>>> 2017-02-09 05:04:25.906492 Iteration 8800 mean testing loss (depth) 1.04052135538
>>> 2017-02-09 05:04:25.906513 Iteration 8800 mean testing loss (rgbd) 1.04052135538
>>> 2017-02-09 05:04:25.906531 Iteration 8800 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  1.          0.83333333]
I0209 05:04:26.985816 14948 solver.cpp:228] Iteration 8800, loss = 0.0286724
I0209 05:04:26.985846 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:04:26.985854 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0286724 (* 1 = 0.0286724 loss)
I0209 05:04:26.985862 14948 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0209 05:05:20.065940 14948 solver.cpp:228] Iteration 8850, loss = 0.025535
I0209 05:05:20.065970 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:05:20.065979 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0306265 (* 1 = 0.0306265 loss)
I0209 05:05:20.065984 14948 sgd_solver.cpp:106] Iteration 8850, lr = 0.001
>>> 2017-02-09 05:06:11.972752 Begin model classification tests
>>> 2017-02-09 05:06:29.947176 Iteration 8900 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 05:06:29.947208 Iteration 8900 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 05:06:29.947216 Iteration 8900 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 05:06:29.947222 Iteration 8900 mean testing loss (rgb) 1.04258531456
>>> 2017-02-09 05:06:29.947234 Iteration 8900 mean testing loss (depth) 1.04258531456
>>> 2017-02-09 05:06:29.947250 Iteration 8900 mean testing loss (rgbd) 1.04258531456
>>> 2017-02-09 05:06:29.947259 Iteration 8900 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:06:30.984549 14948 solver.cpp:228] Iteration 8900, loss = 0.0611649
I0209 05:06:30.984576 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 05:06:30.984586 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0611649 (* 1 = 0.0611649 loss)
I0209 05:06:30.984591 14948 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
I0209 05:07:23.880578 14948 solver.cpp:228] Iteration 8950, loss = 0.0307754
I0209 05:07:23.880607 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:07:23.880615 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0229878 (* 1 = 0.0229878 loss)
I0209 05:07:23.880622 14948 sgd_solver.cpp:106] Iteration 8950, lr = 0.001
I0209 05:08:15.638469 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_9000.caffemodel
I0209 05:09:04.851727 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_9000.solverstate
>>> 2017-02-09 05:09:13.042009 Begin model classification tests
>>> 2017-02-09 05:09:30.667814 Iteration 9000 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:09:30.667858 Iteration 9000 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:09:30.667866 Iteration 9000 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:09:30.667875 Iteration 9000 mean testing loss (rgb) 1.02559041602
>>> 2017-02-09 05:09:30.667896 Iteration 9000 mean testing loss (depth) 1.02559041602
>>> 2017-02-09 05:09:30.667912 Iteration 9000 mean testing loss (rgbd) 1.02559041602
>>> 2017-02-09 05:09:30.667933 Iteration 9000 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  1.          0.83333333]
I0209 05:09:31.689256 14948 solver.cpp:228] Iteration 9000, loss = 0.0129127
I0209 05:09:31.689283 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:09:31.689291 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0129127 (* 1 = 0.0129127 loss)
I0209 05:09:31.689297 14948 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0209 05:10:25.228950 14948 solver.cpp:228] Iteration 9050, loss = 0.0297238
I0209 05:10:25.228979 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:10:25.228987 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0298158 (* 1 = 0.0298158 loss)
I0209 05:10:25.228993 14948 sgd_solver.cpp:106] Iteration 9050, lr = 0.001
>>> 2017-02-09 05:11:17.870048 Begin model classification tests
>>> 2017-02-09 05:11:36.022442 Iteration 9100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 05:11:36.022472 Iteration 9100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 05:11:36.022480 Iteration 9100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 05:11:36.022487 Iteration 9100 mean testing loss (rgb) 1.02079990046
>>> 2017-02-09 05:11:36.022498 Iteration 9100 mean testing loss (depth) 1.02079990046
>>> 2017-02-09 05:11:36.022516 Iteration 9100 mean testing loss (rgbd) 1.02079990046
>>> 2017-02-09 05:11:36.022533 Iteration 9100 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.96969697  0.83333333]
I0209 05:11:37.060165 14948 solver.cpp:228] Iteration 9100, loss = 0.0138274
I0209 05:11:37.060194 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:11:37.060202 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0138274 (* 1 = 0.0138274 loss)
I0209 05:11:37.060209 14948 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
I0209 05:12:30.718794 14948 solver.cpp:228] Iteration 9150, loss = 0.0332614
I0209 05:12:30.718824 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:12:30.718832 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0534951 (* 1 = 0.0534951 loss)
I0209 05:12:30.718838 14948 sgd_solver.cpp:106] Iteration 9150, lr = 0.001
>>> 2017-02-09 05:13:23.165898 Begin model classification tests
>>> 2017-02-09 05:13:41.164160 Iteration 9200 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 05:13:41.164189 Iteration 9200 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 05:13:41.164197 Iteration 9200 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 05:13:41.164203 Iteration 9200 mean testing loss (rgb) 1.02230471588
>>> 2017-02-09 05:13:41.164215 Iteration 9200 mean testing loss (depth) 1.02230471588
>>> 2017-02-09 05:13:41.164232 Iteration 9200 mean testing loss (rgbd) 1.02230471588
>>> 2017-02-09 05:13:41.164240 Iteration 9200 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:13:42.236804 14948 solver.cpp:228] Iteration 9200, loss = 0.0140182
I0209 05:13:42.236834 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:13:42.236841 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0140182 (* 1 = 0.0140182 loss)
I0209 05:13:42.236847 14948 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0209 05:14:35.621237 14948 solver.cpp:228] Iteration 9250, loss = 0.0252611
I0209 05:14:35.621263 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:14:35.621273 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0191728 (* 1 = 0.0191728 loss)
I0209 05:14:35.621279 14948 sgd_solver.cpp:106] Iteration 9250, lr = 0.001
>>> 2017-02-09 05:15:27.646706 Begin model classification tests
>>> 2017-02-09 05:15:45.655929 Iteration 9300 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:15:45.655959 Iteration 9300 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:15:45.655967 Iteration 9300 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:15:45.655973 Iteration 9300 mean testing loss (rgb) 1.02238194879
>>> 2017-02-09 05:15:45.655985 Iteration 9300 mean testing loss (depth) 1.02238194879
>>> 2017-02-09 05:15:45.656005 Iteration 9300 mean testing loss (rgbd) 1.02238194879
>>> 2017-02-09 05:15:45.656024 Iteration 9300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.96969697  0.83333333]
I0209 05:15:46.696882 14948 solver.cpp:228] Iteration 9300, loss = 0.027674
I0209 05:15:46.696909 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:15:46.696918 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.027674 (* 1 = 0.027674 loss)
I0209 05:15:46.696924 14948 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I0209 05:16:39.764400 14948 solver.cpp:228] Iteration 9350, loss = 0.0286699
I0209 05:16:39.764426 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:16:39.764436 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0415766 (* 1 = 0.0415766 loss)
I0209 05:16:39.764446 14948 sgd_solver.cpp:106] Iteration 9350, lr = 0.001
>>> 2017-02-09 05:17:31.621834 Begin model classification tests
>>> 2017-02-09 05:17:49.596928 Iteration 9400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 05:17:49.596961 Iteration 9400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 05:17:49.596984 Iteration 9400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 05:17:49.596999 Iteration 9400 mean testing loss (rgb) 1.01332786849
>>> 2017-02-09 05:17:49.597012 Iteration 9400 mean testing loss (depth) 1.01332786849
>>> 2017-02-09 05:17:49.597036 Iteration 9400 mean testing loss (rgbd) 1.01332786849
>>> 2017-02-09 05:17:49.597056 Iteration 9400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:17:50.632298 14948 solver.cpp:228] Iteration 9400, loss = 0.011345
I0209 05:17:50.632325 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:17:50.632334 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.011345 (* 1 = 0.011345 loss)
I0209 05:17:50.632340 14948 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0209 05:18:43.627645 14948 solver.cpp:228] Iteration 9450, loss = 0.026275
I0209 05:18:43.627672 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:18:43.627682 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0290162 (* 1 = 0.0290162 loss)
I0209 05:18:43.627688 14948 sgd_solver.cpp:106] Iteration 9450, lr = 0.001
>>> 2017-02-09 05:19:35.614623 Begin model classification tests
>>> 2017-02-09 05:19:53.534397 Iteration 9500 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:19:53.534427 Iteration 9500 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:19:53.534435 Iteration 9500 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:19:53.534441 Iteration 9500 mean testing loss (rgb) 1.02777608847
>>> 2017-02-09 05:19:53.534453 Iteration 9500 mean testing loss (depth) 1.02777608847
>>> 2017-02-09 05:19:53.534473 Iteration 9500 mean testing loss (rgbd) 1.02777608847
>>> 2017-02-09 05:19:53.534492 Iteration 9500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 05:19:54.588187 14948 solver.cpp:228] Iteration 9500, loss = 0.0458618
I0209 05:19:54.588215 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 05:19:54.588223 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0458618 (* 1 = 0.0458618 loss)
I0209 05:19:54.588229 14948 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I0209 05:20:47.346279 14948 solver.cpp:228] Iteration 9550, loss = 0.0331637
I0209 05:20:47.346318 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:20:47.346328 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0261708 (* 1 = 0.0261708 loss)
I0209 05:20:47.346338 14948 sgd_solver.cpp:106] Iteration 9550, lr = 0.001
>>> 2017-02-09 05:21:38.910881 Begin model classification tests
>>> 2017-02-09 05:21:56.879554 Iteration 9600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 05:21:56.879585 Iteration 9600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 05:21:56.879593 Iteration 9600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 05:21:56.879599 Iteration 9600 mean testing loss (rgb) 1.02033588819
>>> 2017-02-09 05:21:56.879610 Iteration 9600 mean testing loss (depth) 1.02033588819
>>> 2017-02-09 05:21:56.879627 Iteration 9600 mean testing loss (rgbd) 1.02033588819
>>> 2017-02-09 05:21:56.879635 Iteration 9600 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 05:21:57.909672 14948 solver.cpp:228] Iteration 9600, loss = 0.0187501
I0209 05:21:57.909700 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:21:57.909708 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0187501 (* 1 = 0.0187501 loss)
I0209 05:21:57.909714 14948 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0209 05:22:50.656373 14948 solver.cpp:228] Iteration 9650, loss = 0.0259664
I0209 05:22:50.656402 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:22:50.656417 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0161737 (* 1 = 0.0161737 loss)
I0209 05:22:50.656424 14948 sgd_solver.cpp:106] Iteration 9650, lr = 0.001
>>> 2017-02-09 05:23:42.211789 Begin model classification tests
>>> 2017-02-09 05:24:00.196907 Iteration 9700 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:24:00.196941 Iteration 9700 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:24:00.196949 Iteration 9700 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:24:00.196955 Iteration 9700 mean testing loss (rgb) 1.01836415543
>>> 2017-02-09 05:24:00.196966 Iteration 9700 mean testing loss (depth) 1.01836415543
>>> 2017-02-09 05:24:00.196983 Iteration 9700 mean testing loss (rgbd) 1.01836415543
>>> 2017-02-09 05:24:00.197000 Iteration 9700 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.85185185  1.          0.27272727  0.93939394  0.83333333]
I0209 05:24:01.229382 14948 solver.cpp:228] Iteration 9700, loss = 0.0166373
I0209 05:24:01.229410 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:24:01.229418 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0166373 (* 1 = 0.0166373 loss)
I0209 05:24:01.229425 14948 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
I0209 05:24:54.028591 14948 solver.cpp:228] Iteration 9750, loss = 0.0244665
I0209 05:24:54.028620 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:24:54.028627 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0283507 (* 1 = 0.0283507 loss)
I0209 05:24:54.028633 14948 sgd_solver.cpp:106] Iteration 9750, lr = 0.001
>>> 2017-02-09 05:25:45.664038 Begin model classification tests
>>> 2017-02-09 05:26:03.652996 Iteration 9800 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:26:03.653027 Iteration 9800 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:26:03.653035 Iteration 9800 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:26:03.653041 Iteration 9800 mean testing loss (rgb) 1.02175384703
>>> 2017-02-09 05:26:03.653052 Iteration 9800 mean testing loss (depth) 1.02175384703
>>> 2017-02-09 05:26:03.653069 Iteration 9800 mean testing loss (rgbd) 1.02175384703
>>> 2017-02-09 05:26:03.653086 Iteration 9800 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:26:04.711947 14948 solver.cpp:228] Iteration 9800, loss = 0.0590751
I0209 05:26:04.711977 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:26:04.711987 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0590751 (* 1 = 0.0590751 loss)
I0209 05:26:04.711992 14948 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0209 05:26:57.400952 14948 solver.cpp:228] Iteration 9850, loss = 0.026399
I0209 05:26:57.400982 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:26:57.400990 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0150835 (* 1 = 0.0150835 loss)
I0209 05:26:57.400996 14948 sgd_solver.cpp:106] Iteration 9850, lr = 0.001
>>> 2017-02-09 05:27:49.010473 Begin model classification tests
>>> 2017-02-09 05:28:06.917489 Iteration 9900 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:28:06.917523 Iteration 9900 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:28:06.917542 Iteration 9900 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:28:06.917550 Iteration 9900 mean testing loss (rgb) 1.03372081036
>>> 2017-02-09 05:28:06.917575 Iteration 9900 mean testing loss (depth) 1.03372081036
>>> 2017-02-09 05:28:06.917595 Iteration 9900 mean testing loss (rgbd) 1.03372081036
>>> 2017-02-09 05:28:06.917616 Iteration 9900 mean confusion matrix
[ 1.          0.9826087   0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:28:07.949823 14948 solver.cpp:228] Iteration 9900, loss = 0.0152043
I0209 05:28:07.949851 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:28:07.949859 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0152043 (* 1 = 0.0152043 loss)
I0209 05:28:07.949865 14948 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0209 05:29:00.759275 14948 solver.cpp:228] Iteration 9950, loss = 0.0231315
I0209 05:29:00.759305 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:29:00.759313 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0222737 (* 1 = 0.0222737 loss)
I0209 05:29:00.759320 14948 sgd_solver.cpp:106] Iteration 9950, lr = 0.001
I0209 05:29:52.332370 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_10000.caffemodel
I0209 05:30:40.417426 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_10000.solverstate
>>> 2017-02-09 05:30:47.862165 Begin model classification tests
>>> 2017-02-09 05:31:05.496875 Iteration 10000 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:31:05.496908 Iteration 10000 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:31:05.496916 Iteration 10000 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:31:05.496922 Iteration 10000 mean testing loss (rgb) 1.0382934013
>>> 2017-02-09 05:31:05.496931 Iteration 10000 mean testing loss (depth) 1.0382934013
>>> 2017-02-09 05:31:05.496937 Iteration 10000 mean testing loss (rgbd) 1.0382934013
>>> 2017-02-09 05:31:05.496943 Iteration 10000 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:31:06.541309 14948 solver.cpp:228] Iteration 10000, loss = 0.0262302
I0209 05:31:06.541337 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:31:06.541344 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0262302 (* 1 = 0.0262302 loss)
I0209 05:31:06.541352 14948 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0209 05:32:00.531085 14948 solver.cpp:228] Iteration 10050, loss = 0.0282821
I0209 05:32:00.531113 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:32:00.531138 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00336151 (* 1 = 0.00336151 loss)
I0209 05:32:00.531146 14948 sgd_solver.cpp:106] Iteration 10050, lr = 0.0001
>>> 2017-02-09 05:32:53.273477 Begin model classification tests
>>> 2017-02-09 05:33:11.364307 Iteration 10100 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:33:11.364337 Iteration 10100 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:33:11.364345 Iteration 10100 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:33:11.364351 Iteration 10100 mean testing loss (rgb) 1.0376380364
>>> 2017-02-09 05:33:11.364362 Iteration 10100 mean testing loss (depth) 1.0376380364
>>> 2017-02-09 05:33:11.364379 Iteration 10100 mean testing loss (rgbd) 1.0376380364
>>> 2017-02-09 05:33:11.364395 Iteration 10100 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:33:12.400213 14948 solver.cpp:228] Iteration 10100, loss = 0.00997463
I0209 05:33:12.400241 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:33:12.400251 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00997463 (* 1 = 0.00997463 loss)
I0209 05:33:12.400257 14948 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0209 05:34:05.971218 14948 solver.cpp:228] Iteration 10150, loss = 0.0335615
I0209 05:34:05.971246 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:34:05.971256 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0436243 (* 1 = 0.0436243 loss)
I0209 05:34:05.971261 14948 sgd_solver.cpp:106] Iteration 10150, lr = 0.0001
>>> 2017-02-09 05:34:58.390611 Begin model classification tests
>>> 2017-02-09 05:35:16.441791 Iteration 10200 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:35:16.441821 Iteration 10200 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:35:16.441829 Iteration 10200 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:35:16.441835 Iteration 10200 mean testing loss (rgb) 1.03710726849
>>> 2017-02-09 05:35:16.441848 Iteration 10200 mean testing loss (depth) 1.03710726849
>>> 2017-02-09 05:35:16.441868 Iteration 10200 mean testing loss (rgbd) 1.03710726849
>>> 2017-02-09 05:35:16.441887 Iteration 10200 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:35:17.510547 14948 solver.cpp:228] Iteration 10200, loss = 0.0428137
I0209 05:35:17.510574 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:35:17.510582 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0428137 (* 1 = 0.0428137 loss)
I0209 05:35:17.510592 14948 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0209 05:36:11.043627 14948 solver.cpp:228] Iteration 10250, loss = 0.0276004
I0209 05:36:11.043656 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:36:11.043671 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00831176 (* 1 = 0.00831176 loss)
I0209 05:36:11.043678 14948 sgd_solver.cpp:106] Iteration 10250, lr = 0.0001
>>> 2017-02-09 05:37:03.264518 Begin model classification tests
>>> 2017-02-09 05:37:21.244480 Iteration 10300 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:37:21.244513 Iteration 10300 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:37:21.244529 Iteration 10300 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:37:21.244559 Iteration 10300 mean testing loss (rgb) 1.0381460397
>>> 2017-02-09 05:37:21.244580 Iteration 10300 mean testing loss (depth) 1.0381460397
>>> 2017-02-09 05:37:21.244596 Iteration 10300 mean testing loss (rgbd) 1.0381460397
>>> 2017-02-09 05:37:21.244616 Iteration 10300 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:37:22.297745 14948 solver.cpp:228] Iteration 10300, loss = 0.0217828
I0209 05:37:22.297783 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:37:22.297792 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0217828 (* 1 = 0.0217828 loss)
I0209 05:37:22.297803 14948 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0209 05:38:15.557469 14948 solver.cpp:228] Iteration 10350, loss = 0.0222455
I0209 05:38:15.557497 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:38:15.557507 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00688097 (* 1 = 0.00688097 loss)
I0209 05:38:15.557514 14948 sgd_solver.cpp:106] Iteration 10350, lr = 0.0001
>>> 2017-02-09 05:39:07.534609 Begin model classification tests
>>> 2017-02-09 05:39:25.455681 Iteration 10400 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:39:25.455710 Iteration 10400 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:39:25.455718 Iteration 10400 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:39:25.455724 Iteration 10400 mean testing loss (rgb) 1.03738654874
>>> 2017-02-09 05:39:25.455737 Iteration 10400 mean testing loss (depth) 1.03738654874
>>> 2017-02-09 05:39:25.455757 Iteration 10400 mean testing loss (rgbd) 1.03738654874
>>> 2017-02-09 05:39:25.455776 Iteration 10400 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:39:26.494061 14948 solver.cpp:228] Iteration 10400, loss = 0.048126
I0209 05:39:26.494087 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 05:39:26.494096 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.048126 (* 1 = 0.048126 loss)
I0209 05:39:26.494102 14948 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0209 05:40:19.596827 14948 solver.cpp:228] Iteration 10450, loss = 0.0268965
I0209 05:40:19.596854 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:40:19.596863 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.037942 (* 1 = 0.037942 loss)
I0209 05:40:19.596868 14948 sgd_solver.cpp:106] Iteration 10450, lr = 0.0001
>>> 2017-02-09 05:41:11.639130 Begin model classification tests
>>> 2017-02-09 05:41:29.541621 Iteration 10500 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:41:29.541651 Iteration 10500 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:41:29.541665 Iteration 10500 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:41:29.541675 Iteration 10500 mean testing loss (rgb) 1.03646140763
>>> 2017-02-09 05:41:29.541686 Iteration 10500 mean testing loss (depth) 1.03646140763
>>> 2017-02-09 05:41:29.541702 Iteration 10500 mean testing loss (rgbd) 1.03646140763
>>> 2017-02-09 05:41:29.541710 Iteration 10500 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:41:30.606020 14948 solver.cpp:228] Iteration 10500, loss = 0.0319745
I0209 05:41:30.606048 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 05:41:30.606057 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0319745 (* 1 = 0.0319745 loss)
I0209 05:41:30.606063 14948 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0209 05:42:23.741730 14948 solver.cpp:228] Iteration 10550, loss = 0.0264962
I0209 05:42:23.741758 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:42:23.741766 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0278708 (* 1 = 0.0278708 loss)
I0209 05:42:23.741772 14948 sgd_solver.cpp:106] Iteration 10550, lr = 0.0001
>>> 2017-02-09 05:43:15.643845 Begin model classification tests
>>> 2017-02-09 05:43:33.530082 Iteration 10600 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:43:33.530111 Iteration 10600 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:43:33.530119 Iteration 10600 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:43:33.530125 Iteration 10600 mean testing loss (rgb) 1.03593013132
>>> 2017-02-09 05:43:33.530135 Iteration 10600 mean testing loss (depth) 1.03593013132
>>> 2017-02-09 05:43:33.530152 Iteration 10600 mean testing loss (rgbd) 1.03593013132
>>> 2017-02-09 05:43:33.530168 Iteration 10600 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:43:34.566828 14948 solver.cpp:228] Iteration 10600, loss = 0.00131846
I0209 05:43:34.566857 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:43:34.566865 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00131846 (* 1 = 0.00131846 loss)
I0209 05:43:34.566872 14948 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0209 05:44:27.611388 14948 solver.cpp:228] Iteration 10650, loss = 0.0297604
I0209 05:44:27.611415 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 05:44:27.611423 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0466927 (* 1 = 0.0466927 loss)
I0209 05:44:27.611429 14948 sgd_solver.cpp:106] Iteration 10650, lr = 0.0001
>>> 2017-02-09 05:45:19.669521 Begin model classification tests
>>> 2017-02-09 05:45:37.552843 Iteration 10700 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:45:37.552872 Iteration 10700 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:45:37.552880 Iteration 10700 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:45:37.552886 Iteration 10700 mean testing loss (rgb) 1.03555019539
>>> 2017-02-09 05:45:37.552897 Iteration 10700 mean testing loss (depth) 1.03555019539
>>> 2017-02-09 05:45:37.552914 Iteration 10700 mean testing loss (rgbd) 1.03555019539
>>> 2017-02-09 05:45:37.552930 Iteration 10700 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:45:38.587704 14948 solver.cpp:228] Iteration 10700, loss = 0.0320957
I0209 05:45:38.587731 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:45:38.587739 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0320957 (* 1 = 0.0320957 loss)
I0209 05:45:38.587745 14948 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0209 05:46:31.757786 14948 solver.cpp:228] Iteration 10750, loss = 0.0321108
I0209 05:46:31.757817 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 05:46:31.757833 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.084407 (* 1 = 0.084407 loss)
I0209 05:46:31.757858 14948 sgd_solver.cpp:106] Iteration 10750, lr = 0.0001
>>> 2017-02-09 05:47:23.337009 Begin model classification tests
>>> 2017-02-09 05:47:41.333433 Iteration 10800 mean classification accuracy (rgb)  0.858468677494
>>> 2017-02-09 05:47:41.333464 Iteration 10800 mean classification accuracy (depth) 0.858468677494
>>> 2017-02-09 05:47:41.333472 Iteration 10800 mean classification accuracy (rgbd)  0.858468677494
>>> 2017-02-09 05:47:41.333478 Iteration 10800 mean testing loss (rgb) 1.03503629007
>>> 2017-02-09 05:47:41.333489 Iteration 10800 mean testing loss (depth) 1.03503629007
>>> 2017-02-09 05:47:41.333510 Iteration 10800 mean testing loss (rgbd) 1.03503629007
>>> 2017-02-09 05:47:41.333527 Iteration 10800 mean confusion matrix
[ 1.          0.9826087   0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:47:42.386281 14948 solver.cpp:228] Iteration 10800, loss = 0.0471188
I0209 05:47:42.386307 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:47:42.386317 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0471188 (* 1 = 0.0471188 loss)
I0209 05:47:42.386322 14948 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0209 05:48:35.490869 14948 solver.cpp:228] Iteration 10850, loss = 0.0283978
I0209 05:48:35.490896 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:48:35.490906 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0249451 (* 1 = 0.0249451 loss)
I0209 05:48:35.490911 14948 sgd_solver.cpp:106] Iteration 10850, lr = 0.0001
>>> 2017-02-09 05:49:27.292902 Begin model classification tests
>>> 2017-02-09 05:49:45.272504 Iteration 10900 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:49:45.272534 Iteration 10900 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:49:45.272542 Iteration 10900 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:49:45.272548 Iteration 10900 mean testing loss (rgb) 1.03567746325
>>> 2017-02-09 05:49:45.272559 Iteration 10900 mean testing loss (depth) 1.03567746325
>>> 2017-02-09 05:49:45.272579 Iteration 10900 mean testing loss (rgbd) 1.03567746325
>>> 2017-02-09 05:49:45.272598 Iteration 10900 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:49:46.340597 14948 solver.cpp:228] Iteration 10900, loss = 0.0115032
I0209 05:49:46.340625 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:49:46.340633 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0115032 (* 1 = 0.0115032 loss)
I0209 05:49:46.340639 14948 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0209 05:50:39.170941 14948 solver.cpp:228] Iteration 10950, loss = 0.0296392
I0209 05:50:39.170969 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:50:39.170977 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0124102 (* 1 = 0.0124102 loss)
I0209 05:50:39.170984 14948 sgd_solver.cpp:106] Iteration 10950, lr = 0.0001
I0209 05:51:31.083364 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_11000.caffemodel
I0209 05:52:14.164155 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_11000.solverstate
>>> 2017-02-09 05:52:15.174151 Begin model classification tests
>>> 2017-02-09 05:52:32.785691 Iteration 11000 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:52:32.785722 Iteration 11000 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:52:32.785730 Iteration 11000 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:52:32.785737 Iteration 11000 mean testing loss (rgb) 1.03548954889
>>> 2017-02-09 05:52:32.785748 Iteration 11000 mean testing loss (depth) 1.03548954889
>>> 2017-02-09 05:52:32.785765 Iteration 11000 mean testing loss (rgbd) 1.03548954889
>>> 2017-02-09 05:52:32.785774 Iteration 11000 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:52:33.825461 14948 solver.cpp:228] Iteration 11000, loss = 0.013758
I0209 05:52:33.825489 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:52:33.825498 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.013758 (* 1 = 0.013758 loss)
I0209 05:52:33.825506 14948 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0209 05:53:29.822540 14948 solver.cpp:228] Iteration 11050, loss = 0.0290506
I0209 05:53:29.822569 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:53:29.822578 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0221469 (* 1 = 0.0221469 loss)
I0209 05:53:29.822584 14948 sgd_solver.cpp:106] Iteration 11050, lr = 0.0001
>>> 2017-02-09 05:54:22.550307 Begin model classification tests
>>> 2017-02-09 05:54:40.740710 Iteration 11100 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:54:40.740739 Iteration 11100 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:54:40.740747 Iteration 11100 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:54:40.740753 Iteration 11100 mean testing loss (rgb) 1.03515395571
>>> 2017-02-09 05:54:40.740764 Iteration 11100 mean testing loss (depth) 1.03515395571
>>> 2017-02-09 05:54:40.740781 Iteration 11100 mean testing loss (rgbd) 1.03515395571
>>> 2017-02-09 05:54:40.740797 Iteration 11100 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:54:41.808953 14948 solver.cpp:228] Iteration 11100, loss = 0.00972389
I0209 05:54:41.808992 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:54:41.809001 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00972389 (* 1 = 0.00972389 loss)
I0209 05:54:41.809010 14948 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0209 05:55:35.615160 14948 solver.cpp:228] Iteration 11150, loss = 0.0305142
I0209 05:55:35.615187 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:55:35.615195 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0105105 (* 1 = 0.0105105 loss)
I0209 05:55:35.615201 14948 sgd_solver.cpp:106] Iteration 11150, lr = 0.0001
>>> 2017-02-09 05:56:27.918679 Begin model classification tests
>>> 2017-02-09 05:56:45.983703 Iteration 11200 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:56:45.983736 Iteration 11200 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:56:45.983751 Iteration 11200 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:56:45.983760 Iteration 11200 mean testing loss (rgb) 1.03483096255
>>> 2017-02-09 05:56:45.983770 Iteration 11200 mean testing loss (depth) 1.03483096255
>>> 2017-02-09 05:56:45.983776 Iteration 11200 mean testing loss (rgbd) 1.03483096255
>>> 2017-02-09 05:56:45.983782 Iteration 11200 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:56:47.028801 14948 solver.cpp:228] Iteration 11200, loss = 0.0562645
I0209 05:56:47.028830 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:56:47.028838 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0562645 (* 1 = 0.0562645 loss)
I0209 05:56:47.028843 14948 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0209 05:57:40.473402 14948 solver.cpp:228] Iteration 11250, loss = 0.0304997
I0209 05:57:40.473428 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 05:57:40.473436 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0271178 (* 1 = 0.0271178 loss)
I0209 05:57:40.473443 14948 sgd_solver.cpp:106] Iteration 11250, lr = 0.0001
>>> 2017-02-09 05:58:32.718459 Begin model classification tests
>>> 2017-02-09 05:58:50.705353 Iteration 11300 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 05:58:50.705387 Iteration 11300 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 05:58:50.705395 Iteration 11300 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 05:58:50.705401 Iteration 11300 mean testing loss (rgb) 1.03355924507
>>> 2017-02-09 05:58:50.705411 Iteration 11300 mean testing loss (depth) 1.03355924507
>>> 2017-02-09 05:58:50.705417 Iteration 11300 mean testing loss (rgbd) 1.03355924507
>>> 2017-02-09 05:58:50.705427 Iteration 11300 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 05:58:51.836128 14948 solver.cpp:228] Iteration 11300, loss = 0.00172197
I0209 05:58:51.836156 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 05:58:51.836164 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00172197 (* 1 = 0.00172197 loss)
I0209 05:58:51.836170 14948 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0209 05:59:45.010520 14948 solver.cpp:228] Iteration 11350, loss = 0.028647
I0209 05:59:45.010548 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 05:59:45.010557 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0359887 (* 1 = 0.0359887 loss)
I0209 05:59:45.010563 14948 sgd_solver.cpp:106] Iteration 11350, lr = 0.0001
>>> 2017-02-09 06:00:37.035556 Begin model classification tests
>>> 2017-02-09 06:00:55.022731 Iteration 11400 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 06:00:55.022761 Iteration 11400 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 06:00:55.022769 Iteration 11400 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 06:00:55.022775 Iteration 11400 mean testing loss (rgb) 1.03370245216
>>> 2017-02-09 06:00:55.022786 Iteration 11400 mean testing loss (depth) 1.03370245216
>>> 2017-02-09 06:00:55.022803 Iteration 11400 mean testing loss (rgbd) 1.03370245216
>>> 2017-02-09 06:00:55.022821 Iteration 11400 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:00:56.071379 14948 solver.cpp:228] Iteration 11400, loss = 0.0412892
I0209 06:00:56.071419 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 06:00:56.071427 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0412892 (* 1 = 0.0412892 loss)
I0209 06:00:56.071435 14948 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0209 06:01:49.257619 14948 solver.cpp:228] Iteration 11450, loss = 0.0268324
I0209 06:01:49.257649 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:01:49.257658 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0098172 (* 1 = 0.0098172 loss)
I0209 06:01:49.257664 14948 sgd_solver.cpp:106] Iteration 11450, lr = 0.0001
>>> 2017-02-09 06:02:41.167009 Begin model classification tests
>>> 2017-02-09 06:02:59.119259 Iteration 11500 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 06:02:59.119290 Iteration 11500 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 06:02:59.119299 Iteration 11500 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 06:02:59.119305 Iteration 11500 mean testing loss (rgb) 1.03340748744
>>> 2017-02-09 06:02:59.119317 Iteration 11500 mean testing loss (depth) 1.03340748744
>>> 2017-02-09 06:02:59.119334 Iteration 11500 mean testing loss (rgbd) 1.03340748744
>>> 2017-02-09 06:02:59.119350 Iteration 11500 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:03:00.152010 14948 solver.cpp:228] Iteration 11500, loss = 0.0439677
I0209 06:03:00.152039 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 06:03:00.152046 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0439677 (* 1 = 0.0439677 loss)
I0209 06:03:00.152052 14948 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0209 06:03:53.094554 14948 solver.cpp:228] Iteration 11550, loss = 0.0286031
I0209 06:03:53.094583 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:03:53.094591 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00187688 (* 1 = 0.00187688 loss)
I0209 06:03:53.094597 14948 sgd_solver.cpp:106] Iteration 11550, lr = 0.0001
>>> 2017-02-09 06:04:44.888538 Begin model classification tests
>>> 2017-02-09 06:05:02.864680 Iteration 11600 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 06:05:02.864711 Iteration 11600 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 06:05:02.864725 Iteration 11600 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 06:05:02.864752 Iteration 11600 mean testing loss (rgb) 1.03256080588
>>> 2017-02-09 06:05:02.864763 Iteration 11600 mean testing loss (depth) 1.03256080588
>>> 2017-02-09 06:05:02.864770 Iteration 11600 mean testing loss (rgbd) 1.03256080588
>>> 2017-02-09 06:05:02.864777 Iteration 11600 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:05:03.934221 14948 solver.cpp:228] Iteration 11600, loss = 0.00225263
I0209 06:05:03.934248 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:05:03.934257 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00225263 (* 1 = 0.00225263 loss)
I0209 06:05:03.934262 14948 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0209 06:05:57.033315 14948 solver.cpp:228] Iteration 11650, loss = 0.030306
I0209 06:05:57.033342 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:05:57.033351 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0304035 (* 1 = 0.0304035 loss)
I0209 06:05:57.033357 14948 sgd_solver.cpp:106] Iteration 11650, lr = 0.0001
>>> 2017-02-09 06:06:48.911961 Begin model classification tests
>>> 2017-02-09 06:07:06.873694 Iteration 11700 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 06:07:06.873755 Iteration 11700 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 06:07:06.873774 Iteration 11700 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 06:07:06.873790 Iteration 11700 mean testing loss (rgb) 1.03249548859
>>> 2017-02-09 06:07:06.873809 Iteration 11700 mean testing loss (depth) 1.03249548859
>>> 2017-02-09 06:07:06.873827 Iteration 11700 mean testing loss (rgbd) 1.03249548859
>>> 2017-02-09 06:07:06.873844 Iteration 11700 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:07:07.908865 14948 solver.cpp:228] Iteration 11700, loss = 0.0377303
I0209 06:07:07.908893 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:07:07.908902 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0377303 (* 1 = 0.0377303 loss)
I0209 06:07:07.908910 14948 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0209 06:08:00.651530 14948 solver.cpp:228] Iteration 11750, loss = 0.0228861
I0209 06:08:00.651559 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:08:00.651574 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.029373 (* 1 = 0.029373 loss)
I0209 06:08:00.651582 14948 sgd_solver.cpp:106] Iteration 11750, lr = 0.0001
>>> 2017-02-09 06:08:52.711285 Begin model classification tests
>>> 2017-02-09 06:09:10.640115 Iteration 11800 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 06:09:10.640146 Iteration 11800 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 06:09:10.640160 Iteration 11800 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 06:09:10.640170 Iteration 11800 mean testing loss (rgb) 1.03438295912
>>> 2017-02-09 06:09:10.640181 Iteration 11800 mean testing loss (depth) 1.03438295912
>>> 2017-02-09 06:09:10.640198 Iteration 11800 mean testing loss (rgbd) 1.03438295912
>>> 2017-02-09 06:09:10.640204 Iteration 11800 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:09:11.703712 14948 solver.cpp:228] Iteration 11800, loss = 0.00327344
I0209 06:09:11.703742 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:09:11.703750 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00327344 (* 1 = 0.00327344 loss)
I0209 06:09:11.703757 14948 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0209 06:10:04.587097 14948 solver.cpp:228] Iteration 11850, loss = 0.0248813
I0209 06:10:04.587124 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:10:04.587133 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0530016 (* 1 = 0.0530016 loss)
I0209 06:10:04.587139 14948 sgd_solver.cpp:106] Iteration 11850, lr = 0.0001
>>> 2017-02-09 06:10:56.270155 Begin model classification tests
>>> 2017-02-09 06:11:14.250795 Iteration 11900 mean classification accuracy (rgb)  0.856148491879
>>> 2017-02-09 06:11:14.250824 Iteration 11900 mean classification accuracy (depth) 0.856148491879
>>> 2017-02-09 06:11:14.250832 Iteration 11900 mean classification accuracy (rgbd)  0.856148491879
>>> 2017-02-09 06:11:14.250838 Iteration 11900 mean testing loss (rgb) 1.0341617049
>>> 2017-02-09 06:11:14.250849 Iteration 11900 mean testing loss (depth) 1.0341617049
>>> 2017-02-09 06:11:14.250866 Iteration 11900 mean testing loss (rgbd) 1.0341617049
>>> 2017-02-09 06:11:14.250875 Iteration 11900 mean confusion matrix
[ 1.          0.97391304  0.82142857  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:11:15.280145 14948 solver.cpp:228] Iteration 11900, loss = 0.00308395
I0209 06:11:15.280174 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:11:15.280181 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00308395 (* 1 = 0.00308395 loss)
I0209 06:11:15.280187 14948 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0209 06:12:08.048005 14948 solver.cpp:228] Iteration 11950, loss = 0.0309917
I0209 06:12:08.048033 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:12:08.048043 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00795968 (* 1 = 0.00795968 loss)
I0209 06:12:08.048048 14948 sgd_solver.cpp:106] Iteration 11950, lr = 0.0001
I0209 06:12:59.703986 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_12000.caffemodel
I0209 06:13:50.095366 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_12000.solverstate
>>> 2017-02-09 06:13:51.937099 Begin model classification tests
>>> 2017-02-09 06:14:09.569724 Iteration 12000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:14:09.569756 Iteration 12000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:14:09.569764 Iteration 12000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:14:09.569774 Iteration 12000 mean testing loss (rgb) 1.03424205366
>>> 2017-02-09 06:14:09.569802 Iteration 12000 mean testing loss (depth) 1.03424205366
>>> 2017-02-09 06:14:09.569822 Iteration 12000 mean testing loss (rgbd) 1.03424205366
>>> 2017-02-09 06:14:09.569843 Iteration 12000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:14:11.061959 14948 solver.cpp:228] Iteration 12000, loss = 0.0144401
I0209 06:14:11.061986 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:14:11.061995 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0144401 (* 1 = 0.0144401 loss)
I0209 06:14:11.062001 14948 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0209 06:15:04.630177 14948 solver.cpp:228] Iteration 12050, loss = 0.0320991
I0209 06:15:04.630203 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 06:15:04.630213 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0991473 (* 1 = 0.0991473 loss)
I0209 06:15:04.630218 14948 sgd_solver.cpp:106] Iteration 12050, lr = 0.0001
>>> 2017-02-09 06:15:57.484080 Begin model classification tests
>>> 2017-02-09 06:16:15.555653 Iteration 12100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:16:15.555681 Iteration 12100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:16:15.555689 Iteration 12100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:16:15.555695 Iteration 12100 mean testing loss (rgb) 1.0356252494
>>> 2017-02-09 06:16:15.555706 Iteration 12100 mean testing loss (depth) 1.0356252494
>>> 2017-02-09 06:16:15.555723 Iteration 12100 mean testing loss (rgbd) 1.0356252494
>>> 2017-02-09 06:16:15.555729 Iteration 12100 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:16:16.588590 14948 solver.cpp:228] Iteration 12100, loss = 0.0521798
I0209 06:16:16.588618 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:16:16.588626 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0521798 (* 1 = 0.0521798 loss)
I0209 06:16:16.588632 14948 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0209 06:17:10.577100 14948 solver.cpp:228] Iteration 12150, loss = 0.0302667
I0209 06:17:10.577127 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 06:17:10.577136 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0341975 (* 1 = 0.0341975 loss)
I0209 06:17:10.577142 14948 sgd_solver.cpp:106] Iteration 12150, lr = 0.0001
>>> 2017-02-09 06:18:03.056699 Begin model classification tests
>>> 2017-02-09 06:18:21.128304 Iteration 12200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:18:21.128337 Iteration 12200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:18:21.128351 Iteration 12200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:18:21.128378 Iteration 12200 mean testing loss (rgb) 1.03584812906
>>> 2017-02-09 06:18:21.128389 Iteration 12200 mean testing loss (depth) 1.03584812906
>>> 2017-02-09 06:18:21.128406 Iteration 12200 mean testing loss (rgbd) 1.03584812906
>>> 2017-02-09 06:18:21.128424 Iteration 12200 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:18:22.163683 14948 solver.cpp:228] Iteration 12200, loss = 0.0161704
I0209 06:18:22.163712 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:18:22.163722 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0161704 (* 1 = 0.0161704 loss)
I0209 06:18:22.163728 14948 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0209 06:19:15.579721 14948 solver.cpp:228] Iteration 12250, loss = 0.0255265
I0209 06:19:15.579747 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:19:15.579756 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00156473 (* 1 = 0.00156473 loss)
I0209 06:19:15.579761 14948 sgd_solver.cpp:106] Iteration 12250, lr = 0.0001
>>> 2017-02-09 06:20:07.770394 Begin model classification tests
>>> 2017-02-09 06:20:25.758349 Iteration 12300 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:20:25.758379 Iteration 12300 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:20:25.758390 Iteration 12300 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:20:25.758408 Iteration 12300 mean testing loss (rgb) 1.0352987484
>>> 2017-02-09 06:20:25.758429 Iteration 12300 mean testing loss (depth) 1.0352987484
>>> 2017-02-09 06:20:25.758436 Iteration 12300 mean testing loss (rgbd) 1.0352987484
>>> 2017-02-09 06:20:25.758452 Iteration 12300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:20:26.795433 14948 solver.cpp:228] Iteration 12300, loss = 0.00273948
I0209 06:20:26.795461 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:20:26.795470 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00273948 (* 1 = 0.00273948 loss)
I0209 06:20:26.795476 14948 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0209 06:21:20.097375 14948 solver.cpp:228] Iteration 12350, loss = 0.0251818
I0209 06:21:20.097404 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.9375
I0209 06:21:20.097411 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.102127 (* 1 = 0.102127 loss)
I0209 06:21:20.097417 14948 sgd_solver.cpp:106] Iteration 12350, lr = 0.0001
>>> 2017-02-09 06:22:12.106559 Begin model classification tests
>>> 2017-02-09 06:22:30.019531 Iteration 12400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:22:30.019562 Iteration 12400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:22:30.019570 Iteration 12400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:22:30.019576 Iteration 12400 mean testing loss (rgb) 1.03435734154
>>> 2017-02-09 06:22:30.019588 Iteration 12400 mean testing loss (depth) 1.03435734154
>>> 2017-02-09 06:22:30.019608 Iteration 12400 mean testing loss (rgbd) 1.03435734154
>>> 2017-02-09 06:22:30.019627 Iteration 12400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:22:31.055851 14948 solver.cpp:228] Iteration 12400, loss = 0.0793115
I0209 06:22:31.055881 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 06:22:31.055889 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0793115 (* 1 = 0.0793115 loss)
I0209 06:22:31.055896 14948 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0209 06:23:24.028259 14948 solver.cpp:228] Iteration 12450, loss = 0.0264442
I0209 06:23:24.028288 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:23:24.028297 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00558763 (* 1 = 0.00558763 loss)
I0209 06:23:24.028303 14948 sgd_solver.cpp:106] Iteration 12450, lr = 0.0001
>>> 2017-02-09 06:24:15.806946 Begin model classification tests
>>> 2017-02-09 06:24:33.766023 Iteration 12500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:24:33.766054 Iteration 12500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:24:33.766068 Iteration 12500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:24:33.766078 Iteration 12500 mean testing loss (rgb) 1.03341209493
>>> 2017-02-09 06:24:33.766088 Iteration 12500 mean testing loss (depth) 1.03341209493
>>> 2017-02-09 06:24:33.766105 Iteration 12500 mean testing loss (rgbd) 1.03341209493
>>> 2017-02-09 06:24:33.766114 Iteration 12500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:24:34.796437 14948 solver.cpp:228] Iteration 12500, loss = 0.0495319
I0209 06:24:34.796468 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:24:34.796476 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0495319 (* 1 = 0.0495319 loss)
I0209 06:24:34.796483 14948 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0209 06:25:27.682327 14948 solver.cpp:228] Iteration 12550, loss = 0.0285553
I0209 06:25:27.682363 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:25:27.682373 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.000166223 (* 1 = 0.000166223 loss)
I0209 06:25:27.682381 14948 sgd_solver.cpp:106] Iteration 12550, lr = 0.0001
>>> 2017-02-09 06:26:19.355296 Begin model classification tests
>>> 2017-02-09 06:26:37.326434 Iteration 12600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:26:37.326465 Iteration 12600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:26:37.326473 Iteration 12600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:26:37.326479 Iteration 12600 mean testing loss (rgb) 1.03421299362
>>> 2017-02-09 06:26:37.326490 Iteration 12600 mean testing loss (depth) 1.03421299362
>>> 2017-02-09 06:26:37.326511 Iteration 12600 mean testing loss (rgbd) 1.03421299362
>>> 2017-02-09 06:26:37.326529 Iteration 12600 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:26:38.363117 14948 solver.cpp:228] Iteration 12600, loss = 0.00247177
I0209 06:26:38.363147 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:26:38.363154 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00247177 (* 1 = 0.00247177 loss)
I0209 06:26:38.363160 14948 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0209 06:27:31.342753 14948 solver.cpp:228] Iteration 12650, loss = 0.0253452
I0209 06:27:31.342782 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 06:27:31.342790 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0849115 (* 1 = 0.0849115 loss)
I0209 06:27:31.342797 14948 sgd_solver.cpp:106] Iteration 12650, lr = 0.0001
>>> 2017-02-09 06:28:23.146638 Begin model classification tests
>>> 2017-02-09 06:28:41.055495 Iteration 12700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:28:41.055524 Iteration 12700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:28:41.055532 Iteration 12700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:28:41.055538 Iteration 12700 mean testing loss (rgb) 1.03340434465
>>> 2017-02-09 06:28:41.055549 Iteration 12700 mean testing loss (depth) 1.03340434465
>>> 2017-02-09 06:28:41.055566 Iteration 12700 mean testing loss (rgbd) 1.03340434465
>>> 2017-02-09 06:28:41.055572 Iteration 12700 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:28:42.093834 14948 solver.cpp:228] Iteration 12700, loss = 0.00646636
I0209 06:28:42.093864 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:28:42.093874 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00646636 (* 1 = 0.00646636 loss)
I0209 06:28:42.093881 14948 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0209 06:29:34.995352 14948 solver.cpp:228] Iteration 12750, loss = 0.024363
I0209 06:29:34.995381 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:29:34.995390 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0483279 (* 1 = 0.0483279 loss)
I0209 06:29:34.995396 14948 sgd_solver.cpp:106] Iteration 12750, lr = 0.0001
>>> 2017-02-09 06:30:26.624845 Begin model classification tests
>>> 2017-02-09 06:30:44.612870 Iteration 12800 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:30:44.612900 Iteration 12800 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:30:44.612909 Iteration 12800 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:30:44.612916 Iteration 12800 mean testing loss (rgb) 1.03295687276
>>> 2017-02-09 06:30:44.612938 Iteration 12800 mean testing loss (depth) 1.03295687276
>>> 2017-02-09 06:30:44.612945 Iteration 12800 mean testing loss (rgbd) 1.03295687276
>>> 2017-02-09 06:30:44.612961 Iteration 12800 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:30:45.647979 14948 solver.cpp:228] Iteration 12800, loss = 0.0407792
I0209 06:30:45.648006 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 06:30:45.648015 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0407792 (* 1 = 0.0407792 loss)
I0209 06:30:45.648021 14948 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0209 06:31:38.499411 14948 solver.cpp:228] Iteration 12850, loss = 0.0263911
I0209 06:31:38.499439 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:31:38.499447 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00813642 (* 1 = 0.00813642 loss)
I0209 06:31:38.499454 14948 sgd_solver.cpp:106] Iteration 12850, lr = 0.0001
>>> 2017-02-09 06:32:30.142199 Begin model classification tests
>>> 2017-02-09 06:32:48.047477 Iteration 12900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:32:48.047506 Iteration 12900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:32:48.047514 Iteration 12900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:32:48.047520 Iteration 12900 mean testing loss (rgb) 1.03386945938
>>> 2017-02-09 06:32:48.047531 Iteration 12900 mean testing loss (depth) 1.03386945938
>>> 2017-02-09 06:32:48.047551 Iteration 12900 mean testing loss (rgbd) 1.03386945938
>>> 2017-02-09 06:32:48.047570 Iteration 12900 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:32:49.081316 14948 solver.cpp:228] Iteration 12900, loss = 0.00872552
I0209 06:32:49.081344 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:32:49.081352 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00872552 (* 1 = 0.00872552 loss)
I0209 06:32:49.081359 14948 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0209 06:33:42.099773 14948 solver.cpp:228] Iteration 12950, loss = 0.034849
I0209 06:33:42.099802 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:33:42.099810 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00280765 (* 1 = 0.00280765 loss)
I0209 06:33:42.099817 14948 sgd_solver.cpp:106] Iteration 12950, lr = 0.0001
I0209 06:34:33.744709 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_13000.caffemodel
I0209 06:35:26.443023 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_13000.solverstate
>>> 2017-02-09 06:35:28.640217 Begin model classification tests
>>> 2017-02-09 06:35:46.283414 Iteration 13000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:35:46.283444 Iteration 13000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:35:46.283452 Iteration 13000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:35:46.283458 Iteration 13000 mean testing loss (rgb) 1.03352860228
>>> 2017-02-09 06:35:46.283470 Iteration 13000 mean testing loss (depth) 1.03352860228
>>> 2017-02-09 06:35:46.283486 Iteration 13000 mean testing loss (rgbd) 1.03352860228
>>> 2017-02-09 06:35:46.283503 Iteration 13000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:35:47.324828 14948 solver.cpp:228] Iteration 13000, loss = 0.00365556
I0209 06:35:47.324867 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:35:47.324874 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00365556 (* 1 = 0.00365556 loss)
I0209 06:35:47.324882 14948 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0209 06:36:40.616516 14948 solver.cpp:228] Iteration 13050, loss = 0.0271902
I0209 06:36:40.616542 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:36:40.616550 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00114591 (* 1 = 0.00114591 loss)
I0209 06:36:40.616556 14948 sgd_solver.cpp:106] Iteration 13050, lr = 0.0001
>>> 2017-02-09 06:37:32.909848 Begin model classification tests
>>> 2017-02-09 06:37:50.962409 Iteration 13100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:37:50.962441 Iteration 13100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:37:50.962449 Iteration 13100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:37:50.962455 Iteration 13100 mean testing loss (rgb) 1.03281000408
>>> 2017-02-09 06:37:50.962464 Iteration 13100 mean testing loss (depth) 1.03281000408
>>> 2017-02-09 06:37:50.962470 Iteration 13100 mean testing loss (rgbd) 1.03281000408
>>> 2017-02-09 06:37:50.962476 Iteration 13100 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:37:51.994374 14948 solver.cpp:228] Iteration 13100, loss = 0.0784111
I0209 06:37:51.994401 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 06:37:51.994410 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0784111 (* 1 = 0.0784111 loss)
I0209 06:37:51.994415 14948 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0209 06:38:45.294279 14948 solver.cpp:228] Iteration 13150, loss = 0.0282219
I0209 06:38:45.294309 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.953125
I0209 06:38:45.294324 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0841524 (* 1 = 0.0841524 loss)
I0209 06:38:45.294353 14948 sgd_solver.cpp:106] Iteration 13150, lr = 0.0001
>>> 2017-02-09 06:39:37.449399 Begin model classification tests
>>> 2017-02-09 06:39:55.422932 Iteration 13200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:39:55.422962 Iteration 13200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:39:55.422970 Iteration 13200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:39:55.422977 Iteration 13200 mean testing loss (rgb) 1.03283212511
>>> 2017-02-09 06:39:55.422989 Iteration 13200 mean testing loss (depth) 1.03283212511
>>> 2017-02-09 06:39:55.423009 Iteration 13200 mean testing loss (rgbd) 1.03283212511
>>> 2017-02-09 06:39:55.423028 Iteration 13200 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:39:56.460665 14948 solver.cpp:228] Iteration 13200, loss = 0.0290105
I0209 06:39:56.460693 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:39:56.460701 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0290105 (* 1 = 0.0290105 loss)
I0209 06:39:56.460707 14948 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0209 06:40:49.814998 14948 solver.cpp:228] Iteration 13250, loss = 0.0279696
I0209 06:40:49.815028 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:40:49.815042 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0179942 (* 1 = 0.0179942 loss)
I0209 06:40:49.815050 14948 sgd_solver.cpp:106] Iteration 13250, lr = 0.0001
>>> 2017-02-09 06:41:41.708487 Begin model classification tests
>>> 2017-02-09 06:41:59.678170 Iteration 13300 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:41:59.678200 Iteration 13300 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:41:59.678208 Iteration 13300 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:41:59.678214 Iteration 13300 mean testing loss (rgb) 1.03319646243
>>> 2017-02-09 06:41:59.678226 Iteration 13300 mean testing loss (depth) 1.03319646243
>>> 2017-02-09 06:41:59.678246 Iteration 13300 mean testing loss (rgbd) 1.03319646243
>>> 2017-02-09 06:41:59.678265 Iteration 13300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:42:00.716768 14948 solver.cpp:228] Iteration 13300, loss = 0.00217066
I0209 06:42:00.716799 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:42:00.716807 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00217066 (* 1 = 0.00217066 loss)
I0209 06:42:00.716814 14948 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0209 06:42:53.749888 14948 solver.cpp:228] Iteration 13350, loss = 0.0285861
I0209 06:42:53.749919 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:42:53.749934 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0130053 (* 1 = 0.0130053 loss)
I0209 06:42:53.749955 14948 sgd_solver.cpp:106] Iteration 13350, lr = 0.0001
>>> 2017-02-09 06:43:45.652924 Begin model classification tests
>>> 2017-02-09 06:44:03.534326 Iteration 13400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:44:03.534357 Iteration 13400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:44:03.534364 Iteration 13400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:44:03.534371 Iteration 13400 mean testing loss (rgb) 1.03288961159
>>> 2017-02-09 06:44:03.534383 Iteration 13400 mean testing loss (depth) 1.03288961159
>>> 2017-02-09 06:44:03.534403 Iteration 13400 mean testing loss (rgbd) 1.03288961159
>>> 2017-02-09 06:44:03.534422 Iteration 13400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:44:04.584470 14948 solver.cpp:228] Iteration 13400, loss = 0.00661831
I0209 06:44:04.584498 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:44:04.584507 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00661831 (* 1 = 0.00661831 loss)
I0209 06:44:04.584513 14948 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0209 06:44:57.658864 14948 solver.cpp:228] Iteration 13450, loss = 0.0239276
I0209 06:44:57.658892 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 06:44:57.658900 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0719198 (* 1 = 0.0719198 loss)
I0209 06:44:57.658907 14948 sgd_solver.cpp:106] Iteration 13450, lr = 0.0001
>>> 2017-02-09 06:45:49.431613 Begin model classification tests
>>> 2017-02-09 06:46:07.328877 Iteration 13500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:46:07.328908 Iteration 13500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:46:07.328917 Iteration 13500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:46:07.328923 Iteration 13500 mean testing loss (rgb) 1.03320517156
>>> 2017-02-09 06:46:07.328936 Iteration 13500 mean testing loss (depth) 1.03320517156
>>> 2017-02-09 06:46:07.328965 Iteration 13500 mean testing loss (rgbd) 1.03320517156
>>> 2017-02-09 06:46:07.328976 Iteration 13500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:46:08.358434 14948 solver.cpp:228] Iteration 13500, loss = 0.0457599
I0209 06:46:08.358463 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:46:08.358471 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0457599 (* 1 = 0.0457599 loss)
I0209 06:46:08.358477 14948 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0209 06:47:01.293094 14948 solver.cpp:228] Iteration 13550, loss = 0.0264111
I0209 06:47:01.293123 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:47:01.293131 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0437984 (* 1 = 0.0437984 loss)
I0209 06:47:01.293138 14948 sgd_solver.cpp:106] Iteration 13550, lr = 0.0001
>>> 2017-02-09 06:47:52.843484 Begin model classification tests
>>> 2017-02-09 06:48:10.818780 Iteration 13600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:48:10.818809 Iteration 13600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:48:10.818817 Iteration 13600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:48:10.818823 Iteration 13600 mean testing loss (rgb) 1.03320241462
>>> 2017-02-09 06:48:10.818834 Iteration 13600 mean testing loss (depth) 1.03320241462
>>> 2017-02-09 06:48:10.818851 Iteration 13600 mean testing loss (rgbd) 1.03320241462
>>> 2017-02-09 06:48:10.818857 Iteration 13600 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:48:11.852202 14948 solver.cpp:228] Iteration 13600, loss = 0.0375584
I0209 06:48:11.852231 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 06:48:11.852239 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0375584 (* 1 = 0.0375584 loss)
I0209 06:48:11.852246 14948 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0209 06:49:04.601047 14948 solver.cpp:228] Iteration 13650, loss = 0.0242458
I0209 06:49:04.601074 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:49:04.601083 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0149796 (* 1 = 0.0149796 loss)
I0209 06:49:04.601089 14948 sgd_solver.cpp:106] Iteration 13650, lr = 0.0001
>>> 2017-02-09 06:49:56.272460 Begin model classification tests
>>> 2017-02-09 06:50:14.236982 Iteration 13700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:50:14.237012 Iteration 13700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:50:14.237020 Iteration 13700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:50:14.237026 Iteration 13700 mean testing loss (rgb) 1.03310057425
>>> 2017-02-09 06:50:14.237038 Iteration 13700 mean testing loss (depth) 1.03310057425
>>> 2017-02-09 06:50:14.237058 Iteration 13700 mean testing loss (rgbd) 1.03310057425
>>> 2017-02-09 06:50:14.237076 Iteration 13700 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:50:15.289250 14948 solver.cpp:228] Iteration 13700, loss = 0.00624277
I0209 06:50:15.289279 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:50:15.289288 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00624277 (* 1 = 0.00624277 loss)
I0209 06:50:15.289294 14948 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0209 06:51:08.021625 14948 solver.cpp:228] Iteration 13750, loss = 0.0269361
I0209 06:51:08.021656 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:51:08.021664 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0117133 (* 1 = 0.0117133 loss)
I0209 06:51:08.021672 14948 sgd_solver.cpp:106] Iteration 13750, lr = 0.0001
>>> 2017-02-09 06:51:59.677987 Begin model classification tests
>>> 2017-02-09 06:52:17.648447 Iteration 13800 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:52:17.648479 Iteration 13800 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:52:17.648493 Iteration 13800 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:52:17.648502 Iteration 13800 mean testing loss (rgb) 1.03399337225
>>> 2017-02-09 06:52:17.648513 Iteration 13800 mean testing loss (depth) 1.03399337225
>>> 2017-02-09 06:52:17.648530 Iteration 13800 mean testing loss (rgbd) 1.03399337225
>>> 2017-02-09 06:52:17.648538 Iteration 13800 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:52:18.681504 14948 solver.cpp:228] Iteration 13800, loss = 0.0148784
I0209 06:52:18.681535 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:52:18.681542 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0148784 (* 1 = 0.0148784 loss)
I0209 06:52:18.681548 14948 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0209 06:53:11.665989 14948 solver.cpp:228] Iteration 13850, loss = 0.0259972
I0209 06:53:11.666020 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 06:53:11.666045 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0314105 (* 1 = 0.0314105 loss)
I0209 06:53:11.666054 14948 sgd_solver.cpp:106] Iteration 13850, lr = 0.0001
>>> 2017-02-09 06:54:03.517808 Begin model classification tests
>>> 2017-02-09 06:54:21.415294 Iteration 13900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:54:21.415325 Iteration 13900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:54:21.415333 Iteration 13900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:54:21.415340 Iteration 13900 mean testing loss (rgb) 1.03280358843
>>> 2017-02-09 06:54:21.415361 Iteration 13900 mean testing loss (depth) 1.03280358843
>>> 2017-02-09 06:54:21.415369 Iteration 13900 mean testing loss (rgbd) 1.03280358843
>>> 2017-02-09 06:54:21.415385 Iteration 13900 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:54:22.451620 14948 solver.cpp:228] Iteration 13900, loss = 0.000366375
I0209 06:54:22.451648 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:54:22.451656 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.000366375 (* 1 = 0.000366375 loss)
I0209 06:54:22.451663 14948 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0209 06:55:15.294617 14948 solver.cpp:228] Iteration 13950, loss = 0.0294125
I0209 06:55:15.294647 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 06:55:15.294663 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0601075 (* 1 = 0.0601075 loss)
I0209 06:55:15.294690 14948 sgd_solver.cpp:106] Iteration 13950, lr = 0.0001
I0209 06:56:07.018357 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_14000.caffemodel
I0209 06:56:57.964784 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_14000.solverstate
>>> 2017-02-09 06:57:00.367523 Begin model classification tests
>>> 2017-02-09 06:57:17.993082 Iteration 14000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:57:17.993112 Iteration 14000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:57:17.993120 Iteration 14000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:57:17.993126 Iteration 14000 mean testing loss (rgb) 1.03324144685
>>> 2017-02-09 06:57:17.993137 Iteration 14000 mean testing loss (depth) 1.03324144685
>>> 2017-02-09 06:57:17.993157 Iteration 14000 mean testing loss (rgbd) 1.03324144685
>>> 2017-02-09 06:57:17.993176 Iteration 14000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:57:19.015734 14948 solver.cpp:228] Iteration 14000, loss = 0.0105954
I0209 06:57:19.015763 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:57:19.015770 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0105954 (* 1 = 0.0105954 loss)
I0209 06:57:19.015776 14948 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0209 06:58:12.702433 14948 solver.cpp:228] Iteration 14050, loss = 0.0271968
I0209 06:58:12.702461 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:58:12.702483 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00510182 (* 1 = 0.00510182 loss)
I0209 06:58:12.702489 14948 sgd_solver.cpp:106] Iteration 14050, lr = 0.0001
>>> 2017-02-09 06:59:05.470649 Begin model classification tests
>>> 2017-02-09 06:59:23.670591 Iteration 14100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 06:59:23.670622 Iteration 14100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 06:59:23.670630 Iteration 14100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 06:59:23.670637 Iteration 14100 mean testing loss (rgb) 1.03337061163
>>> 2017-02-09 06:59:23.670650 Iteration 14100 mean testing loss (depth) 1.03337061163
>>> 2017-02-09 06:59:23.670671 Iteration 14100 mean testing loss (rgbd) 1.03337061163
>>> 2017-02-09 06:59:23.670689 Iteration 14100 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 06:59:24.710880 14948 solver.cpp:228] Iteration 14100, loss = 0.00632879
I0209 06:59:24.710908 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 06:59:24.710916 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00632879 (* 1 = 0.00632879 loss)
I0209 06:59:24.710922 14948 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0209 07:00:18.539571 14948 solver.cpp:228] Iteration 14150, loss = 0.0267094
I0209 07:00:18.539597 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:00:18.539605 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0102725 (* 1 = 0.0102725 loss)
I0209 07:00:18.539611 14948 sgd_solver.cpp:106] Iteration 14150, lr = 0.0001
>>> 2017-02-09 07:01:11.021724 Begin model classification tests
>>> 2017-02-09 07:01:29.111962 Iteration 14200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:01:29.111991 Iteration 14200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:01:29.111999 Iteration 14200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:01:29.112005 Iteration 14200 mean testing loss (rgb) 1.03418288955
>>> 2017-02-09 07:01:29.112017 Iteration 14200 mean testing loss (depth) 1.03418288955
>>> 2017-02-09 07:01:29.112037 Iteration 14200 mean testing loss (rgbd) 1.03418288955
>>> 2017-02-09 07:01:29.112056 Iteration 14200 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:01:30.146126 14948 solver.cpp:228] Iteration 14200, loss = 0.0205305
I0209 07:01:30.146155 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:01:30.146164 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0205305 (* 1 = 0.0205305 loss)
I0209 07:01:30.146170 14948 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0209 07:02:23.515417 14948 solver.cpp:228] Iteration 14250, loss = 0.0296324
I0209 07:02:23.515444 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:02:23.515453 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0514518 (* 1 = 0.0514518 loss)
I0209 07:02:23.515458 14948 sgd_solver.cpp:106] Iteration 14250, lr = 0.0001
>>> 2017-02-09 07:03:15.606724 Begin model classification tests
>>> 2017-02-09 07:03:33.590004 Iteration 14300 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:03:33.590036 Iteration 14300 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:03:33.590044 Iteration 14300 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:03:33.590050 Iteration 14300 mean testing loss (rgb) 1.03346595066
>>> 2017-02-09 07:03:33.590062 Iteration 14300 mean testing loss (depth) 1.03346595066
>>> 2017-02-09 07:03:33.590082 Iteration 14300 mean testing loss (rgbd) 1.03346595066
>>> 2017-02-09 07:03:33.590101 Iteration 14300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:03:34.624037 14948 solver.cpp:228] Iteration 14300, loss = 0.014066
I0209 07:03:34.624066 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:03:34.624074 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.014066 (* 1 = 0.014066 loss)
I0209 07:03:34.624080 14948 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0209 07:04:27.701129 14948 solver.cpp:228] Iteration 14350, loss = 0.0273702
I0209 07:04:27.701159 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:04:27.701166 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0369663 (* 1 = 0.0369663 loss)
I0209 07:04:27.701172 14948 sgd_solver.cpp:106] Iteration 14350, lr = 0.0001
>>> 2017-02-09 07:05:19.588680 Begin model classification tests
>>> 2017-02-09 07:05:37.580887 Iteration 14400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:05:37.580918 Iteration 14400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:05:37.580926 Iteration 14400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:05:37.580932 Iteration 14400 mean testing loss (rgb) 1.03297573385
>>> 2017-02-09 07:05:37.580943 Iteration 14400 mean testing loss (depth) 1.03297573385
>>> 2017-02-09 07:05:37.580963 Iteration 14400 mean testing loss (rgbd) 1.03297573385
>>> 2017-02-09 07:05:37.580983 Iteration 14400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:05:38.614629 14948 solver.cpp:228] Iteration 14400, loss = 0.0159744
I0209 07:05:38.614657 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:05:38.614666 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0159744 (* 1 = 0.0159744 loss)
I0209 07:05:38.614672 14948 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0209 07:06:31.792875 14948 solver.cpp:228] Iteration 14450, loss = 0.0278206
I0209 07:06:31.792903 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:06:31.792912 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0351464 (* 1 = 0.0351464 loss)
I0209 07:06:31.792918 14948 sgd_solver.cpp:106] Iteration 14450, lr = 0.0001
>>> 2017-02-09 07:07:23.562735 Begin model classification tests
>>> 2017-02-09 07:07:41.534276 Iteration 14500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:07:41.534306 Iteration 14500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:07:41.534314 Iteration 14500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:07:41.534320 Iteration 14500 mean testing loss (rgb) 1.03279000502
>>> 2017-02-09 07:07:41.534332 Iteration 14500 mean testing loss (depth) 1.03279000502
>>> 2017-02-09 07:07:41.534352 Iteration 14500 mean testing loss (rgbd) 1.03279000502
>>> 2017-02-09 07:07:41.534371 Iteration 14500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:07:42.586297 14948 solver.cpp:228] Iteration 14500, loss = 0.0257044
I0209 07:07:42.586325 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:07:42.586334 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0257044 (* 1 = 0.0257044 loss)
I0209 07:07:42.586340 14948 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0209 07:08:35.400674 14948 solver.cpp:228] Iteration 14550, loss = 0.0305348
I0209 07:08:35.400702 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:08:35.400722 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00322567 (* 1 = 0.00322567 loss)
I0209 07:08:35.400732 14948 sgd_solver.cpp:106] Iteration 14550, lr = 0.0001
>>> 2017-02-09 07:09:27.127808 Begin model classification tests
>>> 2017-02-09 07:09:45.045231 Iteration 14600 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:09:45.045261 Iteration 14600 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:09:45.045270 Iteration 14600 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:09:45.045277 Iteration 14600 mean testing loss (rgb) 1.03404168392
>>> 2017-02-09 07:09:45.045288 Iteration 14600 mean testing loss (depth) 1.03404168392
>>> 2017-02-09 07:09:45.045306 Iteration 14600 mean testing loss (rgbd) 1.03404168392
>>> 2017-02-09 07:09:45.045323 Iteration 14600 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:09:46.080759 14948 solver.cpp:228] Iteration 14600, loss = 0.00181395
I0209 07:09:46.080787 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:09:46.080796 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00181395 (* 1 = 0.00181395 loss)
I0209 07:09:46.080802 14948 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0209 07:10:38.955907 14948 solver.cpp:228] Iteration 14650, loss = 0.0301247
I0209 07:10:38.955936 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:10:38.955945 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00618405 (* 1 = 0.00618405 loss)
I0209 07:10:38.955950 14948 sgd_solver.cpp:106] Iteration 14650, lr = 0.0001
>>> 2017-02-09 07:11:30.610987 Begin model classification tests
>>> 2017-02-09 07:11:48.493378 Iteration 14700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:11:48.493411 Iteration 14700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:11:48.493419 Iteration 14700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:11:48.493425 Iteration 14700 mean testing loss (rgb) 1.03425513128
>>> 2017-02-09 07:11:48.493437 Iteration 14700 mean testing loss (depth) 1.03425513128
>>> 2017-02-09 07:11:48.493458 Iteration 14700 mean testing loss (rgbd) 1.03425513128
>>> 2017-02-09 07:11:48.493478 Iteration 14700 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:11:49.530417 14948 solver.cpp:228] Iteration 14700, loss = 0.0114551
I0209 07:11:49.530443 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:11:49.530452 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0114551 (* 1 = 0.0114551 loss)
I0209 07:11:49.530457 14948 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0209 07:12:42.345244 14948 solver.cpp:228] Iteration 14750, loss = 0.0246487
I0209 07:12:42.345273 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:12:42.345281 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.010451 (* 1 = 0.010451 loss)
I0209 07:12:42.345288 14948 sgd_solver.cpp:106] Iteration 14750, lr = 0.0001
>>> 2017-02-09 07:13:33.959967 Begin model classification tests
>>> 2017-02-09 07:13:51.875727 Iteration 14800 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:13:51.875758 Iteration 14800 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:13:51.875766 Iteration 14800 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:13:51.875773 Iteration 14800 mean testing loss (rgb) 1.03474282005
>>> 2017-02-09 07:13:51.875784 Iteration 14800 mean testing loss (depth) 1.03474282005
>>> 2017-02-09 07:13:51.875801 Iteration 14800 mean testing loss (rgbd) 1.03474282005
>>> 2017-02-09 07:13:51.875817 Iteration 14800 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:13:52.913297 14948 solver.cpp:228] Iteration 14800, loss = 0.0267934
I0209 07:13:52.913326 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:13:52.913334 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0267934 (* 1 = 0.0267934 loss)
I0209 07:13:52.913341 14948 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0209 07:14:45.715876 14948 solver.cpp:228] Iteration 14850, loss = 0.0298533
I0209 07:14:45.715905 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:14:45.715914 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.023214 (* 1 = 0.023214 loss)
I0209 07:14:45.715919 14948 sgd_solver.cpp:106] Iteration 14850, lr = 0.0001
>>> 2017-02-09 07:15:37.290172 Begin model classification tests
>>> 2017-02-09 07:15:55.217029 Iteration 14900 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:15:55.217060 Iteration 14900 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:15:55.217068 Iteration 14900 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:15:55.217074 Iteration 14900 mean testing loss (rgb) 1.03458923334
>>> 2017-02-09 07:15:55.217084 Iteration 14900 mean testing loss (depth) 1.03458923334
>>> 2017-02-09 07:15:55.217101 Iteration 14900 mean testing loss (rgbd) 1.03458923334
>>> 2017-02-09 07:15:55.217118 Iteration 14900 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:15:56.255769 14948 solver.cpp:228] Iteration 14900, loss = 0.0395596
I0209 07:15:56.255798 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:15:56.255807 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0395596 (* 1 = 0.0395596 loss)
I0209 07:15:56.255813 14948 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0209 07:16:49.062216 14948 solver.cpp:228] Iteration 14950, loss = 0.0264162
I0209 07:16:49.062244 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:16:49.062253 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.061031 (* 1 = 0.061031 loss)
I0209 07:16:49.062259 14948 sgd_solver.cpp:106] Iteration 14950, lr = 0.0001
I0209 07:17:40.784318 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_15000.caffemodel
I0209 07:18:58.311496 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_15000.solverstate
>>> 2017-02-09 07:18:59.205822 Begin model classification tests
>>> 2017-02-09 07:19:16.770272 Iteration 15000 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:19:16.770303 Iteration 15000 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:19:16.770311 Iteration 15000 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:19:16.770317 Iteration 15000 mean testing loss (rgb) 1.03490203507
>>> 2017-02-09 07:19:16.770327 Iteration 15000 mean testing loss (depth) 1.03490203507
>>> 2017-02-09 07:19:16.770344 Iteration 15000 mean testing loss (rgbd) 1.03490203507
>>> 2017-02-09 07:19:16.770353 Iteration 15000 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:19:17.809191 14948 solver.cpp:228] Iteration 15000, loss = 0.0383653
I0209 07:19:17.809221 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:19:17.809229 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0383653 (* 1 = 0.0383653 loss)
I0209 07:19:17.809236 14948 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0209 07:20:13.178812 14948 solver.cpp:228] Iteration 15050, loss = 0.0277605
I0209 07:20:13.178839 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:20:13.178854 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0171447 (* 1 = 0.0171447 loss)
I0209 07:20:13.178863 14948 sgd_solver.cpp:106] Iteration 15050, lr = 0.0001
>>> 2017-02-09 07:21:05.982732 Begin model classification tests
>>> 2017-02-09 07:21:24.086736 Iteration 15100 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:21:24.086767 Iteration 15100 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:21:24.086776 Iteration 15100 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:21:24.086783 Iteration 15100 mean testing loss (rgb) 1.03470853126
>>> 2017-02-09 07:21:24.086805 Iteration 15100 mean testing loss (depth) 1.03470853126
>>> 2017-02-09 07:21:24.086812 Iteration 15100 mean testing loss (rgbd) 1.03470853126
>>> 2017-02-09 07:21:24.086828 Iteration 15100 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:21:25.123427 14948 solver.cpp:228] Iteration 15100, loss = 0.0318998
I0209 07:21:25.123455 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:21:25.123462 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0318998 (* 1 = 0.0318998 loss)
I0209 07:21:25.123468 14948 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0209 07:22:18.739348 14948 solver.cpp:228] Iteration 15150, loss = 0.0250318
I0209 07:22:18.739377 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:22:18.739399 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0199106 (* 1 = 0.0199106 loss)
I0209 07:22:18.739406 14948 sgd_solver.cpp:106] Iteration 15150, lr = 0.0001
>>> 2017-02-09 07:23:10.915940 Begin model classification tests
>>> 2017-02-09 07:23:28.916558 Iteration 15200 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:23:28.916589 Iteration 15200 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:23:28.916597 Iteration 15200 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:23:28.916603 Iteration 15200 mean testing loss (rgb) 1.03492045048
>>> 2017-02-09 07:23:28.916614 Iteration 15200 mean testing loss (depth) 1.03492045048
>>> 2017-02-09 07:23:28.916631 Iteration 15200 mean testing loss (rgbd) 1.03492045048
>>> 2017-02-09 07:23:28.916638 Iteration 15200 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:23:29.954882 14948 solver.cpp:228] Iteration 15200, loss = 0.0236283
I0209 07:23:29.954908 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:23:29.954917 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0236283 (* 1 = 0.0236283 loss)
I0209 07:23:29.954923 14948 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0209 07:24:23.351280 14948 solver.cpp:228] Iteration 15250, loss = 0.0261439
I0209 07:24:23.351310 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:24:23.351317 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0174126 (* 1 = 0.0174126 loss)
I0209 07:24:23.351323 14948 sgd_solver.cpp:106] Iteration 15250, lr = 0.0001
>>> 2017-02-09 07:25:15.493252 Begin model classification tests
>>> 2017-02-09 07:25:33.509736 Iteration 15300 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:25:33.509767 Iteration 15300 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:25:33.509775 Iteration 15300 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:25:33.509781 Iteration 15300 mean testing loss (rgb) 1.0343859677
>>> 2017-02-09 07:25:33.509793 Iteration 15300 mean testing loss (depth) 1.0343859677
>>> 2017-02-09 07:25:33.509814 Iteration 15300 mean testing loss (rgbd) 1.0343859677
>>> 2017-02-09 07:25:33.509832 Iteration 15300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:25:34.549739 14948 solver.cpp:228] Iteration 15300, loss = 0.0235293
I0209 07:25:34.549777 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:25:34.549787 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0235293 (* 1 = 0.0235293 loss)
I0209 07:25:34.549804 14948 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0209 07:26:27.708638 14948 solver.cpp:228] Iteration 15350, loss = 0.0257797
I0209 07:26:27.708667 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:26:27.708675 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0442389 (* 1 = 0.0442389 loss)
I0209 07:26:27.708681 14948 sgd_solver.cpp:106] Iteration 15350, lr = 0.0001
>>> 2017-02-09 07:27:19.601980 Begin model classification tests
>>> 2017-02-09 07:27:37.598788 Iteration 15400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:27:37.598819 Iteration 15400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:27:37.598827 Iteration 15400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:27:37.598833 Iteration 15400 mean testing loss (rgb) 1.03429362553
>>> 2017-02-09 07:27:37.598844 Iteration 15400 mean testing loss (depth) 1.03429362553
>>> 2017-02-09 07:27:37.598865 Iteration 15400 mean testing loss (rgbd) 1.03429362553
>>> 2017-02-09 07:27:37.598883 Iteration 15400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:27:38.633489 14948 solver.cpp:228] Iteration 15400, loss = 0.0549412
I0209 07:27:38.633520 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:27:38.633529 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0549412 (* 1 = 0.0549412 loss)
I0209 07:27:38.633535 14948 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0209 07:28:31.729821 14948 solver.cpp:228] Iteration 15450, loss = 0.0293288
I0209 07:28:31.729848 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:28:31.729857 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0423509 (* 1 = 0.0423509 loss)
I0209 07:28:31.729863 14948 sgd_solver.cpp:106] Iteration 15450, lr = 0.0001
>>> 2017-02-09 07:29:23.532352 Begin model classification tests
>>> 2017-02-09 07:29:41.506031 Iteration 15500 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:29:41.506062 Iteration 15500 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:29:41.506070 Iteration 15500 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:29:41.506076 Iteration 15500 mean testing loss (rgb) 1.03526737678
>>> 2017-02-09 07:29:41.506088 Iteration 15500 mean testing loss (depth) 1.03526737678
>>> 2017-02-09 07:29:41.506108 Iteration 15500 mean testing loss (rgbd) 1.03526737678
>>> 2017-02-09 07:29:41.506128 Iteration 15500 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:29:42.541683 14948 solver.cpp:228] Iteration 15500, loss = 0.0263586
I0209 07:29:42.541710 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:29:42.541719 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0263586 (* 1 = 0.0263586 loss)
I0209 07:29:42.541725 14948 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0209 07:30:35.560735 14948 solver.cpp:228] Iteration 15550, loss = 0.0284657
I0209 07:30:35.560762 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:30:35.560771 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.003239 (* 1 = 0.003239 loss)
I0209 07:30:35.560777 14948 sgd_solver.cpp:106] Iteration 15550, lr = 0.0001
>>> 2017-02-09 07:31:27.345765 Begin model classification tests
>>> 2017-02-09 07:31:45.323588 Iteration 15600 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:31:45.323619 Iteration 15600 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:31:45.323627 Iteration 15600 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:31:45.323634 Iteration 15600 mean testing loss (rgb) 1.03354990207
>>> 2017-02-09 07:31:45.323646 Iteration 15600 mean testing loss (depth) 1.03354990207
>>> 2017-02-09 07:31:45.323663 Iteration 15600 mean testing loss (rgbd) 1.03354990207
>>> 2017-02-09 07:31:45.323680 Iteration 15600 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:31:46.354300 14948 solver.cpp:228] Iteration 15600, loss = 0.00634244
I0209 07:31:46.354327 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:31:46.354336 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00634244 (* 1 = 0.00634244 loss)
I0209 07:31:46.354341 14948 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0209 07:32:39.190734 14948 solver.cpp:228] Iteration 15650, loss = 0.0228262
I0209 07:32:39.190762 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:32:39.190771 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00668701 (* 1 = 0.00668701 loss)
I0209 07:32:39.190778 14948 sgd_solver.cpp:106] Iteration 15650, lr = 0.0001
>>> 2017-02-09 07:33:30.965368 Begin model classification tests
>>> 2017-02-09 07:33:48.891926 Iteration 15700 mean classification accuracy (rgb)  0.85150812065
>>> 2017-02-09 07:33:48.891966 Iteration 15700 mean classification accuracy (depth) 0.85150812065
>>> 2017-02-09 07:33:48.891974 Iteration 15700 mean classification accuracy (rgbd)  0.85150812065
>>> 2017-02-09 07:33:48.891980 Iteration 15700 mean testing loss (rgb) 1.03375360824
>>> 2017-02-09 07:33:48.891994 Iteration 15700 mean testing loss (depth) 1.03375360824
>>> 2017-02-09 07:33:48.892014 Iteration 15700 mean testing loss (rgbd) 1.03375360824
>>> 2017-02-09 07:33:48.892034 Iteration 15700 mean confusion matrix
[ 1.          0.96521739  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:33:49.926674 14948 solver.cpp:228] Iteration 15700, loss = 0.00895492
I0209 07:33:49.926704 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:33:49.926712 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00895492 (* 1 = 0.00895492 loss)
I0209 07:33:49.926718 14948 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0209 07:34:42.730316 14948 solver.cpp:228] Iteration 15750, loss = 0.0254033
I0209 07:34:42.730347 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:34:42.730360 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0203332 (* 1 = 0.0203332 loss)
I0209 07:34:42.730381 14948 sgd_solver.cpp:106] Iteration 15750, lr = 0.0001
>>> 2017-02-09 07:35:34.558932 Begin model classification tests
>>> 2017-02-09 07:35:52.579644 Iteration 15800 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:35:52.579674 Iteration 15800 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:35:52.579682 Iteration 15800 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:35:52.579689 Iteration 15800 mean testing loss (rgb) 1.03383325654
>>> 2017-02-09 07:35:52.579700 Iteration 15800 mean testing loss (depth) 1.03383325654
>>> 2017-02-09 07:35:52.579717 Iteration 15800 mean testing loss (rgbd) 1.03383325654
>>> 2017-02-09 07:35:52.579734 Iteration 15800 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:35:53.612632 14948 solver.cpp:228] Iteration 15800, loss = 0.000622262
I0209 07:35:53.612670 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:35:53.612679 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.000622262 (* 1 = 0.000622262 loss)
I0209 07:35:53.612687 14948 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0209 07:36:47.044363 14948 solver.cpp:228] Iteration 15850, loss = 0.030657
I0209 07:36:47.044392 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:36:47.044402 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0428329 (* 1 = 0.0428329 loss)
I0209 07:36:47.044409 14948 sgd_solver.cpp:106] Iteration 15850, lr = 0.0001
>>> 2017-02-09 07:37:39.013200 Begin model classification tests
>>> 2017-02-09 07:37:56.998933 Iteration 15900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:37:56.998964 Iteration 15900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:37:56.998972 Iteration 15900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:37:56.998978 Iteration 15900 mean testing loss (rgb) 1.03386817431
>>> 2017-02-09 07:37:56.998989 Iteration 15900 mean testing loss (depth) 1.03386817431
>>> 2017-02-09 07:37:56.999006 Iteration 15900 mean testing loss (rgbd) 1.03386817431
>>> 2017-02-09 07:37:56.999022 Iteration 15900 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:37:58.038406 14948 solver.cpp:228] Iteration 15900, loss = 0.0344568
I0209 07:37:58.038434 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:37:58.038442 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0344568 (* 1 = 0.0344568 loss)
I0209 07:37:58.038449 14948 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0209 07:38:51.374047 14948 solver.cpp:228] Iteration 15950, loss = 0.0327159
I0209 07:38:51.374075 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:38:51.374083 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0260319 (* 1 = 0.0260319 loss)
I0209 07:38:51.374089 14948 sgd_solver.cpp:106] Iteration 15950, lr = 0.0001
I0209 07:39:43.714848 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_16000.caffemodel
I0209 07:40:14.572753 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_16000.solverstate
>>> 2017-02-09 07:40:15.468663 Begin model classification tests
>>> 2017-02-09 07:40:33.087322 Iteration 16000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:40:33.087352 Iteration 16000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:40:33.087361 Iteration 16000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:40:33.087367 Iteration 16000 mean testing loss (rgb) 1.03236337318
>>> 2017-02-09 07:40:33.087379 Iteration 16000 mean testing loss (depth) 1.03236337318
>>> 2017-02-09 07:40:33.087399 Iteration 16000 mean testing loss (rgbd) 1.03236337318
>>> 2017-02-09 07:40:33.087418 Iteration 16000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:40:34.113407 14948 solver.cpp:228] Iteration 16000, loss = 0.0185655
I0209 07:40:34.113435 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:40:34.113443 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0185655 (* 1 = 0.0185655 loss)
I0209 07:40:34.113450 14948 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0209 07:41:31.374210 14948 solver.cpp:228] Iteration 16050, loss = 0.0293569
I0209 07:41:31.374238 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:41:31.374248 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0676656 (* 1 = 0.0676656 loss)
I0209 07:41:31.374253 14948 sgd_solver.cpp:106] Iteration 16050, lr = 0.0001
>>> 2017-02-09 07:42:24.404827 Begin model classification tests
>>> 2017-02-09 07:42:42.519541 Iteration 16100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:42:42.519573 Iteration 16100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:42:42.519587 Iteration 16100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:42:42.519615 Iteration 16100 mean testing loss (rgb) 1.03184372185
>>> 2017-02-09 07:42:42.519639 Iteration 16100 mean testing loss (depth) 1.03184372185
>>> 2017-02-09 07:42:42.519657 Iteration 16100 mean testing loss (rgbd) 1.03184372185
>>> 2017-02-09 07:42:42.519673 Iteration 16100 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:42:43.558248 14948 solver.cpp:228] Iteration 16100, loss = 0.0189604
I0209 07:42:43.558274 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:42:43.558282 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0189604 (* 1 = 0.0189604 loss)
I0209 07:42:43.558289 14948 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0209 07:43:37.477802 14948 solver.cpp:228] Iteration 16150, loss = 0.0284117
I0209 07:43:37.477829 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:43:37.477838 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0428214 (* 1 = 0.0428214 loss)
I0209 07:43:37.477844 14948 sgd_solver.cpp:106] Iteration 16150, lr = 0.0001
>>> 2017-02-09 07:44:30.047542 Begin model classification tests
>>> 2017-02-09 07:44:48.050013 Iteration 16200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:44:48.050043 Iteration 16200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:44:48.050052 Iteration 16200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:44:48.050058 Iteration 16200 mean testing loss (rgb) 1.03065949322
>>> 2017-02-09 07:44:48.050069 Iteration 16200 mean testing loss (depth) 1.03065949322
>>> 2017-02-09 07:44:48.050086 Iteration 16200 mean testing loss (rgbd) 1.03065949322
>>> 2017-02-09 07:44:48.050092 Iteration 16200 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:44:49.134701 14948 solver.cpp:228] Iteration 16200, loss = 0.00811766
I0209 07:44:49.134730 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:44:49.134745 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00811766 (* 1 = 0.00811766 loss)
I0209 07:44:49.134752 14948 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0209 07:45:42.768687 14948 solver.cpp:228] Iteration 16250, loss = 0.0255258
I0209 07:45:42.768717 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:45:42.768725 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0242528 (* 1 = 0.0242528 loss)
I0209 07:45:42.768731 14948 sgd_solver.cpp:106] Iteration 16250, lr = 0.0001
>>> 2017-02-09 07:46:34.922848 Begin model classification tests
>>> 2017-02-09 07:46:52.946652 Iteration 16300 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:46:52.946681 Iteration 16300 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:46:52.946689 Iteration 16300 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:46:52.946695 Iteration 16300 mean testing loss (rgb) 1.03027448
>>> 2017-02-09 07:46:52.946706 Iteration 16300 mean testing loss (depth) 1.03027448
>>> 2017-02-09 07:46:52.946723 Iteration 16300 mean testing loss (rgbd) 1.03027448
>>> 2017-02-09 07:46:52.946742 Iteration 16300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:46:53.982123 14948 solver.cpp:228] Iteration 16300, loss = 0.0392304
I0209 07:46:53.982151 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:46:53.982161 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0392304 (* 1 = 0.0392304 loss)
I0209 07:46:53.982167 14948 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0209 07:47:47.158968 14948 solver.cpp:228] Iteration 16350, loss = 0.027163
I0209 07:47:47.158996 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:47:47.159004 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00556602 (* 1 = 0.00556602 loss)
I0209 07:47:47.159010 14948 sgd_solver.cpp:106] Iteration 16350, lr = 0.0001
>>> 2017-02-09 07:48:39.342960 Begin model classification tests
>>> 2017-02-09 07:48:57.324834 Iteration 16400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:48:57.324865 Iteration 16400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:48:57.324873 Iteration 16400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:48:57.324879 Iteration 16400 mean testing loss (rgb) 1.03017176355
>>> 2017-02-09 07:48:57.324891 Iteration 16400 mean testing loss (depth) 1.03017176355
>>> 2017-02-09 07:48:57.324910 Iteration 16400 mean testing loss (rgbd) 1.03017176355
>>> 2017-02-09 07:48:57.324929 Iteration 16400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:48:58.357446 14948 solver.cpp:228] Iteration 16400, loss = 0.0231214
I0209 07:48:58.357475 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:48:58.357483 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0231214 (* 1 = 0.0231214 loss)
I0209 07:48:58.357489 14948 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0209 07:49:51.262675 14948 solver.cpp:228] Iteration 16450, loss = 0.0285694
I0209 07:49:51.262703 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:49:51.262712 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0370249 (* 1 = 0.0370249 loss)
I0209 07:49:51.262718 14948 sgd_solver.cpp:106] Iteration 16450, lr = 0.0001
>>> 2017-02-09 07:50:43.261529 Begin model classification tests
>>> 2017-02-09 07:51:01.259572 Iteration 16500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:51:01.259603 Iteration 16500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:51:01.259612 Iteration 16500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:51:01.259619 Iteration 16500 mean testing loss (rgb) 1.02938282286
>>> 2017-02-09 07:51:01.259630 Iteration 16500 mean testing loss (depth) 1.02938282286
>>> 2017-02-09 07:51:01.259649 Iteration 16500 mean testing loss (rgbd) 1.02938282286
>>> 2017-02-09 07:51:01.259656 Iteration 16500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:51:02.366803 14948 solver.cpp:228] Iteration 16500, loss = 0.0262519
I0209 07:51:02.366832 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:51:02.366842 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0262519 (* 1 = 0.0262519 loss)
I0209 07:51:02.366847 14948 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0209 07:51:55.421083 14948 solver.cpp:228] Iteration 16550, loss = 0.0231246
I0209 07:51:55.421113 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:51:55.421120 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0146791 (* 1 = 0.0146791 loss)
I0209 07:51:55.421126 14948 sgd_solver.cpp:106] Iteration 16550, lr = 0.0001
>>> 2017-02-09 07:52:47.627703 Begin model classification tests
>>> 2017-02-09 07:53:05.600839 Iteration 16600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:53:05.600869 Iteration 16600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:53:05.600878 Iteration 16600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:53:05.600884 Iteration 16600 mean testing loss (rgb) 1.02972858196
>>> 2017-02-09 07:53:05.600896 Iteration 16600 mean testing loss (depth) 1.02972858196
>>> 2017-02-09 07:53:05.600913 Iteration 16600 mean testing loss (rgbd) 1.02972858196
>>> 2017-02-09 07:53:05.600930 Iteration 16600 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:53:06.635913 14948 solver.cpp:228] Iteration 16600, loss = 0.0492816
I0209 07:53:06.635941 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:53:06.635949 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0492816 (* 1 = 0.0492816 loss)
I0209 07:53:06.635956 14948 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0209 07:53:59.384763 14948 solver.cpp:228] Iteration 16650, loss = 0.0295015
I0209 07:53:59.384791 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 07:53:59.384799 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0494891 (* 1 = 0.0494891 loss)
I0209 07:53:59.384805 14948 sgd_solver.cpp:106] Iteration 16650, lr = 0.0001
>>> 2017-02-09 07:54:50.907123 Begin model classification tests
>>> 2017-02-09 07:55:08.878720 Iteration 16700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:55:08.878751 Iteration 16700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:55:08.878760 Iteration 16700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:55:08.878766 Iteration 16700 mean testing loss (rgb) 1.03009899469
>>> 2017-02-09 07:55:08.878779 Iteration 16700 mean testing loss (depth) 1.03009899469
>>> 2017-02-09 07:55:08.878800 Iteration 16700 mean testing loss (rgbd) 1.03009899469
>>> 2017-02-09 07:55:08.878818 Iteration 16700 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:55:09.914997 14948 solver.cpp:228] Iteration 16700, loss = 0.0277605
I0209 07:55:09.915026 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:55:09.915035 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0277605 (* 1 = 0.0277605 loss)
I0209 07:55:09.915041 14948 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0209 07:56:02.662272 14948 solver.cpp:228] Iteration 16750, loss = 0.0290065
I0209 07:56:02.662300 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:56:02.662308 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0211109 (* 1 = 0.0211109 loss)
I0209 07:56:02.662314 14948 sgd_solver.cpp:106] Iteration 16750, lr = 0.0001
>>> 2017-02-09 07:56:54.109914 Begin model classification tests
>>> 2017-02-09 07:57:12.011730 Iteration 16800 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:57:12.011761 Iteration 16800 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:57:12.011772 Iteration 16800 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:57:12.011789 Iteration 16800 mean testing loss (rgb) 1.02970291302
>>> 2017-02-09 07:57:12.011810 Iteration 16800 mean testing loss (depth) 1.02970291302
>>> 2017-02-09 07:57:12.011817 Iteration 16800 mean testing loss (rgbd) 1.02970291302
>>> 2017-02-09 07:57:12.011833 Iteration 16800 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:57:13.042987 14948 solver.cpp:228] Iteration 16800, loss = 0.0481775
I0209 07:57:13.043016 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 07:57:13.043025 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0481775 (* 1 = 0.0481775 loss)
I0209 07:57:13.043030 14948 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0209 07:58:05.650811 14948 solver.cpp:228] Iteration 16850, loss = 0.0295867
I0209 07:58:05.650840 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:58:05.650851 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0203154 (* 1 = 0.0203154 loss)
I0209 07:58:05.650856 14948 sgd_solver.cpp:106] Iteration 16850, lr = 0.0001
>>> 2017-02-09 07:58:57.257012 Begin model classification tests
>>> 2017-02-09 07:59:15.143512 Iteration 16900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 07:59:15.143543 Iteration 16900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 07:59:15.143552 Iteration 16900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 07:59:15.143559 Iteration 16900 mean testing loss (rgb) 1.03056671571
>>> 2017-02-09 07:59:15.143570 Iteration 16900 mean testing loss (depth) 1.03056671571
>>> 2017-02-09 07:59:15.143588 Iteration 16900 mean testing loss (rgbd) 1.03056671571
>>> 2017-02-09 07:59:15.143596 Iteration 16900 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 07:59:16.179832 14948 solver.cpp:228] Iteration 16900, loss = 0.00820554
I0209 07:59:16.179860 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 07:59:16.179869 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00820554 (* 1 = 0.00820554 loss)
I0209 07:59:16.179875 14948 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0209 08:00:09.066712 14948 solver.cpp:228] Iteration 16950, loss = 0.0275825
I0209 08:00:09.066741 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:00:09.066751 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.01108 (* 1 = 0.01108 loss)
I0209 08:00:09.066756 14948 sgd_solver.cpp:106] Iteration 16950, lr = 0.0001
I0209 08:01:00.581786 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_17000.caffemodel
I0209 08:01:48.176288 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_17000.solverstate
>>> 2017-02-09 08:01:49.073118 Begin model classification tests
>>> 2017-02-09 08:02:06.695338 Iteration 17000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:02:06.695369 Iteration 17000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:02:06.695377 Iteration 17000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:02:06.695384 Iteration 17000 mean testing loss (rgb) 1.03008014536
>>> 2017-02-09 08:02:06.695395 Iteration 17000 mean testing loss (depth) 1.03008014536
>>> 2017-02-09 08:02:06.695413 Iteration 17000 mean testing loss (rgbd) 1.03008014536
>>> 2017-02-09 08:02:06.695429 Iteration 17000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:02:07.716678 14948 solver.cpp:228] Iteration 17000, loss = 0.00916475
I0209 08:02:07.716707 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:02:07.716717 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00916475 (* 1 = 0.00916475 loss)
I0209 08:02:07.716722 14948 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0209 08:03:03.195467 14948 solver.cpp:228] Iteration 17050, loss = 0.0282926
I0209 08:03:03.195495 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:03:03.195503 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0128906 (* 1 = 0.0128906 loss)
I0209 08:03:03.195509 14948 sgd_solver.cpp:106] Iteration 17050, lr = 0.0001
>>> 2017-02-09 08:03:55.704130 Begin model classification tests
>>> 2017-02-09 08:04:13.771183 Iteration 17100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:04:13.771212 Iteration 17100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:04:13.771220 Iteration 17100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:04:13.771226 Iteration 17100 mean testing loss (rgb) 1.0314707487
>>> 2017-02-09 08:04:13.771237 Iteration 17100 mean testing loss (depth) 1.0314707487
>>> 2017-02-09 08:04:13.771254 Iteration 17100 mean testing loss (rgbd) 1.0314707487
>>> 2017-02-09 08:04:13.771260 Iteration 17100 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:04:14.806557 14948 solver.cpp:228] Iteration 17100, loss = 0.00614237
I0209 08:04:14.806587 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:04:14.806596 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00614237 (* 1 = 0.00614237 loss)
I0209 08:04:14.806602 14948 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0209 08:05:08.435134 14948 solver.cpp:228] Iteration 17150, loss = 0.0279755
I0209 08:05:08.435163 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:05:08.435178 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0376351 (* 1 = 0.0376351 loss)
I0209 08:05:08.435185 14948 sgd_solver.cpp:106] Iteration 17150, lr = 0.0001
>>> 2017-02-09 08:06:00.519452 Begin model classification tests
>>> 2017-02-09 08:06:18.499791 Iteration 17200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:06:18.499821 Iteration 17200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:06:18.499837 Iteration 17200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:06:18.499847 Iteration 17200 mean testing loss (rgb) 1.03175466156
>>> 2017-02-09 08:06:18.499858 Iteration 17200 mean testing loss (depth) 1.03175466156
>>> 2017-02-09 08:06:18.499875 Iteration 17200 mean testing loss (rgbd) 1.03175466156
>>> 2017-02-09 08:06:18.499882 Iteration 17200 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:06:19.533305 14948 solver.cpp:228] Iteration 17200, loss = 0.0239957
I0209 08:06:19.533342 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:06:19.533351 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0239957 (* 1 = 0.0239957 loss)
I0209 08:06:19.533360 14948 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0209 08:07:12.532843 14948 solver.cpp:228] Iteration 17250, loss = 0.0287312
I0209 08:07:12.532871 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:07:12.532881 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0646344 (* 1 = 0.0646344 loss)
I0209 08:07:12.532886 14948 sgd_solver.cpp:106] Iteration 17250, lr = 0.0001
>>> 2017-02-09 08:08:04.490723 Begin model classification tests
>>> 2017-02-09 08:08:22.407997 Iteration 17300 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:08:22.408027 Iteration 17300 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:08:22.408035 Iteration 17300 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:08:22.408041 Iteration 17300 mean testing loss (rgb) 1.03211696979
>>> 2017-02-09 08:08:22.408052 Iteration 17300 mean testing loss (depth) 1.03211696979
>>> 2017-02-09 08:08:22.408069 Iteration 17300 mean testing loss (rgbd) 1.03211696979
>>> 2017-02-09 08:08:22.408086 Iteration 17300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:08:23.441015 14948 solver.cpp:228] Iteration 17300, loss = 0.0381325
I0209 08:08:23.441042 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:08:23.441051 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0381325 (* 1 = 0.0381325 loss)
I0209 08:08:23.441057 14948 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0209 08:09:16.332248 14948 solver.cpp:228] Iteration 17350, loss = 0.0246425
I0209 08:09:16.332276 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:09:16.332284 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0310943 (* 1 = 0.0310943 loss)
I0209 08:09:16.332291 14948 sgd_solver.cpp:106] Iteration 17350, lr = 0.0001
>>> 2017-02-09 08:10:07.893935 Begin model classification tests
>>> 2017-02-09 08:10:25.786523 Iteration 17400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:10:25.786554 Iteration 17400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:10:25.786562 Iteration 17400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:10:25.786568 Iteration 17400 mean testing loss (rgb) 1.03128098599
>>> 2017-02-09 08:10:25.786580 Iteration 17400 mean testing loss (depth) 1.03128098599
>>> 2017-02-09 08:10:25.786601 Iteration 17400 mean testing loss (rgbd) 1.03128098599
>>> 2017-02-09 08:10:25.786620 Iteration 17400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:10:26.816977 14948 solver.cpp:228] Iteration 17400, loss = 0.0320846
I0209 08:10:26.817008 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:10:26.817016 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0320846 (* 1 = 0.0320846 loss)
I0209 08:10:26.817023 14948 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0209 08:11:19.722863 14948 solver.cpp:228] Iteration 17450, loss = 0.0293078
I0209 08:11:19.722892 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:11:19.722900 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0101534 (* 1 = 0.0101534 loss)
I0209 08:11:19.722906 14948 sgd_solver.cpp:106] Iteration 17450, lr = 0.0001
>>> 2017-02-09 08:12:11.477569 Begin model classification tests
>>> 2017-02-09 08:12:29.364681 Iteration 17500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:12:29.364711 Iteration 17500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:12:29.364719 Iteration 17500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:12:29.364724 Iteration 17500 mean testing loss (rgb) 1.03139041054
>>> 2017-02-09 08:12:29.364736 Iteration 17500 mean testing loss (depth) 1.03139041054
>>> 2017-02-09 08:12:29.364753 Iteration 17500 mean testing loss (rgbd) 1.03139041054
>>> 2017-02-09 08:12:29.364761 Iteration 17500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:12:30.452486 14948 solver.cpp:228] Iteration 17500, loss = 0.0274778
I0209 08:12:30.452514 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:12:30.452529 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0274778 (* 1 = 0.0274778 loss)
I0209 08:12:30.452556 14948 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0209 08:13:23.145534 14948 solver.cpp:228] Iteration 17550, loss = 0.0262378
I0209 08:13:23.145560 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:13:23.145568 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00852614 (* 1 = 0.00852614 loss)
I0209 08:13:23.145573 14948 sgd_solver.cpp:106] Iteration 17550, lr = 0.0001
>>> 2017-02-09 08:14:14.730181 Begin model classification tests
>>> 2017-02-09 08:14:32.700502 Iteration 17600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:14:32.700536 Iteration 17600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:14:32.700544 Iteration 17600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:14:32.700550 Iteration 17600 mean testing loss (rgb) 1.03201490729
>>> 2017-02-09 08:14:32.700563 Iteration 17600 mean testing loss (depth) 1.03201490729
>>> 2017-02-09 08:14:32.700583 Iteration 17600 mean testing loss (rgbd) 1.03201490729
>>> 2017-02-09 08:14:32.700602 Iteration 17600 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:14:33.732424 14948 solver.cpp:228] Iteration 17600, loss = 0.00461817
I0209 08:14:33.732451 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:14:33.732460 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00461817 (* 1 = 0.00461817 loss)
I0209 08:14:33.732466 14948 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0209 08:15:26.411056 14948 solver.cpp:228] Iteration 17650, loss = 0.0247007
I0209 08:15:26.411085 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:15:26.411094 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0302806 (* 1 = 0.0302806 loss)
I0209 08:15:26.411100 14948 sgd_solver.cpp:106] Iteration 17650, lr = 0.0001
>>> 2017-02-09 08:16:17.939247 Begin model classification tests
>>> 2017-02-09 08:16:35.829617 Iteration 17700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:16:35.829646 Iteration 17700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:16:35.829654 Iteration 17700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:16:35.829660 Iteration 17700 mean testing loss (rgb) 1.03205425292
>>> 2017-02-09 08:16:35.829671 Iteration 17700 mean testing loss (depth) 1.03205425292
>>> 2017-02-09 08:16:35.829688 Iteration 17700 mean testing loss (rgbd) 1.03205425292
>>> 2017-02-09 08:16:35.829707 Iteration 17700 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:16:36.860153 14948 solver.cpp:228] Iteration 17700, loss = 0.00141676
I0209 08:16:36.860182 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:16:36.860190 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00141676 (* 1 = 0.00141676 loss)
I0209 08:16:36.860196 14948 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0209 08:17:29.494546 14948 solver.cpp:228] Iteration 17750, loss = 0.0257657
I0209 08:17:29.494575 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:17:29.494583 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0307052 (* 1 = 0.0307052 loss)
I0209 08:17:29.494590 14948 sgd_solver.cpp:106] Iteration 17750, lr = 0.0001
>>> 2017-02-09 08:18:20.991850 Begin model classification tests
>>> 2017-02-09 08:18:38.850812 Iteration 17800 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:18:38.850842 Iteration 17800 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:18:38.850850 Iteration 17800 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:18:38.850856 Iteration 17800 mean testing loss (rgb) 1.0319099297
>>> 2017-02-09 08:18:38.850867 Iteration 17800 mean testing loss (depth) 1.0319099297
>>> 2017-02-09 08:18:38.850884 Iteration 17800 mean testing loss (rgbd) 1.0319099297
>>> 2017-02-09 08:18:38.850900 Iteration 17800 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:18:39.881937 14948 solver.cpp:228] Iteration 17800, loss = 0.0318312
I0209 08:18:39.881964 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:18:39.881973 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0318312 (* 1 = 0.0318312 loss)
I0209 08:18:39.881978 14948 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0209 08:19:32.359477 14948 solver.cpp:228] Iteration 17850, loss = 0.0274865
I0209 08:19:32.359516 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:19:32.359525 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0559882 (* 1 = 0.0559882 loss)
I0209 08:19:32.359532 14948 sgd_solver.cpp:106] Iteration 17850, lr = 0.0001
>>> 2017-02-09 08:20:23.835214 Begin model classification tests
>>> 2017-02-09 08:20:41.691318 Iteration 17900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:20:41.691349 Iteration 17900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:20:41.691357 Iteration 17900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:20:41.691363 Iteration 17900 mean testing loss (rgb) 1.03161498666
>>> 2017-02-09 08:20:41.691374 Iteration 17900 mean testing loss (depth) 1.03161498666
>>> 2017-02-09 08:20:41.691390 Iteration 17900 mean testing loss (rgbd) 1.03161498666
>>> 2017-02-09 08:20:41.691407 Iteration 17900 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:20:42.720679 14948 solver.cpp:228] Iteration 17900, loss = 0.0190989
I0209 08:20:42.720708 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:20:42.720716 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0190989 (* 1 = 0.0190989 loss)
I0209 08:20:42.720734 14948 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0209 08:21:35.058763 14948 solver.cpp:228] Iteration 17950, loss = 0.0229838
I0209 08:21:35.058791 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:21:35.058800 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0410566 (* 1 = 0.0410566 loss)
I0209 08:21:35.058805 14948 sgd_solver.cpp:106] Iteration 17950, lr = 0.0001
I0209 08:22:26.327975 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_18000.caffemodel
I0209 08:23:21.488597 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_18000.solverstate
>>> 2017-02-09 08:23:22.385913 Begin model classification tests
>>> 2017-02-09 08:23:40.007141 Iteration 18000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:23:40.007172 Iteration 18000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:23:40.007180 Iteration 18000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:23:40.007186 Iteration 18000 mean testing loss (rgb) 1.03084487617
>>> 2017-02-09 08:23:40.007198 Iteration 18000 mean testing loss (depth) 1.03084487617
>>> 2017-02-09 08:23:40.007215 Iteration 18000 mean testing loss (rgbd) 1.03084487617
>>> 2017-02-09 08:23:40.007231 Iteration 18000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:23:41.039582 14948 solver.cpp:228] Iteration 18000, loss = 0.0201477
I0209 08:23:41.039611 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:23:41.039620 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0201477 (* 1 = 0.0201477 loss)
I0209 08:23:41.039626 14948 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0209 08:24:37.424387 14948 solver.cpp:228] Iteration 18050, loss = 0.0240143
I0209 08:24:37.424417 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:24:37.424432 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.050757 (* 1 = 0.050757 loss)
I0209 08:24:37.424438 14948 sgd_solver.cpp:106] Iteration 18050, lr = 0.0001
>>> 2017-02-09 08:25:30.128796 Begin model classification tests
>>> 2017-02-09 08:25:48.204525 Iteration 18100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:25:48.204555 Iteration 18100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:25:48.204563 Iteration 18100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:25:48.204569 Iteration 18100 mean testing loss (rgb) 1.03203710792
>>> 2017-02-09 08:25:48.204580 Iteration 18100 mean testing loss (depth) 1.03203710792
>>> 2017-02-09 08:25:48.204596 Iteration 18100 mean testing loss (rgbd) 1.03203710792
>>> 2017-02-09 08:25:48.204613 Iteration 18100 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:25:49.269753 14948 solver.cpp:228] Iteration 18100, loss = 0.00657187
I0209 08:25:49.269795 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:25:49.269812 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00657187 (* 1 = 0.00657187 loss)
I0209 08:25:49.269821 14948 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0209 08:26:42.801671 14948 solver.cpp:228] Iteration 18150, loss = 0.0253862
I0209 08:26:42.801699 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:26:42.801707 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0740662 (* 1 = 0.0740662 loss)
I0209 08:26:42.801714 14948 sgd_solver.cpp:106] Iteration 18150, lr = 0.0001
>>> 2017-02-09 08:27:34.668637 Begin model classification tests
>>> 2017-02-09 08:27:52.639325 Iteration 18200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:27:52.639354 Iteration 18200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:27:52.639362 Iteration 18200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:27:52.639368 Iteration 18200 mean testing loss (rgb) 1.03258638226
>>> 2017-02-09 08:27:52.639381 Iteration 18200 mean testing loss (depth) 1.03258638226
>>> 2017-02-09 08:27:52.639400 Iteration 18200 mean testing loss (rgbd) 1.03258638226
>>> 2017-02-09 08:27:52.639419 Iteration 18200 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:27:53.700232 14948 solver.cpp:228] Iteration 18200, loss = 0.0246215
I0209 08:27:53.700261 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:27:53.700269 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0246215 (* 1 = 0.0246215 loss)
I0209 08:27:53.700275 14948 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0209 08:28:46.673013 14948 solver.cpp:228] Iteration 18250, loss = 0.0234032
I0209 08:28:46.673040 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:28:46.673048 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0485155 (* 1 = 0.0485155 loss)
I0209 08:28:46.673054 14948 sgd_solver.cpp:106] Iteration 18250, lr = 0.0001
>>> 2017-02-09 08:29:38.336910 Begin model classification tests
>>> 2017-02-09 08:29:56.204297 Iteration 18300 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:29:56.204328 Iteration 18300 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:29:56.204336 Iteration 18300 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:29:56.204342 Iteration 18300 mean testing loss (rgb) 1.0328110805
>>> 2017-02-09 08:29:56.204353 Iteration 18300 mean testing loss (depth) 1.0328110805
>>> 2017-02-09 08:29:56.204370 Iteration 18300 mean testing loss (rgbd) 1.0328110805
>>> 2017-02-09 08:29:56.204376 Iteration 18300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:29:57.236631 14948 solver.cpp:228] Iteration 18300, loss = 0.0101983
I0209 08:29:57.236660 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:29:57.236668 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0101983 (* 1 = 0.0101983 loss)
I0209 08:29:57.236673 14948 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0209 08:30:49.768993 14948 solver.cpp:228] Iteration 18350, loss = 0.0325946
I0209 08:30:49.769022 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:30:49.769032 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.030667 (* 1 = 0.030667 loss)
I0209 08:30:49.769037 14948 sgd_solver.cpp:106] Iteration 18350, lr = 0.0001
>>> 2017-02-09 08:31:41.220918 Begin model classification tests
>>> 2017-02-09 08:31:59.079265 Iteration 18400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:31:59.079296 Iteration 18400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:31:59.079311 Iteration 18400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:31:59.079322 Iteration 18400 mean testing loss (rgb) 1.03352443006
>>> 2017-02-09 08:31:59.079333 Iteration 18400 mean testing loss (depth) 1.03352443006
>>> 2017-02-09 08:31:59.079350 Iteration 18400 mean testing loss (rgbd) 1.03352443006
>>> 2017-02-09 08:31:59.079357 Iteration 18400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:32:00.111366 14948 solver.cpp:228] Iteration 18400, loss = 0.0243453
I0209 08:32:00.111394 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:32:00.111402 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0243453 (* 1 = 0.0243453 loss)
I0209 08:32:00.111408 14948 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0209 08:32:52.737275 14948 solver.cpp:228] Iteration 18450, loss = 0.0298906
I0209 08:32:52.737305 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:32:52.737313 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0382408 (* 1 = 0.0382408 loss)
I0209 08:32:52.737320 14948 sgd_solver.cpp:106] Iteration 18450, lr = 0.0001
>>> 2017-02-09 08:33:44.191503 Begin model classification tests
>>> 2017-02-09 08:34:02.052509 Iteration 18500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:34:02.052538 Iteration 18500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:34:02.052546 Iteration 18500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:34:02.052552 Iteration 18500 mean testing loss (rgb) 1.03350957665
>>> 2017-02-09 08:34:02.052563 Iteration 18500 mean testing loss (depth) 1.03350957665
>>> 2017-02-09 08:34:02.052580 Iteration 18500 mean testing loss (rgbd) 1.03350957665
>>> 2017-02-09 08:34:02.052597 Iteration 18500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:34:03.085142 14948 solver.cpp:228] Iteration 18500, loss = 0.0303075
I0209 08:34:03.085170 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:34:03.085177 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0303075 (* 1 = 0.0303075 loss)
I0209 08:34:03.085183 14948 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0209 08:34:55.571507 14948 solver.cpp:228] Iteration 18550, loss = 0.0284757
I0209 08:34:55.571534 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:34:55.571543 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0146489 (* 1 = 0.0146489 loss)
I0209 08:34:55.571549 14948 sgd_solver.cpp:106] Iteration 18550, lr = 0.0001
>>> 2017-02-09 08:35:46.676319 Begin model classification tests
>>> 2017-02-09 08:36:04.561915 Iteration 18600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:36:04.561944 Iteration 18600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:36:04.561951 Iteration 18600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:36:04.561957 Iteration 18600 mean testing loss (rgb) 1.03379472458
>>> 2017-02-09 08:36:04.561968 Iteration 18600 mean testing loss (depth) 1.03379472458
>>> 2017-02-09 08:36:04.561988 Iteration 18600 mean testing loss (rgbd) 1.03379472458
>>> 2017-02-09 08:36:04.562008 Iteration 18600 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:36:05.612653 14948 solver.cpp:228] Iteration 18600, loss = 0.011728
I0209 08:36:05.612681 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:36:05.612691 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.011728 (* 1 = 0.011728 loss)
I0209 08:36:05.612697 14948 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0209 08:36:58.162894 14948 solver.cpp:228] Iteration 18650, loss = 0.0252641
I0209 08:36:58.162922 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:36:58.162931 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0376798 (* 1 = 0.0376798 loss)
I0209 08:36:58.162937 14948 sgd_solver.cpp:106] Iteration 18650, lr = 0.0001
>>> 2017-02-09 08:37:49.552468 Begin model classification tests
>>> 2017-02-09 08:38:07.535573 Iteration 18700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:38:07.535612 Iteration 18700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:38:07.535620 Iteration 18700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:38:07.535627 Iteration 18700 mean testing loss (rgb) 1.03445986376
>>> 2017-02-09 08:38:07.535648 Iteration 18700 mean testing loss (depth) 1.03445986376
>>> 2017-02-09 08:38:07.535655 Iteration 18700 mean testing loss (rgbd) 1.03445986376
>>> 2017-02-09 08:38:07.535662 Iteration 18700 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:38:08.568665 14948 solver.cpp:228] Iteration 18700, loss = 0.000427224
I0209 08:38:08.568693 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:38:08.568701 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.000427224 (* 1 = 0.000427224 loss)
I0209 08:38:08.568707 14948 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0209 08:39:01.105757 14948 solver.cpp:228] Iteration 18750, loss = 0.0265581
I0209 08:39:01.105787 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:39:01.105795 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.063922 (* 1 = 0.063922 loss)
I0209 08:39:01.105801 14948 sgd_solver.cpp:106] Iteration 18750, lr = 0.0001
>>> 2017-02-09 08:39:52.595336 Begin model classification tests
>>> 2017-02-09 08:40:10.481810 Iteration 18800 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:40:10.481842 Iteration 18800 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:40:10.481856 Iteration 18800 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:40:10.481886 Iteration 18800 mean testing loss (rgb) 1.03454348084
>>> 2017-02-09 08:40:10.481907 Iteration 18800 mean testing loss (depth) 1.03454348084
>>> 2017-02-09 08:40:10.481923 Iteration 18800 mean testing loss (rgbd) 1.03454348084
>>> 2017-02-09 08:40:10.481940 Iteration 18800 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:40:11.512768 14948 solver.cpp:228] Iteration 18800, loss = 0.0709423
I0209 08:40:11.512794 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.96875
I0209 08:40:11.512804 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0709423 (* 1 = 0.0709423 loss)
I0209 08:40:11.512809 14948 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0209 08:41:04.126130 14948 solver.cpp:228] Iteration 18850, loss = 0.0271857
I0209 08:41:04.126159 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:41:04.126168 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0568643 (* 1 = 0.0568643 loss)
I0209 08:41:04.126184 14948 sgd_solver.cpp:106] Iteration 18850, lr = 0.0001
>>> 2017-02-09 08:41:55.582305 Begin model classification tests
>>> 2017-02-09 08:42:13.497977 Iteration 18900 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:42:13.498008 Iteration 18900 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:42:13.498016 Iteration 18900 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:42:13.498022 Iteration 18900 mean testing loss (rgb) 1.03520961224
>>> 2017-02-09 08:42:13.498034 Iteration 18900 mean testing loss (depth) 1.03520961224
>>> 2017-02-09 08:42:13.498054 Iteration 18900 mean testing loss (rgbd) 1.03520961224
>>> 2017-02-09 08:42:13.498073 Iteration 18900 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:42:14.530194 14948 solver.cpp:228] Iteration 18900, loss = 0.0306861
I0209 08:42:14.530221 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:42:14.530230 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0306861 (* 1 = 0.0306861 loss)
I0209 08:42:14.530236 14948 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0209 08:43:07.080853 14948 solver.cpp:228] Iteration 18950, loss = 0.0273134
I0209 08:43:07.080880 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:43:07.080888 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0404891 (* 1 = 0.0404891 loss)
I0209 08:43:07.080894 14948 sgd_solver.cpp:106] Iteration 18950, lr = 0.0001
I0209 08:43:58.453135 14948 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/romans_stage3_iter_19000.caffemodel
I0209 08:44:50.772702 14948 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/romans_stage3_iter_19000.solverstate
>>> 2017-02-09 08:44:52.873301 Begin model classification tests
>>> 2017-02-09 08:45:10.503215 Iteration 19000 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:45:10.503245 Iteration 19000 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:45:10.503254 Iteration 19000 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:45:10.503260 Iteration 19000 mean testing loss (rgb) 1.03496394887
>>> 2017-02-09 08:45:10.503271 Iteration 19000 mean testing loss (depth) 1.03496394887
>>> 2017-02-09 08:45:10.503288 Iteration 19000 mean testing loss (rgbd) 1.03496394887
>>> 2017-02-09 08:45:10.503303 Iteration 19000 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:45:12.185719 14948 solver.cpp:228] Iteration 19000, loss = 0.0221859
I0209 08:45:12.185748 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:45:12.185756 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0221859 (* 1 = 0.0221859 loss)
I0209 08:45:12.185763 14948 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0209 08:46:05.882495 14948 solver.cpp:228] Iteration 19050, loss = 0.0253816
I0209 08:46:05.882525 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:46:05.882534 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0260475 (* 1 = 0.0260475 loss)
I0209 08:46:05.882540 14948 sgd_solver.cpp:106] Iteration 19050, lr = 0.0001
>>> 2017-02-09 08:46:58.621360 Begin model classification tests
>>> 2017-02-09 08:47:16.594568 Iteration 19100 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:47:16.594599 Iteration 19100 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:47:16.594607 Iteration 19100 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:47:16.594613 Iteration 19100 mean testing loss (rgb) 1.03536510086
>>> 2017-02-09 08:47:16.594625 Iteration 19100 mean testing loss (depth) 1.03536510086
>>> 2017-02-09 08:47:16.594642 Iteration 19100 mean testing loss (rgbd) 1.03536510086
>>> 2017-02-09 08:47:16.594659 Iteration 19100 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:47:17.660573 14948 solver.cpp:228] Iteration 19100, loss = 0.00980531
I0209 08:47:17.660601 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:47:17.660609 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00980531 (* 1 = 0.00980531 loss)
I0209 08:47:17.660615 14948 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0209 08:48:11.158557 14948 solver.cpp:228] Iteration 19150, loss = 0.0242927
I0209 08:48:11.158584 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:48:11.158592 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0218673 (* 1 = 0.0218673 loss)
I0209 08:48:11.158598 14948 sgd_solver.cpp:106] Iteration 19150, lr = 0.0001
>>> 2017-02-09 08:49:03.564817 Begin model classification tests
>>> 2017-02-09 08:49:21.455121 Iteration 19200 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:49:21.455151 Iteration 19200 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:49:21.455159 Iteration 19200 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:49:21.455166 Iteration 19200 mean testing loss (rgb) 1.0353473237
>>> 2017-02-09 08:49:21.455177 Iteration 19200 mean testing loss (depth) 1.0353473237
>>> 2017-02-09 08:49:21.455197 Iteration 19200 mean testing loss (rgbd) 1.0353473237
>>> 2017-02-09 08:49:21.455217 Iteration 19200 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:49:22.485024 14948 solver.cpp:228] Iteration 19200, loss = 0.0223961
I0209 08:49:22.485051 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:49:22.485060 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0223961 (* 1 = 0.0223961 loss)
I0209 08:49:22.485066 14948 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0209 08:50:15.811532 14948 solver.cpp:228] Iteration 19250, loss = 0.0252224
I0209 08:50:15.811559 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:50:15.811568 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.017153 (* 1 = 0.017153 loss)
I0209 08:50:15.811573 14948 sgd_solver.cpp:106] Iteration 19250, lr = 0.0001
>>> 2017-02-09 08:51:07.892141 Begin model classification tests
>>> 2017-02-09 08:51:25.762246 Iteration 19300 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:51:25.762277 Iteration 19300 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:51:25.762291 Iteration 19300 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:51:25.762318 Iteration 19300 mean testing loss (rgb) 1.03679152341
>>> 2017-02-09 08:51:25.762329 Iteration 19300 mean testing loss (depth) 1.03679152341
>>> 2017-02-09 08:51:25.762335 Iteration 19300 mean testing loss (rgbd) 1.03679152341
>>> 2017-02-09 08:51:25.762343 Iteration 19300 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:51:26.788717 14948 solver.cpp:228] Iteration 19300, loss = 0.0226646
I0209 08:51:26.788744 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:51:26.788753 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0226646 (* 1 = 0.0226646 loss)
I0209 08:51:26.788759 14948 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0209 08:52:19.915737 14948 solver.cpp:228] Iteration 19350, loss = 0.0236999
I0209 08:52:19.915767 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:52:19.915781 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0104892 (* 1 = 0.0104892 loss)
I0209 08:52:19.915788 14948 sgd_solver.cpp:106] Iteration 19350, lr = 0.0001
>>> 2017-02-09 08:53:11.809066 Begin model classification tests
>>> 2017-02-09 08:53:29.714702 Iteration 19400 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:53:29.714737 Iteration 19400 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:53:29.714744 Iteration 19400 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:53:29.714751 Iteration 19400 mean testing loss (rgb) 1.03621743942
>>> 2017-02-09 08:53:29.714762 Iteration 19400 mean testing loss (depth) 1.03621743942
>>> 2017-02-09 08:53:29.714782 Iteration 19400 mean testing loss (rgbd) 1.03621743942
>>> 2017-02-09 08:53:29.714801 Iteration 19400 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:53:30.747728 14948 solver.cpp:228] Iteration 19400, loss = 0.0248858
I0209 08:53:30.747756 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:53:30.747778 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0248858 (* 1 = 0.0248858 loss)
I0209 08:53:30.747787 14948 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0209 08:54:23.791142 14948 solver.cpp:228] Iteration 19450, loss = 0.0284896
I0209 08:54:23.791170 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:54:23.791178 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0167224 (* 1 = 0.0167224 loss)
I0209 08:54:23.791184 14948 sgd_solver.cpp:106] Iteration 19450, lr = 0.0001
>>> 2017-02-09 08:55:15.795063 Begin model classification tests
>>> 2017-02-09 08:55:33.646996 Iteration 19500 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:55:33.647026 Iteration 19500 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:55:33.647034 Iteration 19500 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:55:33.647040 Iteration 19500 mean testing loss (rgb) 1.03602997733
>>> 2017-02-09 08:55:33.647052 Iteration 19500 mean testing loss (depth) 1.03602997733
>>> 2017-02-09 08:55:33.647073 Iteration 19500 mean testing loss (rgbd) 1.03602997733
>>> 2017-02-09 08:55:33.647092 Iteration 19500 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:55:34.682353 14948 solver.cpp:228] Iteration 19500, loss = 0.020289
I0209 08:55:34.682379 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:55:34.682387 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.020289 (* 1 = 0.020289 loss)
I0209 08:55:34.682394 14948 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0209 08:56:27.730334 14948 solver.cpp:228] Iteration 19550, loss = 0.0273084
I0209 08:56:27.730362 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:56:27.730370 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0442713 (* 1 = 0.0442713 loss)
I0209 08:56:27.730376 14948 sgd_solver.cpp:106] Iteration 19550, lr = 0.0001
>>> 2017-02-09 08:57:19.542286 Begin model classification tests
>>> 2017-02-09 08:57:37.455728 Iteration 19600 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:57:37.455756 Iteration 19600 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:57:37.455764 Iteration 19600 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:57:37.455770 Iteration 19600 mean testing loss (rgb) 1.03710199819
>>> 2017-02-09 08:57:37.455781 Iteration 19600 mean testing loss (depth) 1.03710199819
>>> 2017-02-09 08:57:37.455797 Iteration 19600 mean testing loss (rgbd) 1.03710199819
>>> 2017-02-09 08:57:37.455814 Iteration 19600 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:57:38.517259 14948 solver.cpp:228] Iteration 19600, loss = 0.0150442
I0209 08:57:38.517287 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:57:38.517295 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0150442 (* 1 = 0.0150442 loss)
I0209 08:57:38.517302 14948 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0209 08:58:31.301790 14948 solver.cpp:228] Iteration 19650, loss = 0.0279245
I0209 08:58:31.301834 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 08:58:31.301843 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.00349769 (* 1 = 0.00349769 loss)
I0209 08:58:31.301849 14948 sgd_solver.cpp:106] Iteration 19650, lr = 0.0001
>>> 2017-02-09 08:59:22.949125 Begin model classification tests
>>> 2017-02-09 08:59:40.897782 Iteration 19700 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 08:59:40.897813 Iteration 19700 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 08:59:40.897824 Iteration 19700 mean classification accuracy (rgbd)  0.853828306265
>>> 2017-02-09 08:59:40.897842 Iteration 19700 mean testing loss (rgb) 1.03707907917
>>> 2017-02-09 08:59:40.897863 Iteration 19700 mean testing loss (depth) 1.03707907917
>>> 2017-02-09 08:59:40.897870 Iteration 19700 mean testing loss (rgbd) 1.03707907917
>>> 2017-02-09 08:59:40.897877 Iteration 19700 mean confusion matrix
[ 1.          0.97391304  0.80357143  0.          0.6         0.91176471
  0.81481481  1.          0.27272727  0.93939394  0.83333333]
I0209 08:59:41.929203 14948 solver.cpp:228] Iteration 19700, loss = 0.0276897
I0209 08:59:41.929230 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 0.984375
I0209 08:59:41.929239 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0276897 (* 1 = 0.0276897 loss)
I0209 08:59:41.929244 14948 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0209 09:00:34.727262 14948 solver.cpp:228] Iteration 19750, loss = 0.0305588
I0209 09:00:34.727290 14948 solver.cpp:244]     Train net output #0: rgbd_accuracy = 1
I0209 09:00:34.727299 14948 solver.cpp:244]     Train net output #1: rgbd_loss = 0.0346137 (* 1 = 0.0346137 loss)
I0209 09:00:34.727305 14948 sgd_solver.cpp:106] Iteration 19750, lr = 0.0001
>>> 2017-02-09 09:01:26.317067 Begin model classification tests
>>> 2017-02-09 09:01:44.268174 Iteration 19800 mean classification accuracy (rgb)  0.853828306265
>>> 2017-02-09 09:01:44.268206 Iteration 19800 mean classification accuracy (depth) 0.853828306265
>>> 2017-02-09 09:01:44.268214 Iteration 19800 mean classification accuracy (rgbd)  0.85382830