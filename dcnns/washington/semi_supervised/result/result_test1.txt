Script started on Tue 31 Jan 2017 01:10:29 GMT
]0;kevin@kevin-desktop: ~/catkin_ws/src/romans_stack/dcnns/washington/vgg_caffe_net/stage3kevin@kevin-desktop:~/catkin_ws/src/romans_stack/dcnns/washington/vgg_caffe_net/stage3$ pyu[Kthon solve.py
/home/kevin/caffeplus/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/kevin/caffeplus/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/kevin/caffeplus/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0131 01:10:56.012159 25291 solver.cpp:48] Initializing solver from parameters: 
train_net: "train.prototxt"
test_net: "test.prototxt"
test_iter: 0
test_interval: 999999999
base_lr: 0.001
display: 100
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 1000
snapshot_prefix: "/home/kevin/snapshot/rgbd_stage3"
solver_mode: GPU
average_loss: 1000
I0131 01:10:56.012328 25291 solver.cpp:81] Creating training net from train_net file: train.prototxt
I0131 01:10:56.014106 25291 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "rgb"
  top: "depth"
  top: "label"
  python_param {
    module: "data_layers.washington_data_layer"
    layer: "WashingtonDataLayer"
    param_str: "{\'img_size\': (224, 224), \'split\': \'train\', \'dataset_dir\': \'/home/kevin/dataset/washington_rgbd_dataset\', \'randomize\': True, \'mean\': (104.00698793, 116.66876762, 122.67891434), \'seed\': 1337, \'batch_size\': 32, \'crop_size\': (224, 224, 224, 224)}"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "rgb"
  top: "conv1_1"
  param {
    name: "conv1_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    name: "conv1_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "rgb_pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "rgb_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "rgb_pool1"
  top: "conv2_1"
  param {
    name: "conv2_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    name: "conv2_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "rgb_pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "rgb_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "rgb_pool2"
  top: "conv3_1"
  param {
    name: "conv3_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    name: "conv3_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    name: "conv3_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "rgb_pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "rgb_pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "rgb_pool3"
  top: "conv4_1"
  param {
    name: "conv4_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    name: "conv4_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    name: "conv4_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "rgb_pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "rgb_pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "rgb_pool4"
  top: "conv5_1"
  param {
    name: "conv5_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    name: "conv5_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    name: "conv5_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rgb_pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "rgb_pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "rgb_fc6"
  type: "InnerProduct"
  bottom: "rgb_pool5"
  top: "rgb_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_relu6"
  type: "ReLU"
  bottom: "rgb_fc6"
  top: "rgb_fc6"
}
layer {
  name: "rgb_drop6"
  type: "Dropout"
  bottom: "rgb_fc6"
  top: "rgb_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "rgb_fc7"
  type: "InnerProduct"
  bottom: "rgb_fc6"
  top: "rgb_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_relu7"
  type: "ReLU"
  bottom: "rgb_fc7"
  top: "rgb_fc7"
}
layer {
  name: "rgb_drop7"
  type: "Dropout"
  bottom: "rgb_fc7"
  top: "rgb_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "rgb_fc8"
  type: "InnerProduct"
  bottom: "rgb_fc7"
  top: "rgb_fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 51
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "depth"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "depth_pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "depth_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "depth_pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "depth_pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "depth_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "depth_pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "depth_pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "depth_pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "depth_pool3"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "depth_pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "depth_pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "depth_fc6"
  type: "InnerProduct"
  bottom: "depth_pool5"
  top: "depth_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "depth_relu6"
  type: "ReLU"
  bottom: "depth_fc6"
  top: "depth_fc6"
}
layer {
  name: "depth_drop6"
  type: "Dropout"
  bottom: "depth_fc6"
  top: "depth_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "depth_fc7"
  type: "InnerProduct"
  bottom: "depth_fc6"
  top: "depth_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "depth_relu7"
  type: "ReLU"
  bottom: "depth_fc7"
  top: "depth_fc7"
}
layer {
  name: "depth_drop7"
  type: "Dropout"
  bottom: "depth_fc7"
  top: "depth_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "depth_fc8"
  type: "InnerProduct"
  bottom: "depth_fc7"
  top: "depth_fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 51
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "rgb_fc7"
  bottom: "depth_fc7"
  top: "concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "rgbd_fc8"
  type: "InnerProduct"
  bottom: "concat"
  top: "rgbd_fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 51
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_accuracy"
  type: "Accuracy"
  bottom: "rgb_fc8"
  bottom: "label"
  top: "rgb_accuracy"
}
layer {
  name: "rgb_loss"
  type: "SoftmaxWithLoss"
  bottom: "rgb_fc8"
  bottom: "label"
  top: "rgb_loss"
}
layer {
  name: "depth_accuracy"
  type: "Accuracy"
  bottom: "depth_fc8"
  bottom: "label"
  top: "depth_accuracy"
}
layer {
  name: "depth_loss"
  type: "SoftmaxWithLoss"
  bottom: "depth_fc8"
  bottom: "label"
  top: "depth_loss"
}
layer {
  name: "rgbd_accuracy"
  type: "Accuracy"
  bottom: "rgbd_fc8"
  bottom: "label"
  top: "rgbd_accuracy"
}
layer {
  name: "rgbd_loss"
  type: "SoftmaxWithLoss"
  bottom: "rgbd_fc8"
  bottom: "label"
  top: "rgbd_loss"
}
I0131 01:10:56.017668 25291 layer_factory.hpp:77] Creating layer data
I0131 01:10:56.161484 25291 net.cpp:91] Creating Layer data
I0131 01:10:56.161514 25291 net.cpp:399] data -> rgb
I0131 01:10:56.161525 25291 net.cpp:399] data -> depth
I0131 01:10:56.161531 25291 net.cpp:399] data -> label
{'img_size': (224, 224), 'split': 'train', 'dataset_dir': '/home/kevin/dataset/washington_rgbd_dataset', 'crop_size': (224, 224, 224, 224), 'randomize': True, 'seed': 1337, 'batch_size': 32, 'mean': (104.00698793, 116.66876762, 122.67891434)}
I0131 01:10:56.246924 25291 net.cpp:141] Setting up data
I0131 01:10:56.246960 25291 net.cpp:148] Top shape: 32 3 224 224 (4816896)
I0131 01:10:56.246971 25291 net.cpp:148] Top shape: 32 1 224 224 (1605632)
I0131 01:10:56.246979 25291 net.cpp:148] Top shape: 32 1 (32)
I0131 01:10:56.246989 25291 net.cpp:156] Memory required for data: 25690240
I0131 01:10:56.246999 25291 layer_factory.hpp:77] Creating layer label_data_2_split
I0131 01:10:56.247022 25291 net.cpp:91] Creating Layer label_data_2_split
I0131 01:10:56.247032 25291 net.cpp:425] label_data_2_split <- label
I0131 01:10:56.247045 25291 net.cpp:399] label_data_2_split -> label_data_2_split_0
I0131 01:10:56.247061 25291 net.cpp:399] label_data_2_split -> label_data_2_split_1
I0131 01:10:56.247073 25291 net.cpp:399] label_data_2_split -> label_data_2_split_2
I0131 01:10:56.247084 25291 net.cpp:399] label_data_2_split -> label_data_2_split_3
I0131 01:10:56.247097 25291 net.cpp:399] label_data_2_split -> label_data_2_split_4
I0131 01:10:56.247107 25291 net.cpp:399] label_data_2_split -> label_data_2_split_5
I0131 01:10:56.247182 25291 net.cpp:141] Setting up label_data_2_split
I0131 01:10:56.247195 25291 net.cpp:148] Top shape: 32 1 (32)
I0131 01:10:56.247205 25291 net.cpp:148] Top shape: 32 1 (32)
I0131 01:10:56.247213 25291 net.cpp:148] Top shape: 32 1 (32)
I0131 01:10:56.247222 25291 net.cpp:148] Top shape: 32 1 (32)
I0131 01:10:56.247231 25291 net.cpp:148] Top shape: 32 1 (32)
I0131 01:10:56.247239 25291 net.cpp:148] Top shape: 32 1 (32)
I0131 01:10:56.247247 25291 net.cpp:156] Memory required for data: 25691008
I0131 01:10:56.247256 25291 layer_factory.hpp:77] Creating layer conv1_1
I0131 01:10:56.247275 25291 net.cpp:91] Creating Layer conv1_1
I0131 01:10:56.247284 25291 net.cpp:425] conv1_1 <- rgb
I0131 01:10:56.247298 25291 net.cpp:399] conv1_1 -> conv1_1
I0131 01:10:56.248349 25291 net.cpp:141] Setting up conv1_1
I0131 01:10:56.248369 25291 net.cpp:148] Top shape: 32 64 224 224 (102760448)
I0131 01:10:56.248378 25291 net.cpp:156] Memory required for data: 436732800
I0131 01:10:56.248394 25291 layer_factory.hpp:77] Creating layer relu1_1
I0131 01:10:56.248407 25291 net.cpp:91] Creating Layer relu1_1
I0131 01:10:56.248416 25291 net.cpp:425] relu1_1 <- conv1_1
I0131 01:10:56.248428 25291 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0131 01:10:56.248445 25291 net.cpp:141] Setting up relu1_1
I0131 01:10:56.248456 25291 net.cpp:148] Top shape: 32 64 224 224 (102760448)
I0131 01:10:56.248463 25291 net.cpp:156] Memory required for data: 847774592
I0131 01:10:56.248471 25291 layer_factory.hpp:77] Creating layer conv1_2
I0131 01:10:56.248486 25291 net.cpp:91] Creating Layer conv1_2
I0131 01:10:56.248494 25291 net.cpp:425] conv1_2 <- conv1_1
I0131 01:10:56.248504 25291 net.cpp:399] conv1_2 -> conv1_2
I0131 01:10:56.248842 25291 net.cpp:141] Setting up conv1_2
I0131 01:10:56.248855 25291 net.cpp:148] Top shape: 32 64 224 224 (102760448)
I0131 01:10:56.248863 25291 net.cpp:156] Memory required for data: 1258816384
I0131 01:10:56.248877 25291 layer_factory.hpp:77] Creating layer relu1_2
I0131 01:10:56.248888 25291 net.cpp:91] Creating Layer relu1_2
I0131 01:10:56.248896 25291 net.cpp:425] relu1_2 <- conv1_2
I0131 01:10:56.248905 25291 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0131 01:10:56.248916 25291 net.cpp:141] Setting up relu1_2
I0131 01:10:56.248925 25291 net.cpp:148] Top shape: 32 64 224 224 (102760448)
I0131 01:10:56.248934 25291 net.cpp:156] Memory required for data: 1669858176
I0131 01:10:56.248944 25291 layer_factory.hpp:77] Creating layer rgb_pool1
I0131 01:10:56.248955 25291 net.cpp:91] Creating Layer rgb_pool1
I0131 01:10:56.248963 25291 net.cpp:425] rgb_pool1 <- conv1_2
I0131 01:10:56.248972 25291 net.cpp:399] rgb_pool1 -> rgb_pool1
I0131 01:10:56.249017 25291 net.cpp:141] Setting up rgb_pool1
I0131 01:10:56.249029 25291 net.cpp:148] Top shape: 32 64 112 112 (25690112)
I0131 01:10:56.249037 25291 net.cpp:156] Memory required for data: 1772618624
I0131 01:10:56.249047 25291 layer_factory.hpp:77] Creating layer conv2_1
I0131 01:10:56.249061 25291 net.cpp:91] Creating Layer conv2_1
I0131 01:10:56.249070 25291 net.cpp:425] conv2_1 <- rgb_pool1
I0131 01:10:56.249081 25291 net.cpp:399] conv2_1 -> conv2_1
I0131 01:10:56.250200 25291 net.cpp:141] Setting up conv2_1
I0131 01:10:56.250222 25291 net.cpp:148] Top shape: 32 128 112 112 (51380224)
I0131 01:10:56.250231 25291 net.cpp:156] Memory required for data: 1978139520
I0131 01:10:56.250252 25291 layer_factory.hpp:77] Creating layer relu2_1
I0131 01:10:56.250268 25291 net.cpp:91] Creating Layer relu2_1
I0131 01:10:56.250277 25291 net.cpp:425] relu2_1 <- conv2_1
I0131 01:10:56.250288 25291 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0131 01:10:56.250300 25291 net.cpp:141] Setting up relu2_1
I0131 01:10:56.250310 25291 net.cpp:148] Top shape: 32 128 112 112 (51380224)
I0131 01:10:56.250319 25291 net.cpp:156] Memory required for data: 2183660416
I0131 01:10:56.250327 25291 layer_factory.hpp:77] Creating layer conv2_2
I0131 01:10:56.250344 25291 net.cpp:91] Creating Layer conv2_2
I0131 01:10:56.250352 25291 net.cpp:425] conv2_2 <- conv2_1
I0131 01:10:56.250365 25291 net.cpp:399] conv2_2 -> conv2_2
I0131 01:10:56.251359 25291 net.cpp:141] Setting up conv2_2
I0131 01:10:56.251377 25291 net.cpp:148] Top shape: 32 128 112 112 (51380224)
I0131 01:10:56.251386 25291 net.cpp:156] Memory required for data: 2389181312
I0131 01:10:56.251396 25291 layer_factory.hpp:77] Creating layer relu2_2
I0131 01:10:56.251410 25291 net.cpp:91] Creating Layer relu2_2
I0131 01:10:56.251417 25291 net.cpp:425] relu2_2 <- conv2_2
I0131 01:10:56.251427 25291 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0131 01:10:56.251440 25291 net.cpp:141] Setting up relu2_2
I0131 01:10:56.251449 25291 net.cpp:148] Top shape: 32 128 112 112 (51380224)
I0131 01:10:56.251457 25291 net.cpp:156] Memory required for data: 2594702208
I0131 01:10:56.251466 25291 layer_factory.hpp:77] Creating layer rgb_pool2
I0131 01:10:56.251480 25291 net.cpp:91] Creating Layer rgb_pool2
I0131 01:10:56.251488 25291 net.cpp:425] rgb_pool2 <- conv2_2
I0131 01:10:56.251498 25291 net.cpp:399] rgb_pool2 -> rgb_pool2
I0131 01:10:56.251533 25291 net.cpp:141] Setting up rgb_pool2
I0131 01:10:56.251543 25291 net.cpp:148] Top shape: 32 128 56 56 (12845056)
I0131 01:10:56.251551 25291 net.cpp:156] Memory required for data: 2646082432
I0131 01:10:56.251559 25291 layer_factory.hpp:77] Creating layer conv3_1
I0131 01:10:56.251574 25291 net.cpp:91] Creating Layer conv3_1
I0131 01:10:56.251583 25291 net.cpp:425] conv3_1 <- rgb_pool2
I0131 01:10:56.251595 25291 net.cpp:399] conv3_1 -> conv3_1
I0131 01:10:56.253423 25291 net.cpp:141] Setting up conv3_1
I0131 01:10:56.253453 25291 net.cpp:148] Top shape: 32 256 56 56 (25690112)
I0131 01:10:56.253461 25291 net.cpp:156] Memory required for data: 2748842880
I0131 01:10:56.253479 25291 layer_factory.hpp:77] Creating layer relu3_1
I0131 01:10:56.253494 25291 net.cpp:91] Creating Layer relu3_1
I0131 01:10:56.253504 25291 net.cpp:425] relu3_1 <- conv3_1
I0131 01:10:56.253515 25291 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0131 01:10:56.253527 25291 net.cpp:141] Setting up relu3_1
I0131 01:10:56.253537 25291 net.cpp:148] Top shape: 32 256 56 56 (25690112)
I0131 01:10:56.253545 25291 net.cpp:156] Memory required for data: 2851603328
I0131 01:10:56.253553 25291 layer_factory.hpp:77] Creating layer conv3_2
I0131 01:10:56.253567 25291 net.cpp:91] Creating Layer conv3_2
I0131 01:10:56.253576 25291 net.cpp:425] conv3_2 <- conv3_1
I0131 01:10:56.253587 25291 net.cpp:399] conv3_2 -> conv3_2
I0131 01:10:56.257513 25291 net.cpp:141] Setting up conv3_2
I0131 01:10:56.257553 25291 net.cpp:148] Top shape: 32 256 56 56 (25690112)
I0131 01:10:56.257562 25291 net.cpp:156] Memory required for data: 2954363776
I0131 01:10:56.257576 25291 layer_factory.hpp:77] Creating layer relu3_2
I0131 01:10:56.257592 25291 net.cpp:91] Creating Layer relu3_2
I0131 01:10:56.257602 25291 net.cpp:425] relu3_2 <- conv3_2
I0131 01:10:56.257616 25291 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0131 01:10:56.257629 25291 net.cpp:141] Setting up relu3_2
I0131 01:10:56.257640 25291 net.cpp:148] Top shape: 32 256 56 56 (25690112)
I0131 01:10:56.257648 25291 net.cpp:156] Memory required for data: 3057124224
I0131 01:10:56.257657 25291 layer_factory.hpp:77] Creating layer conv3_3
I0131 01:10:56.257675 25291 net.cpp:91] Creating Layer conv3_3
I0131 01:10:56.257684 25291 net.cpp:425] conv3_3 <- conv3_2
I0131 01:10:56.257695 25291 net.cpp:399] conv3_3 -> conv3_3
I0131 01:10:56.261478 25291 net.cpp:141] Setting up conv3_3
I0131 01:10:56.261519 25291 net.cpp:148] Top shape: 32 256 56 56 (25690112)
I0131 01:10:56.261528 25291 net.cpp:156] Memory required for data: 3159884672
I0131 01:10:56.261543 25291 layer_factory.hpp:77] Creating layer relu3_3
I0131 01:10:56.261556 25291 net.cpp:91] Creating Layer relu3_3
I0131 01:10:56.261566 25291 net.cpp:425] relu3_3 <- conv3_3
I0131 01:10:56.261577 25291 net.cpp:386] relu3_3 -> conv3_3 (in-place)
I0131 01:10:56.261591 25291 net.cpp:141] Setting up relu3_3
I0131 01:10:56.261601 25291 net.cpp:148] Top shape: 32 256 56 56 (25690112)
I0131 01:10:56.261610 25291 net.cpp:156] Memory required for data: 3262645120
I0131 01:10:56.261617 25291 layer_factory.hpp:77] Creating layer rgb_pool3
I0131 01:10:56.261631 25291 net.cpp:91] Creating Layer rgb_pool3
I0131 01:10:56.261639 25291 net.cpp:425] rgb_pool3 <- conv3_3
I0131 01:10:56.261649 25291 net.cpp:399] rgb_pool3 -> rgb_pool3
I0131 01:10:56.261693 25291 net.cpp:141] Setting up rgb_pool3
I0131 01:10:56.261708 25291 net.cpp:148] Top shape: 32 256 28 28 (6422528)
I0131 01:10:56.261716 25291 net.cpp:156] Memory required for data: 3288335232
I0131 01:10:56.261724 25291 layer_factory.hpp:77] Creating layer conv4_1
I0131 01:10:56.261741 25291 net.cpp:91] Creating Layer conv4_1
I0131 01:10:56.261750 25291 net.cpp:425] conv4_1 <- rgb_pool3
I0131 01:10:56.261762 25291 net.cpp:399] conv4_1 -> conv4_1
I0131 01:10:56.270372 25291 net.cpp:141] Setting up conv4_1
I0131 01:10:56.270406 25291 net.cpp:148] Top shape: 32 512 28 28 (12845056)
I0131 01:10:56.270414 25291 net.cpp:156] Memory required for data: 3339715456
I0131 01:10:56.270429 25291 layer_factory.hpp:77] Creating layer relu4_1
I0131 01:10:56.270445 25291 net.cpp:91] Creating Layer relu4_1
I0131 01:10:56.270455 25291 net.cpp:425] relu4_1 <- conv4_1
I0131 01:10:56.270467 25291 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0131 01:10:56.270479 25291 net.cpp:141] Setting up relu4_1
I0131 01:10:56.270489 25291 net.cpp:148] Top shape: 32 512 28 28 (12845056)
I0131 01:10:56.270498 25291 net.cpp:156] Memory required for data: 3391095680
I0131 01:10:56.270505 25291 layer_factory.hpp:77] Creating layer conv4_2
I0131 01:10:56.270521 25291 net.cpp:91] Creating Layer conv4_2
I0131 01:10:56.270529 25291 net.cpp:425] conv4_2 <- conv4_1
I0131 01:10:56.270541 25291 net.cpp:399] conv4_2 -> conv4_2
I0131 01:10:56.283756 25291 net.cpp:141] Setting up conv4_2
I0131 01:10:56.283793 25291 net.cpp:148] Top shape: 32 512 28 28 (12845056)
I0131 01:10:56.283804 25291 net.cpp:156] Memory required for data: 3442475904
I0131 01:10:56.283829 25291 layer_factory.hpp:77] Creating layer relu4_2
I0131 01:10:56.283846 25291 net.cpp:91] Creating Layer relu4_2
I0131 01:10:56.283857 25291 net.cpp:425] relu4_2 <- conv4_2
I0131 01:10:56.283870 25291 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0131 01:10:56.283884 25291 net.cpp:141] Setting up relu4_2
I0131 01:10:56.283892 25291 net.cpp:148] Top shape: 32 512 28 28 (12845056)
I0131 01:10:56.283900 25291 net.cpp:156] Memory required for data: 3493856128
I0131 01:10:56.283908 25291 layer_factory.hpp:77] Creating layer conv4_3
I0131 01:10:56.283924 25291 net.cpp:91] Creating Layer conv4_3
I0131 01:10:56.283933 25291 net.cpp:425] conv4_3 <- conv4_2
I0131 01:10:56.283946 25291 net.cpp:399] conv4_3 -> conv4_3
I0131 01:10:56.298538 25291 net.cpp:141] Setting up conv4_3
I0131 01:10:56.298578 25291 net.cpp:148] Top shape: 32 512 28 28 (12845056)
I0131 01:10:56.298588 25291 net.cpp:156] Memory required for data: 3545236352
I0131 01:10:56.298605 25291 layer_factory.hpp:77] Creating layer relu4_3
I0131 01:10:56.298622 25291 net.cpp:91] Creating Layer relu4_3
I0131 01:10:56.298633 25291 net.cpp:425] relu4_3 <- conv4_3
I0131 01:10:56.298650 25291 net.cpp:386] relu4_3 -> conv4_3 (in-place)
I0131 01:10:56.298667 25291 net.cpp:141] Setting up relu4_3
I0131 01:10:56.298678 25291 net.cpp:148] Top shape: 32 512 28 28 (12845056)
I0131 01:10:56.298686 25291 net.cpp:156] Memory required for data: 3596616576
I0131 01:10:56.298694 25291 layer_factory.hpp:77] Creating layer rgb_pool4
I0131 01:10:56.298707 25291 net.cpp:91] Creating Layer rgb_pool4
I0131 01:10:56.298715 25291 net.cpp:425] rgb_pool4 <- conv4_3
I0131 01:10:56.298727 25291 net.cpp:399] rgb_pool4 -> rgb_pool4
I0131 01:10:56.298780 25291 net.cpp:141] Setting up rgb_pool4
I0131 01:10:56.298795 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:56.298804 25291 net.cpp:156] Memory required for data: 3609461632
I0131 01:10:56.298812 25291 layer_factory.hpp:77] Creating layer conv5_1
I0131 01:10:56.298830 25291 net.cpp:91] Creating Layer conv5_1
I0131 01:10:56.298838 25291 net.cpp:425] conv5_1 <- rgb_pool4
I0131 01:10:56.298853 25291 net.cpp:399] conv5_1 -> conv5_1
I0131 01:10:56.313560 25291 net.cpp:141] Setting up conv5_1
I0131 01:10:56.313597 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:56.313607 25291 net.cpp:156] Memory required for data: 3622306688
I0131 01:10:56.313621 25291 layer_factory.hpp:77] Creating layer relu5_1
I0131 01:10:56.313637 25291 net.cpp:91] Creating Layer relu5_1
I0131 01:10:56.313647 25291 net.cpp:425] relu5_1 <- conv5_1
I0131 01:10:56.313659 25291 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0131 01:10:56.313673 25291 net.cpp:141] Setting up relu5_1
I0131 01:10:56.313683 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:56.313691 25291 net.cpp:156] Memory required for data: 3635151744
I0131 01:10:56.313699 25291 layer_factory.hpp:77] Creating layer conv5_2
I0131 01:10:56.313716 25291 net.cpp:91] Creating Layer conv5_2
I0131 01:10:56.313724 25291 net.cpp:425] conv5_2 <- conv5_1
I0131 01:10:56.313737 25291 net.cpp:399] conv5_2 -> conv5_2
I0131 01:10:56.328194 25291 net.cpp:141] Setting up conv5_2
I0131 01:10:56.328230 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:56.328239 25291 net.cpp:156] Memory required for data: 3647996800
I0131 01:10:56.328253 25291 layer_factory.hpp:77] Creating layer relu5_2
I0131 01:10:56.328269 25291 net.cpp:91] Creating Layer relu5_2
I0131 01:10:56.328279 25291 net.cpp:425] relu5_2 <- conv5_2
I0131 01:10:56.328292 25291 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0131 01:10:56.328306 25291 net.cpp:141] Setting up relu5_2
I0131 01:10:56.328316 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:56.328323 25291 net.cpp:156] Memory required for data: 3660841856
I0131 01:10:56.328330 25291 layer_factory.hpp:77] Creating layer conv5_3
I0131 01:10:56.328347 25291 net.cpp:91] Creating Layer conv5_3
I0131 01:10:56.328356 25291 net.cpp:425] conv5_3 <- conv5_2
I0131 01:10:56.328367 25291 net.cpp:399] conv5_3 -> conv5_3
I0131 01:10:56.343334 25291 net.cpp:141] Setting up conv5_3
I0131 01:10:56.343374 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:56.343386 25291 net.cpp:156] Memory required for data: 3673686912
I0131 01:10:56.343402 25291 layer_factory.hpp:77] Creating layer relu5_3
I0131 01:10:56.343421 25291 net.cpp:91] Creating Layer relu5_3
I0131 01:10:56.343433 25291 net.cpp:425] relu5_3 <- conv5_3
I0131 01:10:56.343446 25291 net.cpp:386] relu5_3 -> conv5_3 (in-place)
I0131 01:10:56.343462 25291 net.cpp:141] Setting up relu5_3
I0131 01:10:56.343473 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:56.343482 25291 net.cpp:156] Memory required for data: 3686531968
I0131 01:10:56.343490 25291 layer_factory.hpp:77] Creating layer rgb_pool5
I0131 01:10:56.343510 25291 net.cpp:91] Creating Layer rgb_pool5
I0131 01:10:56.343519 25291 net.cpp:425] rgb_pool5 <- conv5_3
I0131 01:10:56.343533 25291 net.cpp:399] rgb_pool5 -> rgb_pool5
I0131 01:10:56.343595 25291 net.cpp:141] Setting up rgb_pool5
I0131 01:10:56.343611 25291 net.cpp:148] Top shape: 32 512 7 7 (802816)
I0131 01:10:56.343619 25291 net.cpp:156] Memory required for data: 3689743232
I0131 01:10:56.343627 25291 layer_factory.hpp:77] Creating layer rgb_fc6
I0131 01:10:56.343652 25291 net.cpp:91] Creating Layer rgb_fc6
I0131 01:10:56.343662 25291 net.cpp:425] rgb_fc6 <- rgb_pool5
I0131 01:10:56.343674 25291 net.cpp:399] rgb_fc6 -> rgb_fc6
I0131 01:10:56.933928 25291 net.cpp:141] Setting up rgb_fc6
I0131 01:10:56.933969 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:56.933980 25291 net.cpp:156] Memory required for data: 3690267520
I0131 01:10:56.933997 25291 layer_factory.hpp:77] Creating layer rgb_relu6
I0131 01:10:56.934015 25291 net.cpp:91] Creating Layer rgb_relu6
I0131 01:10:56.934026 25291 net.cpp:425] rgb_relu6 <- rgb_fc6
I0131 01:10:56.934041 25291 net.cpp:386] rgb_relu6 -> rgb_fc6 (in-place)
I0131 01:10:56.934057 25291 net.cpp:141] Setting up rgb_relu6
I0131 01:10:56.934068 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:56.934077 25291 net.cpp:156] Memory required for data: 3690791808
I0131 01:10:56.934084 25291 layer_factory.hpp:77] Creating layer rgb_drop6
I0131 01:10:56.934104 25291 net.cpp:91] Creating Layer rgb_drop6
I0131 01:10:56.934113 25291 net.cpp:425] rgb_drop6 <- rgb_fc6
I0131 01:10:56.934124 25291 net.cpp:386] rgb_drop6 -> rgb_fc6 (in-place)
I0131 01:10:56.934166 25291 net.cpp:141] Setting up rgb_drop6
I0131 01:10:56.934180 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:56.934188 25291 net.cpp:156] Memory required for data: 3691316096
I0131 01:10:56.934196 25291 layer_factory.hpp:77] Creating layer rgb_fc7
I0131 01:10:56.934211 25291 net.cpp:91] Creating Layer rgb_fc7
I0131 01:10:56.934219 25291 net.cpp:425] rgb_fc7 <- rgb_fc6
I0131 01:10:56.934231 25291 net.cpp:399] rgb_fc7 -> rgb_fc7
I0131 01:10:57.034631 25291 net.cpp:141] Setting up rgb_fc7
I0131 01:10:57.034673 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.034685 25291 net.cpp:156] Memory required for data: 3691840384
I0131 01:10:57.034703 25291 layer_factory.hpp:77] Creating layer rgb_relu7
I0131 01:10:57.034719 25291 net.cpp:91] Creating Layer rgb_relu7
I0131 01:10:57.034732 25291 net.cpp:425] rgb_relu7 <- rgb_fc7
I0131 01:10:57.034744 25291 net.cpp:386] rgb_relu7 -> rgb_fc7 (in-place)
I0131 01:10:57.034759 25291 net.cpp:141] Setting up rgb_relu7
I0131 01:10:57.034767 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.034773 25291 net.cpp:156] Memory required for data: 3692364672
I0131 01:10:57.034780 25291 layer_factory.hpp:77] Creating layer rgb_drop7
I0131 01:10:57.034792 25291 net.cpp:91] Creating Layer rgb_drop7
I0131 01:10:57.034801 25291 net.cpp:425] rgb_drop7 <- rgb_fc7
I0131 01:10:57.034811 25291 net.cpp:386] rgb_drop7 -> rgb_fc7 (in-place)
I0131 01:10:57.034855 25291 net.cpp:141] Setting up rgb_drop7
I0131 01:10:57.034870 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.034878 25291 net.cpp:156] Memory required for data: 3692888960
I0131 01:10:57.034884 25291 layer_factory.hpp:77] Creating layer rgb_fc7_rgb_drop7_0_split
I0131 01:10:57.034896 25291 net.cpp:91] Creating Layer rgb_fc7_rgb_drop7_0_split
I0131 01:10:57.034904 25291 net.cpp:425] rgb_fc7_rgb_drop7_0_split <- rgb_fc7
I0131 01:10:57.034914 25291 net.cpp:399] rgb_fc7_rgb_drop7_0_split -> rgb_fc7_rgb_drop7_0_split_0
I0131 01:10:57.034925 25291 net.cpp:399] rgb_fc7_rgb_drop7_0_split -> rgb_fc7_rgb_drop7_0_split_1
I0131 01:10:57.034989 25291 net.cpp:141] Setting up rgb_fc7_rgb_drop7_0_split
I0131 01:10:57.035004 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.035014 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.035022 25291 net.cpp:156] Memory required for data: 3693937536
I0131 01:10:57.035032 25291 layer_factory.hpp:77] Creating layer rgb_fc8
I0131 01:10:57.035045 25291 net.cpp:91] Creating Layer rgb_fc8
I0131 01:10:57.035054 25291 net.cpp:425] rgb_fc8 <- rgb_fc7_rgb_drop7_0_split_0
I0131 01:10:57.035065 25291 net.cpp:399] rgb_fc8 -> rgb_fc8
I0131 01:10:57.036523 25291 net.cpp:141] Setting up rgb_fc8
I0131 01:10:57.036542 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.036551 25291 net.cpp:156] Memory required for data: 3693944064
I0131 01:10:57.036564 25291 layer_factory.hpp:77] Creating layer rgb_fc8_rgb_fc8_0_split
I0131 01:10:57.036578 25291 net.cpp:91] Creating Layer rgb_fc8_rgb_fc8_0_split
I0131 01:10:57.036587 25291 net.cpp:425] rgb_fc8_rgb_fc8_0_split <- rgb_fc8
I0131 01:10:57.036598 25291 net.cpp:399] rgb_fc8_rgb_fc8_0_split -> rgb_fc8_rgb_fc8_0_split_0
I0131 01:10:57.036617 25291 net.cpp:399] rgb_fc8_rgb_fc8_0_split -> rgb_fc8_rgb_fc8_0_split_1
I0131 01:10:57.036664 25291 net.cpp:141] Setting up rgb_fc8_rgb_fc8_0_split
I0131 01:10:57.036677 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.036686 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.036695 25291 net.cpp:156] Memory required for data: 3693957120
I0131 01:10:57.036702 25291 layer_factory.hpp:77] Creating layer conv1
I0131 01:10:57.036720 25291 net.cpp:91] Creating Layer conv1
I0131 01:10:57.036731 25291 net.cpp:425] conv1 <- depth
I0131 01:10:57.036742 25291 net.cpp:399] conv1 -> conv1
I0131 01:10:57.036943 25291 net.cpp:141] Setting up conv1
I0131 01:10:57.036957 25291 net.cpp:148] Top shape: 32 128 112 112 (51380224)
I0131 01:10:57.036964 25291 net.cpp:156] Memory required for data: 3899478016
I0131 01:10:57.036991 25291 layer_factory.hpp:77] Creating layer relu1
I0131 01:10:57.037005 25291 net.cpp:91] Creating Layer relu1
I0131 01:10:57.037014 25291 net.cpp:425] relu1 <- conv1
I0131 01:10:57.037025 25291 net.cpp:386] relu1 -> conv1 (in-place)
I0131 01:10:57.037036 25291 net.cpp:141] Setting up relu1
I0131 01:10:57.037047 25291 net.cpp:148] Top shape: 32 128 112 112 (51380224)
I0131 01:10:57.037056 25291 net.cpp:156] Memory required for data: 4104998912
I0131 01:10:57.037065 25291 layer_factory.hpp:77] Creating layer depth_pool1
I0131 01:10:57.037080 25291 net.cpp:91] Creating Layer depth_pool1
I0131 01:10:57.037087 25291 net.cpp:425] depth_pool1 <- conv1
I0131 01:10:57.037098 25291 net.cpp:399] depth_pool1 -> depth_pool1
I0131 01:10:57.037147 25291 net.cpp:141] Setting up depth_pool1
I0131 01:10:57.037159 25291 net.cpp:148] Top shape: 32 128 56 56 (12845056)
I0131 01:10:57.037168 25291 net.cpp:156] Memory required for data: 4156379136
I0131 01:10:57.037175 25291 layer_factory.hpp:77] Creating layer norm1
I0131 01:10:57.037189 25291 net.cpp:91] Creating Layer norm1
I0131 01:10:57.037196 25291 net.cpp:425] norm1 <- depth_pool1
I0131 01:10:57.037209 25291 net.cpp:399] norm1 -> norm1
I0131 01:10:57.037251 25291 net.cpp:141] Setting up norm1
I0131 01:10:57.037262 25291 net.cpp:148] Top shape: 32 128 56 56 (12845056)
I0131 01:10:57.037271 25291 net.cpp:156] Memory required for data: 4207759360
I0131 01:10:57.037279 25291 layer_factory.hpp:77] Creating layer conv2
I0131 01:10:57.037297 25291 net.cpp:91] Creating Layer conv2
I0131 01:10:57.037305 25291 net.cpp:425] conv2 <- norm1
I0131 01:10:57.037317 25291 net.cpp:399] conv2 -> conv2
I0131 01:10:57.042095 25291 net.cpp:141] Setting up conv2
I0131 01:10:57.042129 25291 net.cpp:148] Top shape: 32 256 56 56 (25690112)
I0131 01:10:57.042138 25291 net.cpp:156] Memory required for data: 4310519808
I0131 01:10:57.042152 25291 layer_factory.hpp:77] Creating layer relu2
I0131 01:10:57.042165 25291 net.cpp:91] Creating Layer relu2
I0131 01:10:57.042174 25291 net.cpp:425] relu2 <- conv2
I0131 01:10:57.042184 25291 net.cpp:386] relu2 -> conv2 (in-place)
I0131 01:10:57.042197 25291 net.cpp:141] Setting up relu2
I0131 01:10:57.042207 25291 net.cpp:148] Top shape: 32 256 56 56 (25690112)
I0131 01:10:57.042215 25291 net.cpp:156] Memory required for data: 4413280256
I0131 01:10:57.042222 25291 layer_factory.hpp:77] Creating layer depth_pool2
I0131 01:10:57.042234 25291 net.cpp:91] Creating Layer depth_pool2
I0131 01:10:57.042249 25291 net.cpp:425] depth_pool2 <- conv2
I0131 01:10:57.042261 25291 net.cpp:399] depth_pool2 -> depth_pool2
I0131 01:10:57.042302 25291 net.cpp:141] Setting up depth_pool2
I0131 01:10:57.042313 25291 net.cpp:148] Top shape: 32 256 28 28 (6422528)
I0131 01:10:57.042321 25291 net.cpp:156] Memory required for data: 4438970368
I0131 01:10:57.042328 25291 layer_factory.hpp:77] Creating layer norm2
I0131 01:10:57.042341 25291 net.cpp:91] Creating Layer norm2
I0131 01:10:57.042351 25291 net.cpp:425] norm2 <- depth_pool2
I0131 01:10:57.042362 25291 net.cpp:399] norm2 -> norm2
I0131 01:10:57.042397 25291 net.cpp:141] Setting up norm2
I0131 01:10:57.042409 25291 net.cpp:148] Top shape: 32 256 28 28 (6422528)
I0131 01:10:57.042418 25291 net.cpp:156] Memory required for data: 4464660480
I0131 01:10:57.042426 25291 layer_factory.hpp:77] Creating layer conv3
I0131 01:10:57.042440 25291 net.cpp:91] Creating Layer conv3
I0131 01:10:57.042449 25291 net.cpp:425] conv3 <- norm2
I0131 01:10:57.042462 25291 net.cpp:399] conv3 -> conv3
I0131 01:10:57.046172 25291 net.cpp:141] Setting up conv3
I0131 01:10:57.046200 25291 net.cpp:148] Top shape: 32 384 28 28 (9633792)
I0131 01:10:57.046205 25291 net.cpp:156] Memory required for data: 4503195648
I0131 01:10:57.046217 25291 layer_factory.hpp:77] Creating layer relu3
I0131 01:10:57.046229 25291 net.cpp:91] Creating Layer relu3
I0131 01:10:57.046234 25291 net.cpp:425] relu3 <- conv3
I0131 01:10:57.046254 25291 net.cpp:386] relu3 -> conv3 (in-place)
I0131 01:10:57.046264 25291 net.cpp:141] Setting up relu3
I0131 01:10:57.046269 25291 net.cpp:148] Top shape: 32 384 28 28 (9633792)
I0131 01:10:57.046273 25291 net.cpp:156] Memory required for data: 4541730816
I0131 01:10:57.046277 25291 layer_factory.hpp:77] Creating layer depth_pool3
I0131 01:10:57.046285 25291 net.cpp:91] Creating Layer depth_pool3
I0131 01:10:57.046289 25291 net.cpp:425] depth_pool3 <- conv3
I0131 01:10:57.046298 25291 net.cpp:399] depth_pool3 -> depth_pool3
I0131 01:10:57.046337 25291 net.cpp:141] Setting up depth_pool3
I0131 01:10:57.046345 25291 net.cpp:148] Top shape: 32 384 14 14 (2408448)
I0131 01:10:57.046350 25291 net.cpp:156] Memory required for data: 4551364608
I0131 01:10:57.046353 25291 layer_factory.hpp:77] Creating layer conv4
I0131 01:10:57.046365 25291 net.cpp:91] Creating Layer conv4
I0131 01:10:57.046368 25291 net.cpp:425] conv4 <- depth_pool3
I0131 01:10:57.046375 25291 net.cpp:399] conv4 -> conv4
I0131 01:10:57.059540 25291 net.cpp:141] Setting up conv4
I0131 01:10:57.059586 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:57.059598 25291 net.cpp:156] Memory required for data: 4564209664
I0131 01:10:57.059617 25291 layer_factory.hpp:77] Creating layer relu4
I0131 01:10:57.059635 25291 net.cpp:91] Creating Layer relu4
I0131 01:10:57.059645 25291 net.cpp:425] relu4 <- conv4
I0131 01:10:57.059659 25291 net.cpp:386] relu4 -> conv4 (in-place)
I0131 01:10:57.059674 25291 net.cpp:141] Setting up relu4
I0131 01:10:57.059685 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:57.059695 25291 net.cpp:156] Memory required for data: 4577054720
I0131 01:10:57.059703 25291 layer_factory.hpp:77] Creating layer conv5
I0131 01:10:57.059720 25291 net.cpp:91] Creating Layer conv5
I0131 01:10:57.059729 25291 net.cpp:425] conv5 <- conv4
I0131 01:10:57.059744 25291 net.cpp:399] conv5 -> conv5
I0131 01:10:57.077530 25291 net.cpp:141] Setting up conv5
I0131 01:10:57.077579 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:57.077594 25291 net.cpp:156] Memory required for data: 4589899776
I0131 01:10:57.077612 25291 layer_factory.hpp:77] Creating layer relu5
I0131 01:10:57.077632 25291 net.cpp:91] Creating Layer relu5
I0131 01:10:57.077642 25291 net.cpp:425] relu5 <- conv5
I0131 01:10:57.077656 25291 net.cpp:386] relu5 -> conv5 (in-place)
I0131 01:10:57.077673 25291 net.cpp:141] Setting up relu5
I0131 01:10:57.077682 25291 net.cpp:148] Top shape: 32 512 14 14 (3211264)
I0131 01:10:57.077690 25291 net.cpp:156] Memory required for data: 4602744832
I0131 01:10:57.077697 25291 layer_factory.hpp:77] Creating layer depth_pool5
I0131 01:10:57.077710 25291 net.cpp:91] Creating Layer depth_pool5
I0131 01:10:57.077718 25291 net.cpp:425] depth_pool5 <- conv5
I0131 01:10:57.077729 25291 net.cpp:399] depth_pool5 -> depth_pool5
I0131 01:10:57.077795 25291 net.cpp:141] Setting up depth_pool5
I0131 01:10:57.077810 25291 net.cpp:148] Top shape: 32 512 7 7 (802816)
I0131 01:10:57.077818 25291 net.cpp:156] Memory required for data: 4605956096
I0131 01:10:57.077826 25291 layer_factory.hpp:77] Creating layer depth_fc6
I0131 01:10:57.077841 25291 net.cpp:91] Creating Layer depth_fc6
I0131 01:10:57.077852 25291 net.cpp:425] depth_fc6 <- depth_pool5
I0131 01:10:57.077863 25291 net.cpp:399] depth_fc6 -> depth_fc6
I0131 01:10:57.695863 25291 net.cpp:141] Setting up depth_fc6
I0131 01:10:57.695907 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.695911 25291 net.cpp:156] Memory required for data: 4606480384
I0131 01:10:57.695921 25291 layer_factory.hpp:77] Creating layer depth_relu6
I0131 01:10:57.695935 25291 net.cpp:91] Creating Layer depth_relu6
I0131 01:10:57.695940 25291 net.cpp:425] depth_relu6 <- depth_fc6
I0131 01:10:57.695947 25291 net.cpp:386] depth_relu6 -> depth_fc6 (in-place)
I0131 01:10:57.695955 25291 net.cpp:141] Setting up depth_relu6
I0131 01:10:57.695961 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.695966 25291 net.cpp:156] Memory required for data: 4607004672
I0131 01:10:57.695971 25291 layer_factory.hpp:77] Creating layer depth_drop6
I0131 01:10:57.695976 25291 net.cpp:91] Creating Layer depth_drop6
I0131 01:10:57.695981 25291 net.cpp:425] depth_drop6 <- depth_fc6
I0131 01:10:57.695987 25291 net.cpp:386] depth_drop6 -> depth_fc6 (in-place)
I0131 01:10:57.696005 25291 net.cpp:141] Setting up depth_drop6
I0131 01:10:57.696012 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.696017 25291 net.cpp:156] Memory required for data: 4607528960
I0131 01:10:57.696022 25291 layer_factory.hpp:77] Creating layer depth_fc7
I0131 01:10:57.696030 25291 net.cpp:91] Creating Layer depth_fc7
I0131 01:10:57.696035 25291 net.cpp:425] depth_fc7 <- depth_fc6
I0131 01:10:57.696040 25291 net.cpp:399] depth_fc7 -> depth_fc7
I0131 01:10:57.778560 25291 net.cpp:141] Setting up depth_fc7
I0131 01:10:57.778599 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.778611 25291 net.cpp:156] Memory required for data: 4608053248
I0131 01:10:57.778623 25291 layer_factory.hpp:77] Creating layer depth_relu7
I0131 01:10:57.778640 25291 net.cpp:91] Creating Layer depth_relu7
I0131 01:10:57.778648 25291 net.cpp:425] depth_relu7 <- depth_fc7
I0131 01:10:57.778656 25291 net.cpp:386] depth_relu7 -> depth_fc7 (in-place)
I0131 01:10:57.778666 25291 net.cpp:141] Setting up depth_relu7
I0131 01:10:57.778674 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.778679 25291 net.cpp:156] Memory required for data: 4608577536
I0131 01:10:57.778683 25291 layer_factory.hpp:77] Creating layer depth_drop7
I0131 01:10:57.778692 25291 net.cpp:91] Creating Layer depth_drop7
I0131 01:10:57.778697 25291 net.cpp:425] depth_drop7 <- depth_fc7
I0131 01:10:57.778702 25291 net.cpp:386] depth_drop7 -> depth_fc7 (in-place)
I0131 01:10:57.778723 25291 net.cpp:141] Setting up depth_drop7
I0131 01:10:57.778730 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.778735 25291 net.cpp:156] Memory required for data: 4609101824
I0131 01:10:57.778739 25291 layer_factory.hpp:77] Creating layer depth_fc7_depth_drop7_0_split
I0131 01:10:57.778753 25291 net.cpp:91] Creating Layer depth_fc7_depth_drop7_0_split
I0131 01:10:57.778759 25291 net.cpp:425] depth_fc7_depth_drop7_0_split <- depth_fc7
I0131 01:10:57.778764 25291 net.cpp:399] depth_fc7_depth_drop7_0_split -> depth_fc7_depth_drop7_0_split_0
I0131 01:10:57.778771 25291 net.cpp:399] depth_fc7_depth_drop7_0_split -> depth_fc7_depth_drop7_0_split_1
I0131 01:10:57.778797 25291 net.cpp:141] Setting up depth_fc7_depth_drop7_0_split
I0131 01:10:57.778805 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.778810 25291 net.cpp:148] Top shape: 32 4096 (131072)
I0131 01:10:57.778815 25291 net.cpp:156] Memory required for data: 4610150400
I0131 01:10:57.778818 25291 layer_factory.hpp:77] Creating layer depth_fc8
I0131 01:10:57.778827 25291 net.cpp:91] Creating Layer depth_fc8
I0131 01:10:57.778832 25291 net.cpp:425] depth_fc8 <- depth_fc7_depth_drop7_0_split_0
I0131 01:10:57.778839 25291 net.cpp:399] depth_fc8 -> depth_fc8
I0131 01:10:57.780118 25291 net.cpp:141] Setting up depth_fc8
I0131 01:10:57.780140 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.780144 25291 net.cpp:156] Memory required for data: 4610156928
I0131 01:10:57.780153 25291 layer_factory.hpp:77] Creating layer depth_fc8_depth_fc8_0_split
I0131 01:10:57.780159 25291 net.cpp:91] Creating Layer depth_fc8_depth_fc8_0_split
I0131 01:10:57.780165 25291 net.cpp:425] depth_fc8_depth_fc8_0_split <- depth_fc8
I0131 01:10:57.780171 25291 net.cpp:399] depth_fc8_depth_fc8_0_split -> depth_fc8_depth_fc8_0_split_0
I0131 01:10:57.780179 25291 net.cpp:399] depth_fc8_depth_fc8_0_split -> depth_fc8_depth_fc8_0_split_1
I0131 01:10:57.780205 25291 net.cpp:141] Setting up depth_fc8_depth_fc8_0_split
I0131 01:10:57.780210 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.780215 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.780220 25291 net.cpp:156] Memory required for data: 4610169984
I0131 01:10:57.780225 25291 layer_factory.hpp:77] Creating layer concat
I0131 01:10:57.780237 25291 net.cpp:91] Creating Layer concat
I0131 01:10:57.780243 25291 net.cpp:425] concat <- rgb_fc7_rgb_drop7_0_split_1
I0131 01:10:57.780248 25291 net.cpp:425] concat <- depth_fc7_depth_drop7_0_split_1
I0131 01:10:57.780256 25291 net.cpp:399] concat -> concat
I0131 01:10:57.780272 25291 net.cpp:141] Setting up concat
I0131 01:10:57.780278 25291 net.cpp:148] Top shape: 32 8192 (262144)
I0131 01:10:57.780282 25291 net.cpp:156] Memory required for data: 4611218560
I0131 01:10:57.780287 25291 layer_factory.hpp:77] Creating layer rgbd_fc8
I0131 01:10:57.780294 25291 net.cpp:91] Creating Layer rgbd_fc8
I0131 01:10:57.780299 25291 net.cpp:425] rgbd_fc8 <- concat
I0131 01:10:57.780306 25291 net.cpp:399] rgbd_fc8 -> rgbd_fc8
I0131 01:10:57.783368 25291 net.cpp:141] Setting up rgbd_fc8
I0131 01:10:57.783386 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.783393 25291 net.cpp:156] Memory required for data: 4611225088
I0131 01:10:57.783401 25291 layer_factory.hpp:77] Creating layer rgbd_fc8_rgbd_fc8_0_split
I0131 01:10:57.783408 25291 net.cpp:91] Creating Layer rgbd_fc8_rgbd_fc8_0_split
I0131 01:10:57.783414 25291 net.cpp:425] rgbd_fc8_rgbd_fc8_0_split <- rgbd_fc8
I0131 01:10:57.783421 25291 net.cpp:399] rgbd_fc8_rgbd_fc8_0_split -> rgbd_fc8_rgbd_fc8_0_split_0
I0131 01:10:57.783429 25291 net.cpp:399] rgbd_fc8_rgbd_fc8_0_split -> rgbd_fc8_rgbd_fc8_0_split_1
I0131 01:10:57.783453 25291 net.cpp:141] Setting up rgbd_fc8_rgbd_fc8_0_split
I0131 01:10:57.783459 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.783465 25291 net.cpp:148] Top shape: 32 51 (1632)
I0131 01:10:57.783470 25291 net.cpp:156] Memory required for data: 4611238144
I0131 01:10:57.783473 25291 layer_factory.hpp:77] Creating layer rgb_accuracy
I0131 01:10:57.783489 25291 net.cpp:91] Creating Layer rgb_accuracy
I0131 01:10:57.783494 25291 net.cpp:425] rgb_accuracy <- rgb_fc8_rgb_fc8_0_split_0
I0131 01:10:57.783500 25291 net.cpp:425] rgb_accuracy <- label_data_2_split_0
I0131 01:10:57.783505 25291 net.cpp:399] rgb_accuracy -> rgb_accuracy
I0131 01:10:57.783512 25291 net.cpp:141] Setting up rgb_accuracy
I0131 01:10:57.783519 25291 net.cpp:148] Top shape: (1)
I0131 01:10:57.783522 25291 net.cpp:156] Memory required for data: 4611238148
I0131 01:10:57.783526 25291 layer_factory.hpp:77] Creating layer rgb_loss
I0131 01:10:57.783535 25291 net.cpp:91] Creating Layer rgb_loss
I0131 01:10:57.783540 25291 net.cpp:425] rgb_loss <- rgb_fc8_rgb_fc8_0_split_1
I0131 01:10:57.783545 25291 net.cpp:425] rgb_loss <- label_data_2_split_1
I0131 01:10:57.783550 25291 net.cpp:399] rgb_loss -> rgb_loss
I0131 01:10:57.783557 25291 layer_factory.hpp:77] Creating layer rgb_loss
I0131 01:10:57.783617 25291 net.cpp:141] Setting up rgb_loss
I0131 01:10:57.783624 25291 net.cpp:148] Top shape: (1)
I0131 01:10:57.783628 25291 net.cpp:151]     with loss weight 1
I0131 01:10:57.783638 25291 net.cpp:156] Memory required for data: 4611238152
I0131 01:10:57.783643 25291 layer_factory.hpp:77] Creating layer depth_accuracy
I0131 01:10:57.783648 25291 net.cpp:91] Creating Layer depth_accuracy
I0131 01:10:57.783653 25291 net.cpp:425] depth_accuracy <- depth_fc8_depth_fc8_0_split_0
I0131 01:10:57.783658 25291 net.cpp:425] depth_accuracy <- label_data_2_split_2
I0131 01:10:57.783663 25291 net.cpp:399] depth_accuracy -> depth_accuracy
I0131 01:10:57.783669 25291 net.cpp:141] Setting up depth_accuracy
I0131 01:10:57.783675 25291 net.cpp:148] Top shape: (1)
I0131 01:10:57.783679 25291 net.cpp:156] Memory required for data: 4611238156
I0131 01:10:57.783684 25291 layer_factory.hpp:77] Creating layer depth_loss
I0131 01:10:57.783690 25291 net.cpp:91] Creating Layer depth_loss
I0131 01:10:57.783695 25291 net.cpp:425] depth_loss <- depth_fc8_depth_fc8_0_split_1
I0131 01:10:57.783701 25291 net.cpp:425] depth_loss <- label_data_2_split_3
I0131 01:10:57.783705 25291 net.cpp:399] depth_loss -> depth_loss
I0131 01:10:57.783712 25291 layer_factory.hpp:77] Creating layer depth_loss
I0131 01:10:57.783764 25291 net.cpp:141] Setting up depth_loss
I0131 01:10:57.783771 25291 net.cpp:148] Top shape: (1)
I0131 01:10:57.783776 25291 net.cpp:151]     with loss weight 1
I0131 01:10:57.783781 25291 net.cpp:156] Memory required for data: 4611238160
I0131 01:10:57.783784 25291 layer_factory.hpp:77] Creating layer rgbd_accuracy
I0131 01:10:57.783790 25291 net.cpp:91] Creating Layer rgbd_accuracy
I0131 01:10:57.783795 25291 net.cpp:425] rgbd_accuracy <- rgbd_fc8_rgbd_fc8_0_split_0
I0131 01:10:57.783800 25291 net.cpp:425] rgbd_accuracy <- label_data_2_split_4
I0131 01:10:57.783807 25291 net.cpp:399] rgbd_accuracy -> rgbd_accuracy
I0131 01:10:57.783812 25291 net.cpp:141] Setting up rgbd_accuracy
I0131 01:10:57.783818 25291 net.cpp:148] Top shape: (1)
I0131 01:10:57.783823 25291 net.cpp:156] Memory required for data: 4611238164
I0131 01:10:57.783828 25291 layer_factory.hpp:77] Creating layer rgbd_loss
I0131 01:10:57.783833 25291 net.cpp:91] Creating Layer rgbd_loss
I0131 01:10:57.783838 25291 net.cpp:425] rgbd_loss <- rgbd_fc8_rgbd_fc8_0_split_1
I0131 01:10:57.783843 25291 net.cpp:425] rgbd_loss <- label_data_2_split_5
I0131 01:10:57.783849 25291 net.cpp:399] rgbd_loss -> rgbd_loss
I0131 01:10:57.783855 25291 layer_factory.hpp:77] Creating layer rgbd_loss
I0131 01:10:57.783908 25291 net.cpp:141] Setting up rgbd_loss
I0131 01:10:57.783915 25291 net.cpp:148] Top shape: (1)
I0131 01:10:57.783921 25291 net.cpp:151]     with loss weight 1
I0131 01:10:57.783924 25291 net.cpp:156] Memory required for data: 4611238168
I0131 01:10:57.783929 25291 net.cpp:217] rgbd_loss needs backward computation.
I0131 01:10:57.783933 25291 net.cpp:219] rgbd_accuracy does not need backward computation.
I0131 01:10:57.783938 25291 net.cpp:217] depth_loss needs backward computation.
I0131 01:10:57.783943 25291 net.cpp:219] depth_accuracy does not need backward computation.
I0131 01:10:57.783947 25291 net.cpp:217] rgb_loss needs backward computation.
I0131 01:10:57.783953 25291 net.cpp:219] rgb_accuracy does not need backward computation.
I0131 01:10:57.783957 25291 net.cpp:217] rgbd_fc8_rgbd_fc8_0_split needs backward computation.
I0131 01:10:57.783960 25291 net.cpp:217] rgbd_fc8 needs backward computation.
I0131 01:10:57.783965 25291 net.cpp:217] concat needs backward computation.
I0131 01:10:57.783969 25291 net.cpp:217] depth_fc8_depth_fc8_0_split needs backward computation.
I0131 01:10:57.783973 25291 net.cpp:217] depth_fc8 needs backward computation.
I0131 01:10:57.783977 25291 net.cpp:217] depth_fc7_depth_drop7_0_split needs backward computation.
I0131 01:10:57.783980 25291 net.cpp:217] depth_drop7 needs backward computation.
I0131 01:10:57.783985 25291 net.cpp:217] depth_relu7 needs backward computation.
I0131 01:10:57.783989 25291 net.cpp:217] depth_fc7 needs backward computation.
I0131 01:10:57.783993 25291 net.cpp:217] depth_drop6 needs backward computation.
I0131 01:10:57.783998 25291 net.cpp:217] depth_relu6 needs backward computation.
I0131 01:10:57.784003 25291 net.cpp:217] depth_fc6 needs backward computation.
I0131 01:10:57.784006 25291 net.cpp:219] depth_pool5 does not need backward computation.
I0131 01:10:57.784011 25291 net.cpp:219] relu5 does not need backward computation.
I0131 01:10:57.784015 25291 net.cpp:219] conv5 does not need backward computation.
I0131 01:10:57.784020 25291 net.cpp:219] relu4 does not need backward computation.
I0131 01:10:57.784024 25291 net.cpp:219] conv4 does not need backward computation.
I0131 01:10:57.784029 25291 net.cpp:219] depth_pool3 does not need backward computation.
I0131 01:10:57.784034 25291 net.cpp:219] relu3 does not need backward computation.
I0131 01:10:57.784039 25291 net.cpp:219] conv3 does not need backward computation.
I0131 01:10:57.784042 25291 net.cpp:219] norm2 does not need backward computation.
I0131 01:10:57.784047 25291 net.cpp:219] depth_pool2 does not need backward computation.
I0131 01:10:57.784052 25291 net.cpp:219] relu2 does not need backward computation.
I0131 01:10:57.784057 25291 net.cpp:219] conv2 does not need backward computation.
I0131 01:10:57.784061 25291 net.cpp:219] norm1 does not need backward computation.
I0131 01:10:57.784065 25291 net.cpp:219] depth_pool1 does not need backward computation.
I0131 01:10:57.784070 25291 net.cpp:219] relu1 does not need backward computation.
I0131 01:10:57.784075 25291 net.cpp:219] conv1 does not need backward computation.
I0131 01:10:57.784080 25291 net.cpp:217] rgb_fc8_rgb_fc8_0_split needs backward computation.
I0131 01:10:57.784085 25291 net.cpp:217] rgb_fc8 needs backward computation.
I0131 01:10:57.784090 25291 net.cpp:217] rgb_fc7_rgb_drop7_0_split needs backward computation.
I0131 01:10:57.784095 25291 net.cpp:217] rgb_drop7 needs backward computation.
I0131 01:10:57.784098 25291 net.cpp:217] rgb_relu7 needs backward computation.
I0131 01:10:57.784103 25291 net.cpp:217] rgb_fc7 needs backward computation.
I0131 01:10:57.784107 25291 net.cpp:217] rgb_drop6 needs backward computation.
I0131 01:10:57.784111 25291 net.cpp:217] rgb_relu6 needs backward computation.
I0131 01:10:57.784116 25291 net.cpp:217] rgb_fc6 needs backward computation.
I0131 01:10:57.784121 25291 net.cpp:219] rgb_pool5 does not need backward computation.
I0131 01:10:57.784126 25291 net.cpp:219] relu5_3 does not need backward computation.
I0131 01:10:57.784131 25291 net.cpp:219] conv5_3 does not need backward computation.
I0131 01:10:57.784134 25291 net.cpp:219] relu5_2 does not need backward computation.
I0131 01:10:57.784138 25291 net.cpp:219] conv5_2 does not need backward computation.
I0131 01:10:57.784142 25291 net.cpp:219] relu5_1 does not need backward computation.
I0131 01:10:57.784147 25291 net.cpp:219] conv5_1 does not need backward computation.
I0131 01:10:57.784152 25291 net.cpp:219] rgb_pool4 does not need backward computation.
I0131 01:10:57.784157 25291 net.cpp:219] relu4_3 does not need backward computation.
I0131 01:10:57.784162 25291 net.cpp:219] conv4_3 does not need backward computation.
I0131 01:10:57.784165 25291 net.cpp:219] relu4_2 does not need backward computation.
I0131 01:10:57.784169 25291 net.cpp:219] conv4_2 does not need backward computation.
I0131 01:10:57.784174 25291 net.cpp:219] relu4_1 does not need backward computation.
I0131 01:10:57.784178 25291 net.cpp:219] conv4_1 does not need backward computation.
I0131 01:10:57.784183 25291 net.cpp:219] rgb_pool3 does not need backward computation.
I0131 01:10:57.784188 25291 net.cpp:219] relu3_3 does not need backward computation.
I0131 01:10:57.784193 25291 net.cpp:219] conv3_3 does not need backward computation.
I0131 01:10:57.784196 25291 net.cpp:219] relu3_2 does not need backward computation.
I0131 01:10:57.784200 25291 net.cpp:219] conv3_2 does not need backward computation.
I0131 01:10:57.784204 25291 net.cpp:219] relu3_1 does not need backward computation.
I0131 01:10:57.784209 25291 net.cpp:219] conv3_1 does not need backward computation.
I0131 01:10:57.784214 25291 net.cpp:219] rgb_pool2 does not need backward computation.
I0131 01:10:57.784219 25291 net.cpp:219] relu2_2 does not need backward computation.
I0131 01:10:57.784222 25291 net.cpp:219] conv2_2 does not need backward computation.
I0131 01:10:57.784227 25291 net.cpp:219] relu2_1 does not need backward computation.
I0131 01:10:57.784231 25291 net.cpp:219] conv2_1 does not need backward computation.
I0131 01:10:57.784235 25291 net.cpp:219] rgb_pool1 does not need backward computation.
I0131 01:10:57.784240 25291 net.cpp:219] relu1_2 does not need backward computation.
I0131 01:10:57.784245 25291 net.cpp:219] conv1_2 does not need backward computation.
I0131 01:10:57.784250 25291 net.cpp:219] relu1_1 does not need backward computation.
I0131 01:10:57.784253 25291 net.cpp:219] conv1_1 does not need backward computation.
I0131 01:10:57.784258 25291 net.cpp:219] label_data_2_split does not need backward computation.
I0131 01:10:57.784265 25291 net.cpp:219] data does not need backward computation.
I0131 01:10:57.784268 25291 net.cpp:261] This network produces output depth_accuracy
I0131 01:10:57.784272 25291 net.cpp:261] This network produces output depth_loss
I0131 01:10:57.784277 25291 net.cpp:261] This network produces output rgb_accuracy
I0131 01:10:57.784281 25291 net.cpp:261] This network produces output rgb_loss
I0131 01:10:57.784286 25291 net.cpp:261] This network produces output rgbd_accuracy
I0131 01:10:57.784291 25291 net.cpp:261] This network produces output rgbd_loss
I0131 01:10:57.784320 25291 net.cpp:274] Network initialization done.
I0131 01:10:57.785203 25291 solver.cpp:181] Creating test net (#0) specified by test_net file: test.prototxt
I0131 01:10:57.785477 25291 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Python"
  top: "rgb"
  top: "depth"
  top: "label"
  python_param {
    module: "data_layers.washington_data_layer"
    layer: "WashingtonDataLayer"
    param_str: "{\'img_size\': (224, 224), \'split\': \'test\', \'dataset_dir\': \'/home/kevin/dataset/washington_rgbd_dataset\', \'randomize\': False, \'mean\': (104.00698793, 116.66876762, 122.67891434), \'seed\': 1337, \'batch_size\': 1, \'crop_size\': (224, 224, 224, 224)}"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "rgb"
  top: "conv1_1"
  param {
    name: "conv1_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    name: "conv1_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "rgb_pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "rgb_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "rgb_pool1"
  top: "conv2_1"
  param {
    name: "conv2_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    name: "conv2_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "rgb_pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "rgb_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "rgb_pool2"
  top: "conv3_1"
  param {
    name: "conv3_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    name: "conv3_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    name: "conv3_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "rgb_pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "rgb_pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "rgb_pool3"
  top: "conv4_1"
  param {
    name: "conv4_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    name: "conv4_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    name: "conv4_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "rgb_pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "rgb_pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "rgb_pool4"
  top: "conv5_1"
  param {
    name: "conv5_1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    name: "conv5_2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    name: "conv5_3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rgb_pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "rgb_pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "rgb_fc6"
  type: "InnerProduct"
  bottom: "rgb_pool5"
  top: "rgb_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_relu6"
  type: "ReLU"
  bottom: "rgb_fc6"
  top: "rgb_fc6"
}
layer {
  name: "rgb_drop6"
  type: "Dropout"
  bottom: "rgb_fc6"
  top: "rgb_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "rgb_fc7"
  type: "InnerProduct"
  bottom: "rgb_fc6"
  top: "rgb_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_relu7"
  type: "ReLU"
  bottom: "rgb_fc7"
  top: "rgb_fc7"
}
layer {
  name: "rgb_drop7"
  type: "Dropout"
  bottom: "rgb_fc7"
  top: "rgb_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "rgb_fc8"
  type: "InnerProduct"
  bottom: "rgb_fc7"
  top: "rgb_fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 51
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "depth"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "depth_pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "depth_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "depth_pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "depth_pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "depth_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "depth_pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "depth_pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "depth_pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "depth_pool3"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "depth_pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "depth_pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "depth_fc6"
  type: "InnerProduct"
  bottom: "depth_pool5"
  top: "depth_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "depth_relu6"
  type: "ReLU"
  bottom: "depth_fc6"
  top: "depth_fc6"
}
layer {
  name: "depth_drop6"
  type: "Dropout"
  bottom: "depth_fc6"
  top: "depth_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "depth_fc7"
  type: "InnerProduct"
  bottom: "depth_fc6"
  top: "depth_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "depth_relu7"
  type: "ReLU"
  bottom: "depth_fc7"
  top: "depth_fc7"
}
layer {
  name: "depth_drop7"
  type: "Dropout"
  bottom: "depth_fc7"
  top: "depth_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "depth_fc8"
  type: "InnerProduct"
  bottom: "depth_fc7"
  top: "depth_fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 51
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "rgb_fc7"
  bottom: "depth_fc7"
  top: "concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "rgbd_fc8"
  type: "InnerProduct"
  bottom: "concat"
  top: "rgbd_fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 51
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "rgb_accuracy"
  type: "Accuracy"
  bottom: "rgb_fc8"
  bottom: "label"
  top: "rgb_accuracy"
}
layer {
  name: "rgb_loss"
  type: "SoftmaxWithLoss"
  bottom: "rgb_fc8"
  bottom: "label"
  top: "rgb_loss"
}
layer {
  name: "depth_accuracy"
  type: "Accuracy"
  bottom: "depth_fc8"
  bottom: "label"
  top: "depth_accuracy"
}
layer {
  name: "depth_loss"
  type: "SoftmaxWithLoss"
  bottom: "depth_fc8"
  bottom: "label"
  top: "depth_loss"
}
layer {
  name: "rgbd_accuracy"
  type: "Accuracy"
  bottom: "rgbd_fc8"
  bottom: "label"
  top: "rgbd_accuracy"
}
layer {
  name: "rgbd_loss"
  type: "SoftmaxWithLoss"
  bottom: "rgbd_fc8"
  bottom: "label"
  top: "rgbd_loss"
}
I0131 01:10:57.787792 25291 layer_factory.hpp:77] Creating layer data
I0131 01:10:57.787847 25291 net.cpp:91] Creating Layer data
I0131 01:10:57.787855 25291 net.cpp:399] data -> rgb
I0131 01:10:57.787863 25291 net.cpp:399] data -> depth
I0131 01:10:57.787868 25291 net.cpp:399] data -> label
{'img_size': (224, 224), 'split': 'test', 'dataset_dir': '/home/kevin/dataset/washington_rgbd_dataset', 'crop_size': (224, 224, 224, 224), 'randomize': False, 'seed': 1337, 'batch_size': 1, 'mean': (104.00698793, 116.66876762, 122.67891434)}
I0131 01:10:57.791038 25291 net.cpp:141] Setting up data
I0131 01:10:57.791061 25291 net.cpp:148] Top shape: 1 3 224 224 (150528)
I0131 01:10:57.791067 25291 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0131 01:10:57.791074 25291 net.cpp:148] Top shape: 1 1 (1)
I0131 01:10:57.791077 25291 net.cpp:156] Memory required for data: 802820
I0131 01:10:57.791085 25291 layer_factory.hpp:77] Creating layer label_data_2_split
I0131 01:10:57.791093 25291 net.cpp:91] Creating Layer label_data_2_split
I0131 01:10:57.791100 25291 net.cpp:425] label_data_2_split <- label
I0131 01:10:57.791106 25291 net.cpp:399] label_data_2_split -> label_data_2_split_0
I0131 01:10:57.791115 25291 net.cpp:399] label_data_2_split -> label_data_2_split_1
I0131 01:10:57.791121 25291 net.cpp:399] label_data_2_split -> label_data_2_split_2
I0131 01:10:57.791126 25291 net.cpp:399] label_data_2_split -> label_data_2_split_3
I0131 01:10:57.791131 25291 net.cpp:399] label_data_2_split -> label_data_2_split_4
I0131 01:10:57.791137 25291 net.cpp:399] label_data_2_split -> label_data_2_split_5
I0131 01:10:57.791188 25291 net.cpp:141] Setting up label_data_2_split
I0131 01:10:57.791194 25291 net.cpp:148] Top shape: 1 1 (1)
I0131 01:10:57.791199 25291 net.cpp:148] Top shape: 1 1 (1)
I0131 01:10:57.791204 25291 net.cpp:148] Top shape: 1 1 (1)
I0131 01:10:57.791209 25291 net.cpp:148] Top shape: 1 1 (1)
I0131 01:10:57.791214 25291 net.cpp:148] Top shape: 1 1 (1)
I0131 01:10:57.791219 25291 net.cpp:148] Top shape: 1 1 (1)
I0131 01:10:57.791224 25291 net.cpp:156] Memory required for data: 802844
I0131 01:10:57.791229 25291 layer_factory.hpp:77] Creating layer conv1_1
I0131 01:10:57.791239 25291 net.cpp:91] Creating Layer conv1_1
I0131 01:10:57.791244 25291 net.cpp:425] conv1_1 <- rgb
I0131 01:10:57.791250 25291 net.cpp:399] conv1_1 -> conv1_1
I0131 01:10:57.791422 25291 net.cpp:141] Setting up conv1_1
I0131 01:10:57.791430 25291 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0131 01:10:57.791435 25291 net.cpp:156] Memory required for data: 13647900
I0131 01:10:57.791445 25291 layer_factory.hpp:77] Creating layer relu1_1
I0131 01:10:57.791450 25291 net.cpp:91] Creating Layer relu1_1
I0131 01:10:57.791455 25291 net.cpp:425] relu1_1 <- conv1_1
I0131 01:10:57.791460 25291 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0131 01:10:57.791465 25291 net.cpp:141] Setting up relu1_1
I0131 01:10:57.791471 25291 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0131 01:10:57.791476 25291 net.cpp:156] Memory required for data: 26492956
I0131 01:10:57.791479 25291 layer_factory.hpp:77] Creating layer conv1_2
I0131 01:10:57.791487 25291 net.cpp:91] Creating Layer conv1_2
I0131 01:10:57.791492 25291 net.cpp:425] conv1_2 <- conv1_1
I0131 01:10:57.791497 25291 net.cpp:399] conv1_2 -> conv1_2
I0131 01:10:57.792105 25291 net.cpp:141] Setting up conv1_2
I0131 01:10:57.792117 25291 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0131 01:10:57.792122 25291 net.cpp:156] Memory required for data: 39338012
I0131 01:10:57.792131 25291 layer_factory.hpp:77] Creating layer relu1_2
I0131 01:10:57.792138 25291 net.cpp:91] Creating Layer relu1_2
I0131 01:10:57.792145 25291 net.cpp:425] relu1_2 <- conv1_2
I0131 01:10:57.792150 25291 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0131 01:10:57.792156 25291 net.cpp:141] Setting up relu1_2
I0131 01:10:57.792161 25291 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0131 01:10:57.792166 25291 net.cpp:156] Memory required for data: 52183068
I0131 01:10:57.792171 25291 layer_factory.hpp:77] Creating layer rgb_pool1
I0131 01:10:57.792177 25291 net.cpp:91] Creating Layer rgb_pool1
I0131 01:10:57.792182 25291 net.cpp:425] rgb_pool1 <- conv1_2
I0131 01:10:57.792187 25291 net.cpp:399] rgb_pool1 -> rgb_pool1
I0131 01:10:57.792213 25291 net.cpp:141] Setting up rgb_pool1
I0131 01:10:57.792220 25291 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0131 01:10:57.792224 25291 net.cpp:156] Memory required for data: 55394332
I0131 01:10:57.792229 25291 layer_factory.hpp:77] Creating layer conv2_1
I0131 01:10:57.792237 25291 net.cpp:91] Creating Layer conv2_1
I0131 01:10:57.792242 25291 net.cpp:425] conv2_1 <- rgb_pool1
I0131 01:10:57.792248 25291 net.cpp:399] conv2_1 -> conv2_1
I0131 01:10:57.792917 25291 net.cpp:141] Setting up conv2_1
I0131 01:10:57.792929 25291 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0131 01:10:57.792934 25291 net.cpp:156] Memory required for data: 61816860
I0131 01:10:57.792942 25291 layer_factory.hpp:77] Creating layer relu2_1
I0131 01:10:57.792948 25291 net.cpp:91] Creating Layer relu2_1
I0131 01:10:57.792953 25291 net.cpp:425] relu2_1 <- conv2_1
I0131 01:10:57.792958 25291 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0131 01:10:57.792964 25291 net.cpp:141] Setting up relu2_1
I0131 01:10:57.792970 25291 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0131 01:10:57.792974 25291 net.cpp:156] Memory required for data: 68239388
I0131 01:10:57.792979 25291 layer_factory.hpp:77] Creating layer conv2_2
I0131 01:10:57.792986 25291 net.cpp:91] Creating Layer conv2_2
I0131 01:10:57.792991 25291 net.cpp:425] conv2_2 <- conv2_1
I0131 01:10:57.792996 25291 net.cpp:399] conv2_2 -> conv2_2
I0131 01:10:57.793701 25291 net.cpp:141] Setting up conv2_2
I0131 01:10:57.793709 25291 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0131 01:10:57.793715 25291 net.cpp:156] Memory required for data: 74661916
I0131 01:10:57.793720 25291 layer_factory.hpp:77] Creating layer relu2_2
I0131 01:10:57.793726 25291 net.cpp:91] Creating Layer relu2_2
I0131 01:10:57.793731 25291 net.cpp:425] relu2_2 <- conv2_2
I0131 01:10:57.793736 25291 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0131 01:10:57.793742 25291 net.cpp:141] Setting up relu2_2
I0131 01:10:57.793747 25291 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0131 01:10:57.793751 25291 net.cpp:156] Memory required for data: 81084444
I0131 01:10:57.793756 25291 layer_factory.hpp:77] Creating layer rgb_pool2
I0131 01:10:57.793762 25291 net.cpp:91] Creating Layer rgb_pool2
I0131 01:10:57.793766 25291 net.cpp:425] rgb_pool2 <- conv2_2
I0131 01:10:57.793771 25291 net.cpp:399] rgb_pool2 -> rgb_pool2
I0131 01:10:57.793795 25291 net.cpp:141] Setting up rgb_pool2
I0131 01:10:57.793802 25291 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0131 01:10:57.793805 25291 net.cpp:156] Memory required for data: 82690076
I0131 01:10:57.793809 25291 layer_factory.hpp:77] Creating layer conv3_1
I0131 01:10:57.793817 25291 net.cpp:91] Creating Layer conv3_1
I0131 01:10:57.793820 25291 net.cpp:425] conv3_1 <- rgb_pool2
I0131 01:10:57.793828 25291 net.cpp:399] conv3_1 -> conv3_1
I0131 01:10:57.795382 25291 net.cpp:141] Setting up conv3_1
I0131 01:10:57.795394 25291 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0131 01:10:57.795399 25291 net.cpp:156] Memory required for data: 85901340
I0131 01:10:57.795408 25291 layer_factory.hpp:77] Creating layer relu3_1
I0131 01:10:57.795413 25291 net.cpp:91] Creating Layer relu3_1
I0131 01:10:57.795418 25291 net.cpp:425] relu3_1 <- conv3_1
I0131 01:10:57.795424 25291 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0131 01:10:57.795430 25291 net.cpp:141] Setting up relu3_1
I0131 01:10:57.795436 25291 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0131 01:10:57.795440 25291 net.cpp:156] Memory required for data: 89112604
I0131 01:10:57.795445 25291 layer_factory.hpp:77] Creating layer conv3_2
I0131 01:10:57.795452 25291 net.cpp:91] Creating Layer conv3_2
I0131 01:10:57.795457 25291 net.cpp:425] conv3_2 <- conv3_1
I0131 01:10:57.795464 25291 net.cpp:399] conv3_2 -> conv3_2
I0131 01:10:57.798466 25291 net.cpp:141] Setting up conv3_2
I0131 01:10:57.798493 25291 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0131 01:10:57.798497 25291 net.cpp:156] Memory required for data: 92323868
I0131 01:10:57.798506 25291 layer_factory.hpp:77] Creating layer relu3_2
I0131 01:10:57.798514 25291 net.cpp:91] Creating Layer relu3_2
I0131 01:10:57.798519 25291 net.cpp:425] relu3_2 <- conv3_2
I0131 01:10:57.798526 25291 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0131 01:10:57.798532 25291 net.cpp:141] Setting up relu3_2
I0131 01:10:57.798537 25291 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0131 01:10:57.798540 25291 net.cpp:156] Memory required for data: 95535132
I0131 01:10:57.798544 25291 layer_factory.hpp:77] Creating layer conv3_3
I0131 01:10:57.798554 25291 net.cpp:91] Creating Layer conv3_3
I0131 01:10:57.798558 25291 net.cpp:425] conv3_3 <- conv3_2
I0131 01:10:57.798563 25291 net.cpp:399] conv3_3 -> conv3_3
I0131 01:10:57.801718 25291 net.cpp:141] Setting up conv3_3
I0131 01:10:57.801753 25291 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0131 01:10:57.801759 25291 net.cpp:156] Memory required for data: 98746396
I0131 01:10:57.801769 25291 layer_factory.hpp:77] Creating layer relu3_3
I0131 01:10:57.801779 25291 net.cpp:91] Creating Layer relu3_3
I0131 01:10:57.801785 25291 net.cpp:425] relu3_3 <- conv3_3
I0131 01:10:57.801793 25291 net.cpp:386] relu3_3 -> conv3_3 (in-place)
I0131 01:10:57.801801 25291 net.cpp:141] Setting up relu3_3
I0131 01:10:57.801807 25291 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0131 01:10:57.801811 25291 net.cpp:156] Memory required for data: 101957660
I0131 01:10:57.801816 25291 layer_factory.hpp:77] Creating layer rgb_pool3
I0131 01:10:57.801823 25291 net.cpp:91] Creating Layer rgb_pool3
I0131 01:10:57.801828 25291 net.cpp:425] rgb_pool3 <- conv3_3
I0131 01:10:57.801834 25291 net.cpp:399] rgb_pool3 -> rgb_pool3
I0131 01:10:57.801862 25291 net.cpp:141] Setting up rgb_pool3
I0131 01:10:57.801868 25291 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0131 01:10:57.801872 25291 net.cpp:156] Memory required for data: 102760476
I0131 01:10:57.801878 25291 layer_factory.hpp:77] Creating layer conv4_1
I0131 01:10:57.801887 25291 net.cpp:91] Creating Layer conv4_1
I0131 01:10:57.801892 25291 net.cpp:425] conv4_1 <- rgb_pool3
I0131 01:10:57.801898 25291 net.cpp:399] conv4_1 -> conv4_1
I0131 01:10:57.808048 25291 net.cpp:141] Setting up conv4_1
I0131 01:10:57.808104 25291 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0131 01:10:57.808115 25291 net.cpp:156] Memory required for data: 104366108
I0131 01:10:57.808133 25291 layer_factory.hpp:77] Creating layer relu4_1
I0131 01:10:57.808151 25291 net.cpp:91] Creating Layer relu4_1
I0131 01:10:57.808163 25291 net.cpp:425] relu4_1 <- conv4_1
I0131 01:10:57.808174 25291 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0131 01:10:57.808187 25291 net.cpp:141] Setting up relu4_1
I0131 01:10:57.808193 25291 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0131 01:10:57.808198 25291 net.cpp:156] Memory required for data: 105971740
I0131 01:10:57.808203 25291 layer_factory.hpp:77] Creating layer conv4_2
I0131 01:10:57.808215 25291 net.cpp:91] Creating Layer conv4_2
I0131 01:10:57.808221 25291 net.cpp:425] conv4_2 <- conv4_1
I0131 01:10:57.808229 25291 net.cpp:399] conv4_2 -> conv4_2
I0131 01:10:57.824722 25291 net.cpp:141] Setting up conv4_2
I0131 01:10:57.824793 25291 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0131 01:10:57.824811 25291 net.cpp:156] Memory required for data: 107577372
I0131 01:10:57.824841 25291 layer_factory.hpp:77] Creating layer relu4_2
I0131 01:10:57.824861 25291 net.cpp:91] Creating Layer relu4_2
I0131 01:10:57.824873 25291 net.cpp:425] relu4_2 <- conv4_2
I0131 01:10:57.824887 25291 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0131 01:10:57.824900 25291 net.cpp:141] Setting up relu4_2
I0131 01:10:57.824910 25291 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0131 01:10:57.824918 25291 net.cpp:156] Memory required for data: 109183004
I0131 01:10:57.824924 25291 layer_factory.hpp:77] Creating layer conv4_3
I0131 01:10:57.824939 25291 net.cpp:91] Creating Layer conv4_3
I0131 01:10:57.824949 25291 net.cpp:425] conv4_3 <- conv4_2
I0131 01:10:57.824960 25291 net.cpp:399] conv4_3 -> conv4_3
I0131 01:10:57.840930 25291 net.cpp:141] Setting up conv4_3
I0131 01:10:57.840988 25291 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0131 01:10:57.841004 25291 net.cpp:156] Memory required for data: 110788636
I0131 01:10:57.841023 25291 layer_factory.hpp:77] Creating layer relu4_3
I0131 01:10:57.841042 25291 net.cpp:91] Creating Layer relu4_3
I0131 01:10:57.841054 25291 net.cpp:425] relu4_3 <- conv4_3
I0131 01:10:57.841066 25291 net.cpp:386] relu4_3 -> conv4_3 (in-place)
I0131 01:10:57.841081 25291 net.cpp:141] Setting up relu4_3
I0131 01:10:57.841090 25291 net.cpp:148] Top shape: 1 512 28 28 (401408)
I0131 01:10:57.841099 25291 net.cpp:156] Memory required for data: 112394268
I0131 01:10:57.841106 25291 layer_factory.hpp:77] Creating layer rgb_pool4
I0131 01:10:57.841119 25291 net.cpp:91] Creating Layer rgb_pool4
I0131 01:10:57.841126 25291 net.cpp:425] rgb_pool4 <- conv4_3
I0131 01:10:57.841136 25291 net.cpp:399] rgb_pool4 -> rgb_pool4
I0131 01:10:57.841197 25291 net.cpp:141] Setting up rgb_pool4
I0131 01:10:57.841209 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:57.841217 25291 net.cpp:156] Memory required for data: 112795676
I0131 01:10:57.841224 25291 layer_factory.hpp:77] Creating layer conv5_1
I0131 01:10:57.841238 25291 net.cpp:91] Creating Layer conv5_1
I0131 01:10:57.841246 25291 net.cpp:425] conv5_1 <- rgb_pool4
I0131 01:10:57.841255 25291 net.cpp:399] conv5_1 -> conv5_1
I0131 01:10:57.855901 25291 net.cpp:141] Setting up conv5_1
I0131 01:10:57.855962 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:57.855975 25291 net.cpp:156] Memory required for data: 113197084
I0131 01:10:57.856000 25291 layer_factory.hpp:77] Creating layer relu5_1
I0131 01:10:57.856020 25291 net.cpp:91] Creating Layer relu5_1
I0131 01:10:57.856032 25291 net.cpp:425] relu5_1 <- conv5_1
I0131 01:10:57.856047 25291 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0131 01:10:57.856065 25291 net.cpp:141] Setting up relu5_1
I0131 01:10:57.856076 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:57.856083 25291 net.cpp:156] Memory required for data: 113598492
I0131 01:10:57.856091 25291 layer_factory.hpp:77] Creating layer conv5_2
I0131 01:10:57.856108 25291 net.cpp:91] Creating Layer conv5_2
I0131 01:10:57.856118 25291 net.cpp:425] conv5_2 <- conv5_1
I0131 01:10:57.856132 25291 net.cpp:399] conv5_2 -> conv5_2
I0131 01:10:57.869657 25291 net.cpp:141] Setting up conv5_2
I0131 01:10:57.869709 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:57.869724 25291 net.cpp:156] Memory required for data: 113999900
I0131 01:10:57.869742 25291 layer_factory.hpp:77] Creating layer relu5_2
I0131 01:10:57.869756 25291 net.cpp:91] Creating Layer relu5_2
I0131 01:10:57.869765 25291 net.cpp:425] relu5_2 <- conv5_2
I0131 01:10:57.869774 25291 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0131 01:10:57.869791 25291 net.cpp:141] Setting up relu5_2
I0131 01:10:57.869806 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:57.869813 25291 net.cpp:156] Memory required for data: 114401308
I0131 01:10:57.869820 25291 layer_factory.hpp:77] Creating layer conv5_3
I0131 01:10:57.869833 25291 net.cpp:91] Creating Layer conv5_3
I0131 01:10:57.869839 25291 net.cpp:425] conv5_3 <- conv5_2
I0131 01:10:57.869848 25291 net.cpp:399] conv5_3 -> conv5_3
I0131 01:10:57.883724 25291 net.cpp:141] Setting up conv5_3
I0131 01:10:57.883770 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:57.883780 25291 net.cpp:156] Memory required for data: 114802716
I0131 01:10:57.883795 25291 layer_factory.hpp:77] Creating layer relu5_3
I0131 01:10:57.883808 25291 net.cpp:91] Creating Layer relu5_3
I0131 01:10:57.883817 25291 net.cpp:425] relu5_3 <- conv5_3
I0131 01:10:57.883826 25291 net.cpp:386] relu5_3 -> conv5_3 (in-place)
I0131 01:10:57.883837 25291 net.cpp:141] Setting up relu5_3
I0131 01:10:57.883846 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:57.883859 25291 net.cpp:156] Memory required for data: 115204124
I0131 01:10:57.883865 25291 layer_factory.hpp:77] Creating layer rgb_pool5
I0131 01:10:57.883879 25291 net.cpp:91] Creating Layer rgb_pool5
I0131 01:10:57.883886 25291 net.cpp:425] rgb_pool5 <- conv5_3
I0131 01:10:57.883898 25291 net.cpp:399] rgb_pool5 -> rgb_pool5
I0131 01:10:57.883968 25291 net.cpp:141] Setting up rgb_pool5
I0131 01:10:57.883980 25291 net.cpp:148] Top shape: 1 512 7 7 (25088)
I0131 01:10:57.883985 25291 net.cpp:156] Memory required for data: 115304476
I0131 01:10:57.883991 25291 layer_factory.hpp:77] Creating layer rgb_fc6
I0131 01:10:57.884002 25291 net.cpp:91] Creating Layer rgb_fc6
I0131 01:10:57.884008 25291 net.cpp:425] rgb_fc6 <- rgb_pool5
I0131 01:10:57.884016 25291 net.cpp:399] rgb_fc6 -> rgb_fc6
I0131 01:10:58.447971 25291 net.cpp:141] Setting up rgb_fc6
I0131 01:10:58.448019 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:58.448035 25291 net.cpp:156] Memory required for data: 115320860
I0131 01:10:58.448051 25291 layer_factory.hpp:77] Creating layer rgb_relu6
I0131 01:10:58.448065 25291 net.cpp:91] Creating Layer rgb_relu6
I0131 01:10:58.448074 25291 net.cpp:425] rgb_relu6 <- rgb_fc6
I0131 01:10:58.448083 25291 net.cpp:386] rgb_relu6 -> rgb_fc6 (in-place)
I0131 01:10:58.448096 25291 net.cpp:141] Setting up rgb_relu6
I0131 01:10:58.448103 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:58.448109 25291 net.cpp:156] Memory required for data: 115337244
I0131 01:10:58.448114 25291 layer_factory.hpp:77] Creating layer rgb_drop6
I0131 01:10:58.448123 25291 net.cpp:91] Creating Layer rgb_drop6
I0131 01:10:58.448129 25291 net.cpp:425] rgb_drop6 <- rgb_fc6
I0131 01:10:58.448137 25291 net.cpp:386] rgb_drop6 -> rgb_fc6 (in-place)
I0131 01:10:58.448173 25291 net.cpp:141] Setting up rgb_drop6
I0131 01:10:58.448181 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:58.448185 25291 net.cpp:156] Memory required for data: 115353628
I0131 01:10:58.448191 25291 layer_factory.hpp:77] Creating layer rgb_fc7
I0131 01:10:58.448200 25291 net.cpp:91] Creating Layer rgb_fc7
I0131 01:10:58.448206 25291 net.cpp:425] rgb_fc7 <- rgb_fc6
I0131 01:10:58.448213 25291 net.cpp:399] rgb_fc7 -> rgb_fc7
I0131 01:10:58.544797 25291 net.cpp:141] Setting up rgb_fc7
I0131 01:10:58.544839 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:58.544847 25291 net.cpp:156] Memory required for data: 115370012
I0131 01:10:58.544864 25291 layer_factory.hpp:77] Creating layer rgb_relu7
I0131 01:10:58.544878 25291 net.cpp:91] Creating Layer rgb_relu7
I0131 01:10:58.544889 25291 net.cpp:425] rgb_relu7 <- rgb_fc7
I0131 01:10:58.544898 25291 net.cpp:386] rgb_relu7 -> rgb_fc7 (in-place)
I0131 01:10:58.544909 25291 net.cpp:141] Setting up rgb_relu7
I0131 01:10:58.544915 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:58.544919 25291 net.cpp:156] Memory required for data: 115386396
I0131 01:10:58.544924 25291 layer_factory.hpp:77] Creating layer rgb_drop7
I0131 01:10:58.544932 25291 net.cpp:91] Creating Layer rgb_drop7
I0131 01:10:58.544941 25291 net.cpp:425] rgb_drop7 <- rgb_fc7
I0131 01:10:58.544950 25291 net.cpp:386] rgb_drop7 -> rgb_fc7 (in-place)
I0131 01:10:58.544989 25291 net.cpp:141] Setting up rgb_drop7
I0131 01:10:58.544998 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:58.545004 25291 net.cpp:156] Memory required for data: 115402780
I0131 01:10:58.545009 25291 layer_factory.hpp:77] Creating layer rgb_fc7_rgb_drop7_0_split
I0131 01:10:58.545017 25291 net.cpp:91] Creating Layer rgb_fc7_rgb_drop7_0_split
I0131 01:10:58.545023 25291 net.cpp:425] rgb_fc7_rgb_drop7_0_split <- rgb_fc7
I0131 01:10:58.545029 25291 net.cpp:399] rgb_fc7_rgb_drop7_0_split -> rgb_fc7_rgb_drop7_0_split_0
I0131 01:10:58.545037 25291 net.cpp:399] rgb_fc7_rgb_drop7_0_split -> rgb_fc7_rgb_drop7_0_split_1
I0131 01:10:58.545073 25291 net.cpp:141] Setting up rgb_fc7_rgb_drop7_0_split
I0131 01:10:58.545080 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:58.545086 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:58.545091 25291 net.cpp:156] Memory required for data: 115435548
I0131 01:10:58.545096 25291 layer_factory.hpp:77] Creating layer rgb_fc8
I0131 01:10:58.545105 25291 net.cpp:91] Creating Layer rgb_fc8
I0131 01:10:58.545111 25291 net.cpp:425] rgb_fc8 <- rgb_fc7_rgb_drop7_0_split_0
I0131 01:10:58.545119 25291 net.cpp:399] rgb_fc8 -> rgb_fc8
I0131 01:10:58.546550 25291 net.cpp:141] Setting up rgb_fc8
I0131 01:10:58.546566 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:58.546571 25291 net.cpp:156] Memory required for data: 115435752
I0131 01:10:58.546579 25291 layer_factory.hpp:77] Creating layer rgb_fc8_rgb_fc8_0_split
I0131 01:10:58.546586 25291 net.cpp:91] Creating Layer rgb_fc8_rgb_fc8_0_split
I0131 01:10:58.546593 25291 net.cpp:425] rgb_fc8_rgb_fc8_0_split <- rgb_fc8
I0131 01:10:58.546600 25291 net.cpp:399] rgb_fc8_rgb_fc8_0_split -> rgb_fc8_rgb_fc8_0_split_0
I0131 01:10:58.546612 25291 net.cpp:399] rgb_fc8_rgb_fc8_0_split -> rgb_fc8_rgb_fc8_0_split_1
I0131 01:10:58.546641 25291 net.cpp:141] Setting up rgb_fc8_rgb_fc8_0_split
I0131 01:10:58.546649 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:58.546655 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:58.546659 25291 net.cpp:156] Memory required for data: 115436160
I0131 01:10:58.546665 25291 layer_factory.hpp:77] Creating layer conv1
I0131 01:10:58.546675 25291 net.cpp:91] Creating Layer conv1
I0131 01:10:58.546681 25291 net.cpp:425] conv1 <- depth
I0131 01:10:58.546689 25291 net.cpp:399] conv1 -> conv1
I0131 01:10:58.546885 25291 net.cpp:141] Setting up conv1
I0131 01:10:58.546893 25291 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0131 01:10:58.546900 25291 net.cpp:156] Memory required for data: 121858688
I0131 01:10:58.546910 25291 layer_factory.hpp:77] Creating layer relu1
I0131 01:10:58.546917 25291 net.cpp:91] Creating Layer relu1
I0131 01:10:58.546923 25291 net.cpp:425] relu1 <- conv1
I0131 01:10:58.546929 25291 net.cpp:386] relu1 -> conv1 (in-place)
I0131 01:10:58.546936 25291 net.cpp:141] Setting up relu1
I0131 01:10:58.546942 25291 net.cpp:148] Top shape: 1 128 112 112 (1605632)
I0131 01:10:58.546947 25291 net.cpp:156] Memory required for data: 128281216
I0131 01:10:58.546952 25291 layer_factory.hpp:77] Creating layer depth_pool1
I0131 01:10:58.546959 25291 net.cpp:91] Creating Layer depth_pool1
I0131 01:10:58.546964 25291 net.cpp:425] depth_pool1 <- conv1
I0131 01:10:58.546972 25291 net.cpp:399] depth_pool1 -> depth_pool1
I0131 01:10:58.547003 25291 net.cpp:141] Setting up depth_pool1
I0131 01:10:58.547009 25291 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0131 01:10:58.547014 25291 net.cpp:156] Memory required for data: 129886848
I0131 01:10:58.547019 25291 layer_factory.hpp:77] Creating layer norm1
I0131 01:10:58.547026 25291 net.cpp:91] Creating Layer norm1
I0131 01:10:58.547030 25291 net.cpp:425] norm1 <- depth_pool1
I0131 01:10:58.547037 25291 net.cpp:399] norm1 -> norm1
I0131 01:10:58.547063 25291 net.cpp:141] Setting up norm1
I0131 01:10:58.547070 25291 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0131 01:10:58.547075 25291 net.cpp:156] Memory required for data: 131492480
I0131 01:10:58.547080 25291 layer_factory.hpp:77] Creating layer conv2
I0131 01:10:58.547089 25291 net.cpp:91] Creating Layer conv2
I0131 01:10:58.547094 25291 net.cpp:425] conv2 <- norm1
I0131 01:10:58.547101 25291 net.cpp:399] conv2 -> conv2
I0131 01:10:58.551864 25291 net.cpp:141] Setting up conv2
I0131 01:10:58.551900 25291 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0131 01:10:58.551908 25291 net.cpp:156] Memory required for data: 134703744
I0131 01:10:58.551923 25291 layer_factory.hpp:77] Creating layer relu2
I0131 01:10:58.551934 25291 net.cpp:91] Creating Layer relu2
I0131 01:10:58.551946 25291 net.cpp:425] relu2 <- conv2
I0131 01:10:58.551954 25291 net.cpp:386] relu2 -> conv2 (in-place)
I0131 01:10:58.551964 25291 net.cpp:141] Setting up relu2
I0131 01:10:58.551971 25291 net.cpp:148] Top shape: 1 256 56 56 (802816)
I0131 01:10:58.551976 25291 net.cpp:156] Memory required for data: 137915008
I0131 01:10:58.551982 25291 layer_factory.hpp:77] Creating layer depth_pool2
I0131 01:10:58.551990 25291 net.cpp:91] Creating Layer depth_pool2
I0131 01:10:58.551996 25291 net.cpp:425] depth_pool2 <- conv2
I0131 01:10:58.552003 25291 net.cpp:399] depth_pool2 -> depth_pool2
I0131 01:10:58.552045 25291 net.cpp:141] Setting up depth_pool2
I0131 01:10:58.552053 25291 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0131 01:10:58.552058 25291 net.cpp:156] Memory required for data: 138717824
I0131 01:10:58.552063 25291 layer_factory.hpp:77] Creating layer norm2
I0131 01:10:58.552072 25291 net.cpp:91] Creating Layer norm2
I0131 01:10:58.552078 25291 net.cpp:425] norm2 <- depth_pool2
I0131 01:10:58.552083 25291 net.cpp:399] norm2 -> norm2
I0131 01:10:58.552114 25291 net.cpp:141] Setting up norm2
I0131 01:10:58.552120 25291 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0131 01:10:58.552125 25291 net.cpp:156] Memory required for data: 139520640
I0131 01:10:58.552129 25291 layer_factory.hpp:77] Creating layer conv3
I0131 01:10:58.552139 25291 net.cpp:91] Creating Layer conv3
I0131 01:10:58.552145 25291 net.cpp:425] conv3 <- norm2
I0131 01:10:58.552152 25291 net.cpp:399] conv3 -> conv3
I0131 01:10:58.554874 25291 net.cpp:141] Setting up conv3
I0131 01:10:58.554903 25291 net.cpp:148] Top shape: 1 384 28 28 (301056)
I0131 01:10:58.554910 25291 net.cpp:156] Memory required for data: 140724864
I0131 01:10:58.554920 25291 layer_factory.hpp:77] Creating layer relu3
I0131 01:10:58.554931 25291 net.cpp:91] Creating Layer relu3
I0131 01:10:58.554939 25291 net.cpp:425] relu3 <- conv3
I0131 01:10:58.554945 25291 net.cpp:386] relu3 -> conv3 (in-place)
I0131 01:10:58.554955 25291 net.cpp:141] Setting up relu3
I0131 01:10:58.554960 25291 net.cpp:148] Top shape: 1 384 28 28 (301056)
I0131 01:10:58.554965 25291 net.cpp:156] Memory required for data: 141929088
I0131 01:10:58.554971 25291 layer_factory.hpp:77] Creating layer depth_pool3
I0131 01:10:58.554978 25291 net.cpp:91] Creating Layer depth_pool3
I0131 01:10:58.554983 25291 net.cpp:425] depth_pool3 <- conv3
I0131 01:10:58.554991 25291 net.cpp:399] depth_pool3 -> depth_pool3
I0131 01:10:58.555034 25291 net.cpp:141] Setting up depth_pool3
I0131 01:10:58.555050 25291 net.cpp:148] Top shape: 1 384 14 14 (75264)
I0131 01:10:58.555059 25291 net.cpp:156] Memory required for data: 142230144
I0131 01:10:58.555068 25291 layer_factory.hpp:77] Creating layer conv4
I0131 01:10:58.555079 25291 net.cpp:91] Creating Layer conv4
I0131 01:10:58.555085 25291 net.cpp:425] conv4 <- depth_pool3
I0131 01:10:58.555093 25291 net.cpp:399] conv4 -> conv4
I0131 01:10:58.565321 25291 net.cpp:141] Setting up conv4
I0131 01:10:58.565372 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:58.565384 25291 net.cpp:156] Memory required for data: 142631552
I0131 01:10:58.565402 25291 layer_factory.hpp:77] Creating layer relu4
I0131 01:10:58.565418 25291 net.cpp:91] Creating Layer relu4
I0131 01:10:58.565428 25291 net.cpp:425] relu4 <- conv4
I0131 01:10:58.565443 25291 net.cpp:386] relu4 -> conv4 (in-place)
I0131 01:10:58.565455 25291 net.cpp:141] Setting up relu4
I0131 01:10:58.565465 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:58.565474 25291 net.cpp:156] Memory required for data: 143032960
I0131 01:10:58.565480 25291 layer_factory.hpp:77] Creating layer conv5
I0131 01:10:58.565496 25291 net.cpp:91] Creating Layer conv5
I0131 01:10:58.565506 25291 net.cpp:425] conv5 <- conv4
I0131 01:10:58.565518 25291 net.cpp:399] conv5 -> conv5
I0131 01:10:58.579041 25291 net.cpp:141] Setting up conv5
I0131 01:10:58.579080 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:58.579092 25291 net.cpp:156] Memory required for data: 143434368
I0131 01:10:58.579104 25291 layer_factory.hpp:77] Creating layer relu5
I0131 01:10:58.579118 25291 net.cpp:91] Creating Layer relu5
I0131 01:10:58.579126 25291 net.cpp:425] relu5 <- conv5
I0131 01:10:58.579135 25291 net.cpp:386] relu5 -> conv5 (in-place)
I0131 01:10:58.579146 25291 net.cpp:141] Setting up relu5
I0131 01:10:58.579154 25291 net.cpp:148] Top shape: 1 512 14 14 (100352)
I0131 01:10:58.579160 25291 net.cpp:156] Memory required for data: 143835776
I0131 01:10:58.579166 25291 layer_factory.hpp:77] Creating layer depth_pool5
I0131 01:10:58.579174 25291 net.cpp:91] Creating Layer depth_pool5
I0131 01:10:58.579180 25291 net.cpp:425] depth_pool5 <- conv5
I0131 01:10:58.579187 25291 net.cpp:399] depth_pool5 -> depth_pool5
I0131 01:10:58.579236 25291 net.cpp:141] Setting up depth_pool5
I0131 01:10:58.579244 25291 net.cpp:148] Top shape: 1 512 7 7 (25088)
I0131 01:10:58.579249 25291 net.cpp:156] Memory required for data: 143936128
I0131 01:10:58.579254 25291 layer_factory.hpp:77] Creating layer depth_fc6
I0131 01:10:58.579262 25291 net.cpp:91] Creating Layer depth_fc6
I0131 01:10:58.579268 25291 net.cpp:425] depth_fc6 <- depth_pool5
I0131 01:10:58.579275 25291 net.cpp:399] depth_fc6 -> depth_fc6
I0131 01:10:59.175056 25291 net.cpp:141] Setting up depth_fc6
I0131 01:10:59.175097 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:59.175107 25291 net.cpp:156] Memory required for data: 143952512
I0131 01:10:59.175120 25291 layer_factory.hpp:77] Creating layer depth_relu6
I0131 01:10:59.175134 25291 net.cpp:91] Creating Layer depth_relu6
I0131 01:10:59.175143 25291 net.cpp:425] depth_relu6 <- depth_fc6
I0131 01:10:59.175154 25291 net.cpp:386] depth_relu6 -> depth_fc6 (in-place)
I0131 01:10:59.175166 25291 net.cpp:141] Setting up depth_relu6
I0131 01:10:59.175174 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:59.175181 25291 net.cpp:156] Memory required for data: 143968896
I0131 01:10:59.175187 25291 layer_factory.hpp:77] Creating layer depth_drop6
I0131 01:10:59.175197 25291 net.cpp:91] Creating Layer depth_drop6
I0131 01:10:59.175204 25291 net.cpp:425] depth_drop6 <- depth_fc6
I0131 01:10:59.175215 25291 net.cpp:386] depth_drop6 -> depth_fc6 (in-place)
I0131 01:10:59.175240 25291 net.cpp:141] Setting up depth_drop6
I0131 01:10:59.175249 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:59.175256 25291 net.cpp:156] Memory required for data: 143985280
I0131 01:10:59.175261 25291 layer_factory.hpp:77] Creating layer depth_fc7
I0131 01:10:59.175271 25291 net.cpp:91] Creating Layer depth_fc7
I0131 01:10:59.175277 25291 net.cpp:425] depth_fc7 <- depth_fc6
I0131 01:10:59.175285 25291 net.cpp:399] depth_fc7 -> depth_fc7
I0131 01:10:59.270967 25291 net.cpp:141] Setting up depth_fc7
I0131 01:10:59.271030 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:59.271050 25291 net.cpp:156] Memory required for data: 144001664
I0131 01:10:59.271069 25291 layer_factory.hpp:77] Creating layer depth_relu7
I0131 01:10:59.271085 25291 net.cpp:91] Creating Layer depth_relu7
I0131 01:10:59.271096 25291 net.cpp:425] depth_relu7 <- depth_fc7
I0131 01:10:59.271109 25291 net.cpp:386] depth_relu7 -> depth_fc7 (in-place)
I0131 01:10:59.271123 25291 net.cpp:141] Setting up depth_relu7
I0131 01:10:59.271131 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:59.271136 25291 net.cpp:156] Memory required for data: 144018048
I0131 01:10:59.271139 25291 layer_factory.hpp:77] Creating layer depth_drop7
I0131 01:10:59.271152 25291 net.cpp:91] Creating Layer depth_drop7
I0131 01:10:59.271157 25291 net.cpp:425] depth_drop7 <- depth_fc7
I0131 01:10:59.271163 25291 net.cpp:386] depth_drop7 -> depth_fc7 (in-place)
I0131 01:10:59.271203 25291 net.cpp:141] Setting up depth_drop7
I0131 01:10:59.271211 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:59.271215 25291 net.cpp:156] Memory required for data: 144034432
I0131 01:10:59.271221 25291 layer_factory.hpp:77] Creating layer depth_fc7_depth_drop7_0_split
I0131 01:10:59.271237 25291 net.cpp:91] Creating Layer depth_fc7_depth_drop7_0_split
I0131 01:10:59.271244 25291 net.cpp:425] depth_fc7_depth_drop7_0_split <- depth_fc7
I0131 01:10:59.271250 25291 net.cpp:399] depth_fc7_depth_drop7_0_split -> depth_fc7_depth_drop7_0_split_0
I0131 01:10:59.271258 25291 net.cpp:399] depth_fc7_depth_drop7_0_split -> depth_fc7_depth_drop7_0_split_1
I0131 01:10:59.271316 25291 net.cpp:141] Setting up depth_fc7_depth_drop7_0_split
I0131 01:10:59.271323 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:59.271328 25291 net.cpp:148] Top shape: 1 4096 (4096)
I0131 01:10:59.271333 25291 net.cpp:156] Memory required for data: 144067200
I0131 01:10:59.271338 25291 layer_factory.hpp:77] Creating layer depth_fc8
I0131 01:10:59.271348 25291 net.cpp:91] Creating Layer depth_fc8
I0131 01:10:59.271354 25291 net.cpp:425] depth_fc8 <- depth_fc7_depth_drop7_0_split_0
I0131 01:10:59.271361 25291 net.cpp:399] depth_fc8 -> depth_fc8
I0131 01:10:59.273011 25291 net.cpp:141] Setting up depth_fc8
I0131 01:10:59.273039 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:59.273048 25291 net.cpp:156] Memory required for data: 144067404
I0131 01:10:59.273058 25291 layer_factory.hpp:77] Creating layer depth_fc8_depth_fc8_0_split
I0131 01:10:59.273067 25291 net.cpp:91] Creating Layer depth_fc8_depth_fc8_0_split
I0131 01:10:59.273074 25291 net.cpp:425] depth_fc8_depth_fc8_0_split <- depth_fc8
I0131 01:10:59.273082 25291 net.cpp:399] depth_fc8_depth_fc8_0_split -> depth_fc8_depth_fc8_0_split_0
I0131 01:10:59.273092 25291 net.cpp:399] depth_fc8_depth_fc8_0_split -> depth_fc8_depth_fc8_0_split_1
I0131 01:10:59.273128 25291 net.cpp:141] Setting up depth_fc8_depth_fc8_0_split
I0131 01:10:59.273138 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:59.273142 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:59.273146 25291 net.cpp:156] Memory required for data: 144067812
I0131 01:10:59.273151 25291 layer_factory.hpp:77] Creating layer concat
I0131 01:10:59.273160 25291 net.cpp:91] Creating Layer concat
I0131 01:10:59.273167 25291 net.cpp:425] concat <- rgb_fc7_rgb_drop7_0_split_1
I0131 01:10:59.273174 25291 net.cpp:425] concat <- depth_fc7_depth_drop7_0_split_1
I0131 01:10:59.273180 25291 net.cpp:399] concat -> concat
I0131 01:10:59.273203 25291 net.cpp:141] Setting up concat
I0131 01:10:59.273211 25291 net.cpp:148] Top shape: 1 8192 (8192)
I0131 01:10:59.273216 25291 net.cpp:156] Memory required for data: 144100580
I0131 01:10:59.273219 25291 layer_factory.hpp:77] Creating layer rgbd_fc8
I0131 01:10:59.273228 25291 net.cpp:91] Creating Layer rgbd_fc8
I0131 01:10:59.273232 25291 net.cpp:425] rgbd_fc8 <- concat
I0131 01:10:59.273238 25291 net.cpp:399] rgbd_fc8 -> rgbd_fc8
I0131 01:10:59.275634 25291 net.cpp:141] Setting up rgbd_fc8
I0131 01:10:59.275655 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:59.275660 25291 net.cpp:156] Memory required for data: 144100784
I0131 01:10:59.275671 25291 layer_factory.hpp:77] Creating layer rgbd_fc8_rgbd_fc8_0_split
I0131 01:10:59.275679 25291 net.cpp:91] Creating Layer rgbd_fc8_rgbd_fc8_0_split
I0131 01:10:59.275684 25291 net.cpp:425] rgbd_fc8_rgbd_fc8_0_split <- rgbd_fc8
I0131 01:10:59.275691 25291 net.cpp:399] rgbd_fc8_rgbd_fc8_0_split -> rgbd_fc8_rgbd_fc8_0_split_0
I0131 01:10:59.275697 25291 net.cpp:399] rgbd_fc8_rgbd_fc8_0_split -> rgbd_fc8_rgbd_fc8_0_split_1
I0131 01:10:59.275730 25291 net.cpp:141] Setting up rgbd_fc8_rgbd_fc8_0_split
I0131 01:10:59.275738 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:59.275744 25291 net.cpp:148] Top shape: 1 51 (51)
I0131 01:10:59.275748 25291 net.cpp:156] Memory required for data: 144101192
I0131 01:10:59.275751 25291 layer_factory.hpp:77] Creating layer rgb_accuracy
I0131 01:10:59.275758 25291 net.cpp:91] Creating Layer rgb_accuracy
I0131 01:10:59.275763 25291 net.cpp:425] rgb_accuracy <- rgb_fc8_rgb_fc8_0_split_0
I0131 01:10:59.275769 25291 net.cpp:425] rgb_accuracy <- label_data_2_split_0
I0131 01:10:59.275775 25291 net.cpp:399] rgb_accuracy -> rgb_accuracy
I0131 01:10:59.275784 25291 net.cpp:141] Setting up rgb_accuracy
I0131 01:10:59.275789 25291 net.cpp:148] Top shape: (1)
I0131 01:10:59.275792 25291 net.cpp:156] Memory required for data: 144101196
I0131 01:10:59.275799 25291 layer_factory.hpp:77] Creating layer rgb_loss
I0131 01:10:59.275804 25291 net.cpp:91] Creating Layer rgb_loss
I0131 01:10:59.275810 25291 net.cpp:425] rgb_loss <- rgb_fc8_rgb_fc8_0_split_1
I0131 01:10:59.275813 25291 net.cpp:425] rgb_loss <- label_data_2_split_1
I0131 01:10:59.275820 25291 net.cpp:399] rgb_loss -> rgb_loss
I0131 01:10:59.275827 25291 layer_factory.hpp:77] Creating layer rgb_loss
I0131 01:10:59.275899 25291 net.cpp:141] Setting up rgb_loss
I0131 01:10:59.275907 25291 net.cpp:148] Top shape: (1)
I0131 01:10:59.275910 25291 net.cpp:151]     with loss weight 1
I0131 01:10:59.275921 25291 net.cpp:156] Memory required for data: 144101200
I0131 01:10:59.275925 25291 layer_factory.hpp:77] Creating layer depth_accuracy
I0131 01:10:59.275933 25291 net.cpp:91] Creating Layer depth_accuracy
I0131 01:10:59.275938 25291 net.cpp:425] depth_accuracy <- depth_fc8_depth_fc8_0_split_0
I0131 01:10:59.275943 25291 net.cpp:425] depth_accuracy <- label_data_2_split_2
I0131 01:10:59.275949 25291 net.cpp:399] depth_accuracy -> depth_accuracy
I0131 01:10:59.275955 25291 net.cpp:141] Setting up depth_accuracy
I0131 01:10:59.275961 25291 net.cpp:148] Top shape: (1)
I0131 01:10:59.275965 25291 net.cpp:156] Memory required for data: 144101204
I0131 01:10:59.275969 25291 layer_factory.hpp:77] Creating layer depth_loss
I0131 01:10:59.275975 25291 net.cpp:91] Creating Layer depth_loss
I0131 01:10:59.275979 25291 net.cpp:425] depth_loss <- depth_fc8_depth_fc8_0_split_1
I0131 01:10:59.275985 25291 net.cpp:425] depth_loss <- label_data_2_split_3
I0131 01:10:59.275990 25291 net.cpp:399] depth_loss -> depth_loss
I0131 01:10:59.275996 25291 layer_factory.hpp:77] Creating layer depth_loss
I0131 01:10:59.276057 25291 net.cpp:141] Setting up depth_loss
I0131 01:10:59.276063 25291 net.cpp:148] Top shape: (1)
I0131 01:10:59.276067 25291 net.cpp:151]     with loss weight 1
I0131 01:10:59.276073 25291 net.cpp:156] Memory required for data: 144101208
I0131 01:10:59.276077 25291 layer_factory.hpp:77] Creating layer rgbd_accuracy
I0131 01:10:59.276082 25291 net.cpp:91] Creating Layer rgbd_accuracy
I0131 01:10:59.276088 25291 net.cpp:425] rgbd_accuracy <- rgbd_fc8_rgbd_fc8_0_split_0
I0131 01:10:59.276093 25291 net.cpp:425] rgbd_accuracy <- label_data_2_split_4
I0131 01:10:59.276098 25291 net.cpp:399] rgbd_accuracy -> rgbd_accuracy
I0131 01:10:59.276105 25291 net.cpp:141] Setting up rgbd_accuracy
I0131 01:10:59.276109 25291 net.cpp:148] Top shape: (1)
I0131 01:10:59.276113 25291 net.cpp:156] Memory required for data: 144101212
I0131 01:10:59.276118 25291 layer_factory.hpp:77] Creating layer rgbd_loss
I0131 01:10:59.276124 25291 net.cpp:91] Creating Layer rgbd_loss
I0131 01:10:59.276127 25291 net.cpp:425] rgbd_loss <- rgbd_fc8_rgbd_fc8_0_split_1
I0131 01:10:59.276131 25291 net.cpp:425] rgbd_loss <- label_data_2_split_5
I0131 01:10:59.276137 25291 net.cpp:399] rgbd_loss -> rgbd_loss
I0131 01:10:59.276144 25291 layer_factory.hpp:77] Creating layer rgbd_loss
I0131 01:10:59.276201 25291 net.cpp:141] Setting up rgbd_loss
I0131 01:10:59.276208 25291 net.cpp:148] Top shape: (1)
I0131 01:10:59.276212 25291 net.cpp:151]     with loss weight 1
I0131 01:10:59.276217 25291 net.cpp:156] Memory required for data: 144101216
I0131 01:10:59.276221 25291 net.cpp:217] rgbd_loss needs backward computation.
I0131 01:10:59.276226 25291 net.cpp:219] rgbd_accuracy does not need backward computation.
I0131 01:10:59.276231 25291 net.cpp:217] depth_loss needs backward computation.
I0131 01:10:59.276234 25291 net.cpp:219] depth_accuracy does not need backward computation.
I0131 01:10:59.276239 25291 net.cpp:217] rgb_loss needs backward computation.
I0131 01:10:59.276244 25291 net.cpp:219] rgb_accuracy does not need backward computation.
I0131 01:10:59.276249 25291 net.cpp:217] rgbd_fc8_rgbd_fc8_0_split needs backward computation.
I0131 01:10:59.276253 25291 net.cpp:217] rgbd_fc8 needs backward computation.
I0131 01:10:59.276258 25291 net.cpp:217] concat needs backward computation.
I0131 01:10:59.276262 25291 net.cpp:217] depth_fc8_depth_fc8_0_split needs backward computation.
I0131 01:10:59.276268 25291 net.cpp:217] depth_fc8 needs backward computation.
I0131 01:10:59.276271 25291 net.cpp:217] depth_fc7_depth_drop7_0_split needs backward computation.
I0131 01:10:59.276276 25291 net.cpp:217] depth_drop7 needs backward computation.
I0131 01:10:59.276280 25291 net.cpp:217] depth_relu7 needs backward computation.
I0131 01:10:59.276285 25291 net.cpp:217] depth_fc7 needs backward computation.
I0131 01:10:59.276289 25291 net.cpp:217] depth_drop6 needs backward computation.
I0131 01:10:59.276293 25291 net.cpp:217] depth_relu6 needs backward computation.
I0131 01:10:59.276298 25291 net.cpp:217] depth_fc6 needs backward computation.
I0131 01:10:59.276302 25291 net.cpp:219] depth_pool5 does not need backward computation.
I0131 01:10:59.276307 25291 net.cpp:219] relu5 does not need backward computation.
I0131 01:10:59.276311 25291 net.cpp:219] conv5 does not need backward computation.
I0131 01:10:59.276317 25291 net.cpp:219] relu4 does not need backward computation.
I0131 01:10:59.276321 25291 net.cpp:219] conv4 does not need backward computation.
I0131 01:10:59.276326 25291 net.cpp:219] depth_pool3 does not need backward computation.
I0131 01:10:59.276331 25291 net.cpp:219] relu3 does not need backward computation.
I0131 01:10:59.276336 25291 net.cpp:219] conv3 does not need backward computation.
I0131 01:10:59.276340 25291 net.cpp:219] norm2 does not need backward computation.
I0131 01:10:59.276345 25291 net.cpp:219] depth_pool2 does not need backward computation.
I0131 01:10:59.276350 25291 net.cpp:219] relu2 does not need backward computation.
I0131 01:10:59.276355 25291 net.cpp:219] conv2 does not need backward computation.
I0131 01:10:59.276358 25291 net.cpp:219] norm1 does not need backward computation.
I0131 01:10:59.276363 25291 net.cpp:219] depth_pool1 does not need backward computation.
I0131 01:10:59.276367 25291 net.cpp:219] relu1 does not need backward computation.
I0131 01:10:59.276372 25291 net.cpp:219] conv1 does not need backward computation.
I0131 01:10:59.276377 25291 net.cpp:217] rgb_fc8_rgb_fc8_0_split needs backward computation.
I0131 01:10:59.276382 25291 net.cpp:217] rgb_fc8 needs backward computation.
I0131 01:10:59.276386 25291 net.cpp:217] rgb_fc7_rgb_drop7_0_split needs backward computation.
I0131 01:10:59.276392 25291 net.cpp:217] rgb_drop7 needs backward computation.
I0131 01:10:59.276396 25291 net.cpp:217] rgb_relu7 needs backward computation.
I0131 01:10:59.276401 25291 net.cpp:217] rgb_fc7 needs backward computation.
I0131 01:10:59.276404 25291 net.cpp:217] rgb_drop6 needs backward computation.
I0131 01:10:59.276409 25291 net.cpp:217] rgb_relu6 needs backward computation.
I0131 01:10:59.276412 25291 net.cpp:217] rgb_fc6 needs backward computation.
I0131 01:10:59.276417 25291 net.cpp:219] rgb_pool5 does not need backward computation.
I0131 01:10:59.276422 25291 net.cpp:219] relu5_3 does not need backward computation.
I0131 01:10:59.276427 25291 net.cpp:219] conv5_3 does not need backward computation.
I0131 01:10:59.276432 25291 net.cpp:219] relu5_2 does not need backward computation.
I0131 01:10:59.276437 25291 net.cpp:219] conv5_2 does not need backward computation.
I0131 01:10:59.276440 25291 net.cpp:219] relu5_1 does not need backward computation.
I0131 01:10:59.276444 25291 net.cpp:219] conv5_1 does not need backward computation.
I0131 01:10:59.276450 25291 net.cpp:219] rgb_pool4 does not need backward computation.
I0131 01:10:59.276454 25291 net.cpp:219] relu4_3 does not need backward computation.
I0131 01:10:59.276459 25291 net.cpp:219] conv4_3 does not need backward computation.
I0131 01:10:59.276463 25291 net.cpp:219] relu4_2 does not need backward computation.
I0131 01:10:59.276468 25291 net.cpp:219] conv4_2 does not need backward computation.
I0131 01:10:59.276473 25291 net.cpp:219] relu4_1 does not need backward computation.
I0131 01:10:59.276476 25291 net.cpp:219] conv4_1 does not need backward computation.
I0131 01:10:59.276481 25291 net.cpp:219] rgb_pool3 does not need backward computation.
I0131 01:10:59.276486 25291 net.cpp:219] relu3_3 does not need backward computation.
I0131 01:10:59.276490 25291 net.cpp:219] conv3_3 does not need backward computation.
I0131 01:10:59.276496 25291 net.cpp:219] relu3_2 does not need backward computation.
I0131 01:10:59.276500 25291 net.cpp:219] conv3_2 does not need backward computation.
I0131 01:10:59.276505 25291 net.cpp:219] relu3_1 does not need backward computation.
I0131 01:10:59.276510 25291 net.cpp:219] conv3_1 does not need backward computation.
I0131 01:10:59.276515 25291 net.cpp:219] rgb_pool2 does not need backward computation.
I0131 01:10:59.276518 25291 net.cpp:219] relu2_2 does not need backward computation.
I0131 01:10:59.276523 25291 net.cpp:219] conv2_2 does not need backward computation.
I0131 01:10:59.276527 25291 net.cpp:219] relu2_1 does not need backward computation.
I0131 01:10:59.276532 25291 net.cpp:219] conv2_1 does not need backward computation.
I0131 01:10:59.276536 25291 net.cpp:219] rgb_pool1 does not need backward computation.
I0131 01:10:59.276541 25291 net.cpp:219] relu1_2 does not need backward computation.
I0131 01:10:59.276546 25291 net.cpp:219] conv1_2 does not need backward computation.
I0131 01:10:59.276551 25291 net.cpp:219] relu1_1 does not need backward computation.
I0131 01:10:59.276554 25291 net.cpp:219] conv1_1 does not need backward computation.
I0131 01:10:59.276561 25291 net.cpp:219] label_data_2_split does not need backward computation.
I0131 01:10:59.276566 25291 net.cpp:219] data does not need backward computation.
I0131 01:10:59.276571 25291 net.cpp:261] This network produces output depth_accuracy
I0131 01:10:59.276574 25291 net.cpp:261] This network produces output depth_loss
I0131 01:10:59.276579 25291 net.cpp:261] This network produces output rgb_accuracy
I0131 01:10:59.276583 25291 net.cpp:261] This network produces output rgb_loss
I0131 01:10:59.276587 25291 net.cpp:261] This network produces output rgbd_accuracy
I0131 01:10:59.276592 25291 net.cpp:261] This network produces output rgbd_loss
I0131 01:10:59.276628 25291 net.cpp:274] Network initialization done.
I0131 01:10:59.276849 25291 solver.cpp:60] Solver scaffolding done.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 1038484580
I0131 01:11:03.614254 25291 solver.cpp:337] Iteration 0, Testing net (#0)
I0131 01:11:04.393798 25291 solver.cpp:228] Iteration 0, loss = 5.41327
I0131 01:11:04.393837 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:11:04.393849 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0174601 (* 1 = 0.0174601 loss)
I0131 01:11:04.393857 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:11:04.393863 25291 solver.cpp:244]     Train net output #3: rgb_loss = 7.67082e-06 (* 1 = 7.67082e-06 loss)
I0131 01:11:04.393872 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 0
I0131 01:11:04.393877 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 5.3958 (* 1 = 5.3958 loss)
I0131 01:11:04.393885 25291 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0131 01:11:59.776968 25291 solver.cpp:228] Iteration 100, loss = 0.424819
I0131 01:11:59.777029 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:11:59.777045 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00459697 (* 1 = 0.00459697 loss)
I0131 01:11:59.777056 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:11:59.777066 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000148399 (* 1 = 0.000148399 loss)
I0131 01:11:59.777074 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:11:59.777084 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.0096367 (* 1 = 0.0096367 loss)
I0131 01:11:59.777096 25291 sgd_solver.cpp:106] Iteration 100, lr = 0.001
>>> 2017-01-31 01:12:56.775730 Begin model classification tests
>>> 2017-01-31 01:15:41.306287 Iteration 200 mean classification accuracy (rgb)  0.897020910914
>>> 2017-01-31 01:15:41.306325 Iteration 200 mean classification accuracy (depth) 0.755227728445
>>> 2017-01-31 01:15:41.306337 Iteration 200 mean classification accuracy (rgbd)  0.905041535377
>>> 2017-01-31 01:15:41.306346 Iteration 200 mean testing loss (rgb) 0.429983439794
>>> 2017-01-31 01:15:41.306359 Iteration 200 mean testing loss (depth) 1.58937932071
>>> 2017-01-31 01:15:41.306366 Iteration 200 mean testing loss (rgbd) 0.309913545905
>>> 2017-01-31 01:15:41.306374 Iteration 200 mean confusion matrix
[ 1.          0.10365854  1.          1.          1.          0.9378882   1.
  0.65217391  0.9047619   0.9537037   1.          1.          0.57657658
  1.          1.          1.          1.          1.          1.
  0.44099379  1.          1.          1.          1.          1.          0.8943662
  1.          1.          1.          1.          0.98136646  0.18421053
  0.50617284  1.          0.73049645  0.80714286  0.98639456  0.86486486
  1.          0.97321429  1.          0.97419355  1.          1.          1.
  1.          1.          1.          1.          0.99367089  1.        ]
I0131 01:15:41.869366 25291 solver.cpp:228] Iteration 200, loss = 0.0328681
I0131 01:15:41.869407 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:15:41.869423 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00414872 (* 1 = 0.00414872 loss)
I0131 01:15:41.869431 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:15:41.869437 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000354262 (* 1 = 0.000354262 loss)
I0131 01:15:41.869442 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:15:41.869448 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.0283651 (* 1 = 0.0283651 loss)
I0131 01:15:41.869457 25291 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0131 01:16:40.201587 25291 solver.cpp:228] Iteration 300, loss = 0.0128806
I0131 01:16:40.201637 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:16:40.201656 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000501892 (* 1 = 0.000501892 loss)
I0131 01:16:40.201668 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:16:40.201678 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000147037 (* 1 = 0.000147037 loss)
I0131 01:16:40.201689 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:16:40.201701 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00164835 (* 1 = 0.00164835 loss)
I0131 01:16:40.201714 25291 sgd_solver.cpp:106] Iteration 300, lr = 0.001
>>> 2017-01-31 01:17:38.380360 Begin model classification tests
>>> 2017-01-31 01:20:23.807821 Iteration 400 mean classification accuracy (rgb)  0.892724147809
>>> 2017-01-31 01:20:23.807868 Iteration 400 mean classification accuracy (depth) 0.758235462618
>>> 2017-01-31 01:20:23.807888 Iteration 400 mean classification accuracy (rgbd)  0.915640217703
>>> 2017-01-31 01:20:23.807902 Iteration 400 mean testing loss (rgb) 0.459454010871
>>> 2017-01-31 01:20:23.807921 Iteration 400 mean testing loss (depth) 1.59723220253
>>> 2017-01-31 01:20:23.807934 Iteration 400 mean testing loss (rgbd) 0.311263742098
>>> 2017-01-31 01:20:23.807944 Iteration 400 mean confusion matrix
[ 1.          0.07926829  1.          1.          1.          0.81987578
  1.          0.62608696  0.9047619   0.9537037   1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.82608696  1.          1.          1.          1.          1.
  0.88028169  1.          1.          1.          1.          0.95652174
  0.17105263  0.66666667  1.          0.82978723  0.80714286  0.95238095
  0.78378378  1.          0.96428571  1.          0.99354839  1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 01:20:24.599954 25291 solver.cpp:228] Iteration 400, loss = 0.0288873
I0131 01:20:24.599992 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 01:20:24.600003 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0257963 (* 1 = 0.0257963 loss)
I0131 01:20:24.600008 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:20:24.600016 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000181677 (* 1 = 0.000181677 loss)
I0131 01:20:24.600021 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:20:24.600026 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00290936 (* 1 = 0.00290936 loss)
I0131 01:20:24.600034 25291 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0131 01:21:23.031270 25291 solver.cpp:228] Iteration 500, loss = 0.0109592
I0131 01:21:23.031319 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:21:23.031339 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00144479 (* 1 = 0.00144479 loss)
I0131 01:21:23.031349 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:21:23.031359 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.18685e-05 (* 1 = 4.18685e-05 loss)
I0131 01:21:23.031370 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:21:23.031381 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00416947 (* 1 = 0.00416947 loss)
I0131 01:21:23.031394 25291 sgd_solver.cpp:106] Iteration 500, lr = 0.001
>>> 2017-01-31 01:22:20.341124 Begin model classification tests
>>> 2017-01-31 01:25:05.845241 Iteration 600 mean classification accuracy (rgb)  0.898023488972
>>> 2017-01-31 01:25:05.845278 Iteration 600 mean classification accuracy (depth) 0.755084503008
>>> 2017-01-31 01:25:05.845287 Iteration 600 mean classification accuracy (rgbd)  0.920509882555
>>> 2017-01-31 01:25:05.845295 Iteration 600 mean testing loss (rgb) 0.447709051179
>>> 2017-01-31 01:25:05.845307 Iteration 600 mean testing loss (depth) 1.60681982587
>>> 2017-01-31 01:25:05.845316 Iteration 600 mean testing loss (rgbd) 0.291082650863
>>> 2017-01-31 01:25:05.845322 Iteration 600 mean confusion matrix
[ 1.          0.08536585  1.          1.          1.          0.7826087   1.
  0.65217391  0.9047619   1.          1.          1.          0.78378378
  1.          1.          1.          1.          1.          1.
  0.76397516  1.          1.          1.          1.          1.
  0.94366197  1.          1.          1.          1.          0.95652174
  0.18421053  0.72222222  1.          0.82978723  0.84285714  0.95918367
  0.85585586  1.          0.96428571  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 01:25:06.689465 25291 solver.cpp:228] Iteration 600, loss = 0.0129029
I0131 01:25:06.689504 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:25:06.689514 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.012091 (* 1 = 0.012091 loss)
I0131 01:25:06.689522 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:25:06.689528 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.24234e-05 (* 1 = 4.24234e-05 loss)
I0131 01:25:06.689533 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:25:06.689539 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000769512 (* 1 = 0.000769512 loss)
I0131 01:25:06.689545 25291 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0131 01:26:12.545065 25291 solver.cpp:228] Iteration 700, loss = 0.0112622
I0131 01:26:12.545100 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:26:12.545116 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00503781 (* 1 = 0.00503781 loss)
I0131 01:26:12.545125 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:26:12.545135 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.04986e-05 (* 1 = 3.04986e-05 loss)
I0131 01:26:12.545145 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:26:12.545156 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000734001 (* 1 = 0.000734001 loss)
I0131 01:26:12.545168 25291 sgd_solver.cpp:106] Iteration 700, lr = 0.001
>>> 2017-01-31 01:27:14.284316 Begin model classification tests
>>> 2017-01-31 01:29:58.887305 Iteration 800 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 01:29:58.887420 Iteration 800 mean classification accuracy (depth) 0.754654826697
>>> 2017-01-31 01:29:58.887479 Iteration 800 mean classification accuracy (rgbd)  0.927384703523
>>> 2017-01-31 01:29:58.887525 Iteration 800 mean testing loss (rgb) 0.442389248001
>>> 2017-01-31 01:29:58.887576 Iteration 800 mean testing loss (depth) 1.58266205789
>>> 2017-01-31 01:29:58.887621 Iteration 800 mean testing loss (rgbd) 0.279058298556
>>> 2017-01-31 01:29:58.887665 Iteration 800 mean confusion matrix
[ 1.          0.07926829  1.          1.          1.          0.9068323   1.
  0.60869565  0.8968254   1.          1.          1.          0.78378378
  1.          1.          1.          1.          1.          1.
  0.85093168  1.          1.          1.          1.          1.
  0.93661972  1.          1.          1.          1.          0.98757764
  0.21052632  0.80246914  1.          0.87943262  0.82857143  0.94557823
  0.83783784  1.          0.96428571  1.          0.99354839  1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 01:29:59.570960 25291 solver.cpp:228] Iteration 800, loss = 0.0110909
I0131 01:29:59.571002 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:29:59.571022 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00962644 (* 1 = 0.00962644 loss)
I0131 01:29:59.571033 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:29:59.571045 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000254483 (* 1 = 0.000254483 loss)
I0131 01:29:59.571058 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:29:59.571070 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00121 (* 1 = 0.00121 loss)
I0131 01:29:59.571081 25291 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0131 01:31:03.020757 25291 solver.cpp:228] Iteration 900, loss = 0.0102883
I0131 01:31:03.020794 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:31:03.020804 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0116459 (* 1 = 0.0116459 loss)
I0131 01:31:03.020813 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:31:03.020820 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.95394e-05 (* 1 = 4.95394e-05 loss)
I0131 01:31:03.020826 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:31:03.020833 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000750344 (* 1 = 0.000750344 loss)
I0131 01:31:03.020840 25291 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0131 01:32:03.880620 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_1000.caffemodel
I0131 01:32:26.431167 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_1000.solverstate
>>> 2017-01-31 01:32:41.450345 Begin model classification tests
>>> 2017-01-31 01:35:30.035253 Iteration 1000 mean classification accuracy (rgb)  0.901031223145
>>> 2017-01-31 01:35:30.035290 Iteration 1000 mean classification accuracy (depth) 0.752936121455
>>> 2017-01-31 01:35:30.035299 Iteration 1000 mean classification accuracy (rgbd)  0.928816957892
>>> 2017-01-31 01:35:30.035308 Iteration 1000 mean testing loss (rgb) 0.418827145818
>>> 2017-01-31 01:35:30.035319 Iteration 1000 mean testing loss (depth) 1.60481075302
>>> 2017-01-31 01:35:30.035328 Iteration 1000 mean testing loss (rgbd) 0.273924624547
>>> 2017-01-31 01:35:30.035335 Iteration 1000 mean confusion matrix
[ 1.          0.07926829  1.          1.          1.          0.95652174
  1.          0.66086957  0.8968254   1.          1.          1.
  0.75675676  0.99047619  1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.          0.9084507
  1.          1.          1.          1.          0.98757764  0.19736842
  0.78395062  1.          0.86524823  0.85        0.97278912  0.83783784
  1.          0.96428571  1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.        ]
I0131 01:35:30.767654 25291 solver.cpp:228] Iteration 1000, loss = 0.0153092
I0131 01:35:30.767701 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:35:30.767719 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0149753 (* 1 = 0.0149753 loss)
I0131 01:35:30.767729 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:35:30.767740 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.45229e-05 (* 1 = 2.45229e-05 loss)
I0131 01:35:30.767748 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:35:30.767760 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000309321 (* 1 = 0.000309321 loss)
I0131 01:35:30.767771 25291 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0131 01:40:51.189007 25291 solver.cpp:228] Iteration 1100, loss = 0.0107306
I0131 01:40:51.189055 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:40:51.189076 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00631228 (* 1 = 0.00631228 loss)
I0131 01:40:51.189088 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:40:51.189100 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.05308e-05 (* 1 = 2.05308e-05 loss)
I0131 01:40:51.189110 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:40:51.189121 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000535381 (* 1 = 0.000535381 loss)
I0131 01:40:51.189132 25291 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
>>> 2017-01-31 01:45:22.505695 Begin model classification tests
>>> 2017-01-31 01:48:11.405231 Iteration 1200 mean classification accuracy (rgb)  0.89902606703
>>> 2017-01-31 01:48:11.405279 Iteration 1200 mean classification accuracy (depth) 0.755514179318
>>> 2017-01-31 01:48:11.405290 Iteration 1200 mean classification accuracy (rgbd)  0.927241478087
>>> 2017-01-31 01:48:11.405301 Iteration 1200 mean testing loss (rgb) 0.429573720865
>>> 2017-01-31 01:48:11.405312 Iteration 1200 mean testing loss (depth) 1.56412202732
>>> 2017-01-31 01:48:11.405321 Iteration 1200 mean testing loss (rgbd) 0.294787846687
>>> 2017-01-31 01:48:11.405328 Iteration 1200 mean confusion matrix
[ 1.          0.04878049  1.          1.          1.          0.95031056
  1.          0.63478261  0.8968254   1.          1.          1.
  0.75675676  1.          1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.          0.8943662
  1.          1.          1.          1.          0.98757764  0.19736842
  0.83333333  1.          0.86524823  0.84285714  0.97278912  0.76576577
  1.          0.96428571  1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.        ]
I0131 01:48:13.726346 25291 solver.cpp:228] Iteration 1200, loss = 0.00635312
I0131 01:48:13.726395 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:48:13.726419 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00572747 (* 1 = 0.00572747 loss)
I0131 01:48:13.726433 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:48:13.726447 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000117322 (* 1 = 0.000117322 loss)
I0131 01:48:13.726461 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:48:13.726475 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000508334 (* 1 = 0.000508334 loss)
I0131 01:48:13.726490 25291 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0131 01:51:21.696887 25291 solver.cpp:228] Iteration 1300, loss = 0.0101388
I0131 01:51:21.696945 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:51:21.696964 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00241781 (* 1 = 0.00241781 loss)
I0131 01:51:21.696975 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:51:21.696988 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.09007e-05 (* 1 = 2.09007e-05 loss)
I0131 01:51:21.696998 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:51:21.697010 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000391865 (* 1 = 0.000391865 loss)
I0131 01:51:21.697023 25291 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
>>> 2017-01-31 01:54:05.111675 Begin model classification tests
>>> 2017-01-31 01:56:54.704225 Iteration 1400 mean classification accuracy (rgb)  0.901604124893
>>> 2017-01-31 01:56:54.704269 Iteration 1400 mean classification accuracy (depth) 0.75451160126
>>> 2017-01-31 01:56:54.704282 Iteration 1400 mean classification accuracy (rgbd)  0.922801489545
>>> 2017-01-31 01:56:54.704292 Iteration 1400 mean testing loss (rgb) 0.406321312993
>>> 2017-01-31 01:56:54.704307 Iteration 1400 mean testing loss (depth) 1.60307855356
>>> 2017-01-31 01:56:54.704315 Iteration 1400 mean testing loss (rgbd) 0.287660271901
>>> 2017-01-31 01:56:54.704324 Iteration 1400 mean confusion matrix
[ 1.          0.07317073  1.          1.          1.          0.88819876
  1.          0.63478261  0.8968254   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.          0.8943662
  1.          1.          1.          1.          0.98136646  0.19736842
  0.7037037   1.          0.87943262  0.83571429  0.95238095  0.77477477
  1.          0.96428571  1.          1.          1.          1.          1.
  1.          1.          1.          1.          0.99367089  1.        ]
I0131 01:56:58.969849 25291 solver.cpp:228] Iteration 1400, loss = 0.00671079
I0131 01:56:58.969890 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 01:56:58.969907 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00485691 (* 1 = 0.00485691 loss)
I0131 01:56:58.969913 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 01:56:58.969920 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.31903e-05 (* 1 = 2.31903e-05 loss)
I0131 01:56:58.969926 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 01:56:58.969936 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00183069 (* 1 = 0.00183069 loss)
I0131 01:56:58.969947 25291 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0131 02:00:13.915812 25291 solver.cpp:228] Iteration 1500, loss = 0.0074322
I0131 02:00:13.915866 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 02:00:13.915890 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.024499 (* 1 = 0.024499 loss)
I0131 02:00:13.915904 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:00:13.915920 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.60516e-05 (* 1 = 1.60516e-05 loss)
I0131 02:00:13.915933 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:00:13.915947 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.0003832 (* 1 = 0.0003832 loss)
I0131 02:00:13.915961 25291 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
>>> 2017-01-31 02:03:16.485034 Begin model classification tests
>>> 2017-01-31 02:06:06.019462 Iteration 1600 mean classification accuracy (rgb)  0.901890575766
>>> 2017-01-31 02:06:06.019517 Iteration 1600 mean classification accuracy (depth) 0.749212260097
>>> 2017-01-31 02:06:06.019538 Iteration 1600 mean classification accuracy (rgbd)  0.925236321971
>>> 2017-01-31 02:06:06.019554 Iteration 1600 mean testing loss (rgb) 0.408937405618
>>> 2017-01-31 02:06:06.019576 Iteration 1600 mean testing loss (depth) 1.59771560704
>>> 2017-01-31 02:06:06.019693 Iteration 1600 mean testing loss (rgbd) 0.292792789433
>>> 2017-01-31 02:06:06.019714 Iteration 1600 mean confusion matrix
[ 1.          0.07317073  1.          1.          1.          0.89440994
  1.          0.64347826  0.8968254   0.99074074  1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.          0.8943662
  1.          1.          1.          1.          0.98136646  0.19736842
  0.77160494  1.          0.90780142  0.83571429  0.95238095  0.77477477
  1.          0.96428571  1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.        ]
I0131 02:06:07.577934 25291 solver.cpp:228] Iteration 1600, loss = 0.0292127
I0131 02:06:07.577980 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 02:06:07.578002 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.025671 (* 1 = 0.025671 loss)
I0131 02:06:07.578016 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:06:07.578030 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.47863e-05 (* 1 = 8.47863e-05 loss)
I0131 02:06:07.578042 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:06:07.578057 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00345683 (* 1 = 0.00345683 loss)
I0131 02:06:07.578069 25291 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0131 02:09:51.494465 25291 solver.cpp:228] Iteration 1700, loss = 0.00976866
I0131 02:09:51.494567 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:09:51.494619 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00725819 (* 1 = 0.00725819 loss)
I0131 02:09:51.494659 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:09:51.494736 25291 solver.cpp:244]     Train net output #3: rgb_loss = 9.34706e-06 (* 1 = 9.34706e-06 loss)
I0131 02:09:51.494773 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:09:51.494809 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000520204 (* 1 = 0.000520204 loss)
I0131 02:09:51.494844 25291 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
>>> 2017-01-31 02:13:57.980169 Begin model classification tests
>>> 2017-01-31 02:16:45.379519 Iteration 1800 mean classification accuracy (rgb)  0.90217702664
>>> 2017-01-31 02:16:45.379561 Iteration 1800 mean classification accuracy (depth) 0.751647092524
>>> 2017-01-31 02:16:45.379574 Iteration 1800 mean classification accuracy (rgbd)  0.926382125465
>>> 2017-01-31 02:16:45.379585 Iteration 1800 mean testing loss (rgb) 0.409596155343
>>> 2017-01-31 02:16:45.379602 Iteration 1800 mean testing loss (depth) 1.62390596941
>>> 2017-01-31 02:16:45.379616 Iteration 1800 mean testing loss (rgbd) 0.283227332735
>>> 2017-01-31 02:16:45.379629 Iteration 1800 mean confusion matrix
[ 1.          0.07926829  1.          1.          1.          0.91304348
  1.          0.67826087  0.86507937  0.98148148  1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.85714286  1.          1.          1.          1.          1.          0.8943662
  1.          1.          1.          1.          0.98136646  0.19736842
  0.88271605  1.          0.90780142  0.83571429  0.96598639  0.66666667
  1.          0.95535714  1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.        ]
I0131 02:16:48.216965 25291 solver.cpp:228] Iteration 1800, loss = 0.00250201
I0131 02:16:48.217017 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:16:48.217041 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0023077 (* 1 = 0.0023077 loss)
I0131 02:16:48.217052 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:16:48.217068 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.67951e-05 (* 1 = 2.67951e-05 loss)
I0131 02:16:48.217082 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:16:48.217097 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000167519 (* 1 = 0.000167519 loss)
I0131 02:16:48.217111 25291 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0131 02:19:59.009739 25291 solver.cpp:228] Iteration 1900, loss = 0.0101485
I0131 02:19:59.009793 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:19:59.009817 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00824929 (* 1 = 0.00824929 loss)
I0131 02:19:59.009829 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:19:59.009841 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000111947 (* 1 = 0.000111947 loss)
I0131 02:19:59.009855 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:19:59.009866 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000797834 (* 1 = 0.000797834 loss)
I0131 02:19:59.009881 25291 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0131 02:22:53.716426 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_2000.caffemodel
I0131 02:23:24.825153 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_2000.solverstate
>>> 2017-01-31 02:23:41.870888 Begin model classification tests
>>> 2017-01-31 02:26:31.360801 Iteration 2000 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 02:26:31.360847 Iteration 2000 mean classification accuracy (depth) 0.748782583787
>>> 2017-01-31 02:26:31.360863 Iteration 2000 mean classification accuracy (rgbd)  0.925665998281
>>> 2017-01-31 02:26:31.360875 Iteration 2000 mean testing loss (rgb) 0.41805947184
>>> 2017-01-31 02:26:31.360893 Iteration 2000 mean testing loss (depth) 1.62621513477
>>> 2017-01-31 02:26:31.360905 Iteration 2000 mean testing loss (rgbd) 0.276123154802
>>> 2017-01-31 02:26:31.360917 Iteration 2000 mean confusion matrix
[ 1.          0.13414634  1.          1.          1.          0.88819876
  1.          0.66956522  0.8968254   0.99074074  1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.          0.8943662
  1.          1.          1.          1.          0.98136646  0.19736842
  0.87037037  1.          0.96453901  0.80714286  0.80952381  0.71171171
  1.          0.95535714  1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.        ]
I0131 02:26:33.961267 25291 solver.cpp:228] Iteration 2000, loss = 0.00409006
I0131 02:26:33.961311 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:26:33.961331 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00354211 (* 1 = 0.00354211 loss)
I0131 02:26:33.961343 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:26:33.961359 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.836e-06 (* 1 = 6.836e-06 loss)
I0131 02:26:33.961367 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:26:33.961377 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00054111 (* 1 = 0.00054111 loss)
I0131 02:26:33.961388 25291 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0131 02:30:00.754294 25291 solver.cpp:228] Iteration 2100, loss = 0.0105343
I0131 02:30:00.754401 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:30:00.754449 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000718722 (* 1 = 0.000718722 loss)
I0131 02:30:00.754490 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:30:00.754531 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000223435 (* 1 = 0.000223435 loss)
I0131 02:30:00.754570 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:30:00.754611 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000547593 (* 1 = 0.000547593 loss)
I0131 02:30:00.754652 25291 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
>>> 2017-01-31 02:32:25.148501 Begin model classification tests
>>> 2017-01-31 02:35:20.390639 Iteration 2200 mean classification accuracy (rgb)  0.899742194214
>>> 2017-01-31 02:35:20.390690 Iteration 2200 mean classification accuracy (depth) 0.75179031796
>>> 2017-01-31 02:35:20.390707 Iteration 2200 mean classification accuracy (rgbd)  0.92752792896
>>> 2017-01-31 02:35:20.390719 Iteration 2200 mean testing loss (rgb) 0.422228783275
>>> 2017-01-31 02:35:20.390737 Iteration 2200 mean testing loss (depth) 1.59537927937
>>> 2017-01-31 02:35:20.390749 Iteration 2200 mean testing loss (rgbd) 0.275828490891
>>> 2017-01-31 02:35:20.390761 Iteration 2200 mean confusion matrix
[ 1.          0.1097561   1.          1.          1.          0.9068323   1.
  0.64347826  0.8968254   1.          1.          1.          0.75675676
  1.          1.          1.          1.          1.          1.          0.8447205
  1.          1.          1.          1.          1.          0.88732394
  1.          1.          1.          1.          0.98136646  0.20394737
  0.88271605  1.          0.95744681  0.82857143  0.92517007  0.69369369
  1.          0.95535714  1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.        ]
I0131 02:35:21.217924 25291 solver.cpp:228] Iteration 2200, loss = 0.0329512
I0131 02:35:21.217975 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 02:35:21.217989 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0324489 (* 1 = 0.0324489 loss)
I0131 02:35:21.217999 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:35:21.218009 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.37888e-06 (* 1 = 3.37888e-06 loss)
I0131 02:35:21.218017 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:35:21.218026 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000498923 (* 1 = 0.000498923 loss)
I0131 02:35:21.218037 25291 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0131 02:38:44.945920 25291 solver.cpp:228] Iteration 2300, loss = 0.0106454
I0131 02:38:44.945957 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:38:44.945971 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0244898 (* 1 = 0.0244898 loss)
I0131 02:38:44.945977 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:38:44.945986 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.82181e-06 (* 1 = 8.82181e-06 loss)
I0131 02:38:44.945991 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:38:44.945996 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000976169 (* 1 = 0.000976169 loss)
I0131 02:38:44.946003 25291 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
>>> 2017-01-31 02:41:39.420847 Begin model classification tests
>>> 2017-01-31 02:44:28.540960 Iteration 2400 mean classification accuracy (rgb)  0.899169292466
>>> 2017-01-31 02:44:28.541002 Iteration 2400 mean classification accuracy (depth) 0.750358063592
>>> 2017-01-31 02:44:28.541011 Iteration 2400 mean classification accuracy (rgbd)  0.928387281581
>>> 2017-01-31 02:44:28.541017 Iteration 2400 mean testing loss (rgb) 0.424678520227
>>> 2017-01-31 02:44:28.541029 Iteration 2400 mean testing loss (depth) 1.5713218521
>>> 2017-01-31 02:44:28.541037 Iteration 2400 mean testing loss (rgbd) 0.271508527031
>>> 2017-01-31 02:44:28.541045 Iteration 2400 mean confusion matrix
[ 1.          0.11585366  1.          1.          1.          0.89440994
  1.          0.66956522  0.8968254   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.85093168  1.          1.          1.          1.          1.
  0.88732394  1.          1.          1.          1.          0.98136646
  0.19736842  0.89506173  1.          0.90780142  0.85        0.95238095
  0.72072072  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 02:44:31.264668 25291 solver.cpp:228] Iteration 2400, loss = 0.000239715
I0131 02:44:31.264704 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:44:31.264714 25291 solver.cpp:244]     Train net output #1: depth_loss = 8.27274e-05 (* 1 = 8.27274e-05 loss)
I0131 02:44:31.264721 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:44:31.264729 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.28727e-05 (* 1 = 1.28727e-05 loss)
I0131 02:44:31.264735 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:44:31.264744 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000144115 (* 1 = 0.000144115 loss)
I0131 02:44:31.264750 25291 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0131 02:47:39.802984 25291 solver.cpp:228] Iteration 2500, loss = 0.00673104
I0131 02:47:39.803040 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:47:39.803066 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0144656 (* 1 = 0.0144656 loss)
I0131 02:47:39.803081 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:47:39.803099 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.08098e-05 (* 1 = 3.08098e-05 loss)
I0131 02:47:39.803110 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:47:39.803123 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000343035 (* 1 = 0.000343035 loss)
I0131 02:47:39.803136 25291 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
>>> 2017-01-31 02:50:26.891335 Begin model classification tests
>>> 2017-01-31 02:53:16.499272 Iteration 2600 mean classification accuracy (rgb)  0.895302205672
>>> 2017-01-31 02:53:16.499317 Iteration 2600 mean classification accuracy (depth) 0.757519335434
>>> 2017-01-31 02:53:16.499327 Iteration 2600 mean classification accuracy (rgbd)  0.93024921226
>>> 2017-01-31 02:53:16.499337 Iteration 2600 mean testing loss (rgb) 0.434022189158
>>> 2017-01-31 02:53:16.499349 Iteration 2600 mean testing loss (depth) 1.56764092464
>>> 2017-01-31 02:53:16.499357 Iteration 2600 mean testing loss (rgbd) 0.278885228855
>>> 2017-01-31 02:53:16.499365 Iteration 2600 mean confusion matrix
[ 1.          0.08536585  1.          1.          1.          0.95031056
  1.          0.67826087  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.85714286  1.          1.          1.          1.          1.
  0.88732394  1.          1.          1.          1.          0.98136646
  0.19736842  0.89506173  1.          0.88652482  0.85        0.97959184
  0.76576577  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 02:53:19.115862 25291 solver.cpp:228] Iteration 2600, loss = 0.00938109
I0131 02:53:19.115895 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:53:19.115906 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00857513 (* 1 = 0.00857513 loss)
I0131 02:53:19.115916 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:53:19.115921 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000104419 (* 1 = 0.000104419 loss)
I0131 02:53:19.115927 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:53:19.115933 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000701546 (* 1 = 0.000701546 loss)
I0131 02:53:19.115944 25291 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0131 02:55:56.647290 25291 solver.cpp:228] Iteration 2700, loss = 0.00939179
I0131 02:55:56.647336 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 02:55:56.647353 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00807216 (* 1 = 0.00807216 loss)
I0131 02:55:56.647366 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 02:55:56.647378 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000184354 (* 1 = 0.000184354 loss)
I0131 02:55:56.647389 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 02:55:56.647403 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000864611 (* 1 = 0.000864611 loss)
I0131 02:55:56.647414 25291 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
>>> 2017-01-31 02:58:32.461382 Begin model classification tests
>>> 2017-01-31 03:01:21.648646 Iteration 2800 mean classification accuracy (rgb)  0.897450587224
>>> 2017-01-31 03:01:21.648712 Iteration 2800 mean classification accuracy (depth) 0.755943855629
>>> 2017-01-31 03:01:21.648764 Iteration 2800 mean classification accuracy (rgbd)  0.933543397307
>>> 2017-01-31 03:01:21.648808 Iteration 2800 mean testing loss (rgb) 0.431893190694
>>> 2017-01-31 03:01:21.648856 Iteration 2800 mean testing loss (depth) 1.56993208895
>>> 2017-01-31 03:01:21.648888 Iteration 2800 mean testing loss (rgbd) 0.267554157999
>>> 2017-01-31 03:01:21.648932 Iteration 2800 mean confusion matrix
[ 1.          0.10365854  1.          1.          1.          0.94409938
  1.          0.66956522  0.9047619   1.          1.          1.
  0.73873874  1.          1.          1.          1.          1.          1.
  0.8757764   1.          1.          1.          1.          1.
  0.88732394  1.          1.          1.          1.          0.98136646
  0.20394737  0.9382716   1.          0.89361702  0.87142857  0.98639456
  0.82882883  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 03:01:23.428033 25291 solver.cpp:228] Iteration 2800, loss = 0.00100831
I0131 03:01:23.428081 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:01:23.428100 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000913775 (* 1 = 0.000913775 loss)
I0131 03:01:23.428112 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:01:23.428123 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.12866e-05 (* 1 = 1.12866e-05 loss)
I0131 03:01:23.428135 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:01:23.428148 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 8.32456e-05 (* 1 = 8.32456e-05 loss)
I0131 03:01:23.428159 25291 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0131 03:03:34.826499 25291 solver.cpp:228] Iteration 2900, loss = 0.0105793
I0131 03:03:34.826552 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:03:34.826571 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000954569 (* 1 = 0.000954569 loss)
I0131 03:03:34.826582 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:03:34.826597 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.33558e-05 (* 1 = 2.33558e-05 loss)
I0131 03:03:34.826607 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:03:34.826618 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 9.82335e-05 (* 1 = 9.82335e-05 loss)
I0131 03:03:34.826632 25291 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0131 03:05:57.889824 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_3000.caffemodel
I0131 03:06:23.586491 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_3000.solverstate
>>> 2017-01-31 03:06:35.419230 Begin model classification tests
>>> 2017-01-31 03:09:25.428430 Iteration 3000 mean classification accuracy (rgb)  0.898596390719
>>> 2017-01-31 03:09:25.428476 Iteration 3000 mean classification accuracy (depth) 0.756087081066
>>> 2017-01-31 03:09:25.428485 Iteration 3000 mean classification accuracy (rgbd)  0.933256946434
>>> 2017-01-31 03:09:25.428492 Iteration 3000 mean testing loss (rgb) 0.428344517578
>>> 2017-01-31 03:09:25.428505 Iteration 3000 mean testing loss (depth) 1.59078002272
>>> 2017-01-31 03:09:25.428512 Iteration 3000 mean testing loss (rgbd) 0.263711661204
>>> 2017-01-31 03:09:25.428519 Iteration 3000 mean confusion matrix
[ 1.          0.10365854  1.          1.          1.          0.9068323   1.
  0.67826087  0.9047619   1.          1.          1.          0.77477477
  1.          1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.
  0.88732394  1.          1.          1.          1.          0.96273292
  0.21052632  0.9382716   1.          0.88652482  0.89285714  0.98639456
  0.82882883  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 03:09:26.258597 25291 solver.cpp:228] Iteration 3000, loss = 0.00403859
I0131 03:09:26.258644 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:09:26.258657 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00382806 (* 1 = 0.00382806 loss)
I0131 03:09:26.258667 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:09:26.258674 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.74109e-05 (* 1 = 1.74109e-05 loss)
I0131 03:09:26.258680 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:09:26.258688 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000193126 (* 1 = 0.000193126 loss)
I0131 03:09:26.258697 25291 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0131 03:12:52.960750 25291 solver.cpp:228] Iteration 3100, loss = 0.00854963
I0131 03:12:52.960798 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:12:52.960817 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00227732 (* 1 = 0.00227732 loss)
I0131 03:12:52.960827 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:12:52.960841 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.40174e-06 (* 1 = 5.40174e-06 loss)
I0131 03:12:52.960852 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:12:52.960862 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.62111e-05 (* 1 = 4.62111e-05 loss)
I0131 03:12:52.960873 25291 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
>>> 2017-01-31 03:16:03.458049 Begin model classification tests
>>> 2017-01-31 03:18:51.947606 Iteration 3200 mean classification accuracy (rgb)  0.897880263535
>>> 2017-01-31 03:18:51.947648 Iteration 3200 mean classification accuracy (depth) 0.754654826697
>>> 2017-01-31 03:18:51.947660 Iteration 3200 mean classification accuracy (rgbd)  0.931538241192
>>> 2017-01-31 03:18:51.947667 Iteration 3200 mean testing loss (rgb) 0.431442599025
>>> 2017-01-31 03:18:51.947679 Iteration 3200 mean testing loss (depth) 1.57344881324
>>> 2017-01-31 03:18:51.947687 Iteration 3200 mean testing loss (rgbd) 0.266926052093
>>> 2017-01-31 03:18:51.947696 Iteration 3200 mean confusion matrix
[ 1.          0.1097561   1.          1.          1.          0.9068323   1.
  0.67826087  0.9047619   1.          1.          1.          0.74774775
  1.          1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.
  0.86619718  1.          1.          1.          1.          0.95031056
  0.21052632  0.91975309  1.          0.87234043  0.9         0.98639456
  0.81981982  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 03:18:52.514322 25291 solver.cpp:228] Iteration 3200, loss = 0.0149491
I0131 03:18:52.514366 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:18:52.514380 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0147339 (* 1 = 0.0147339 loss)
I0131 03:18:52.514390 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:18:52.514400 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.86289e-05 (* 1 = 3.86289e-05 loss)
I0131 03:18:52.514408 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:18:52.514420 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000176642 (* 1 = 0.000176642 loss)
I0131 03:18:52.514430 25291 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0131 03:21:58.729046 25291 solver.cpp:228] Iteration 3300, loss = 0.00746429
I0131 03:21:58.729086 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:21:58.729096 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0102481 (* 1 = 0.0102481 loss)
I0131 03:21:58.729104 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:21:58.729113 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000494868 (* 1 = 0.000494868 loss)
I0131 03:21:58.729120 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:21:58.729126 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00107315 (* 1 = 0.00107315 loss)
I0131 03:21:58.729135 25291 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
>>> 2017-01-31 03:24:53.260456 Begin model classification tests
>>> 2017-01-31 03:27:42.528271 Iteration 3400 mean classification accuracy (rgb)  0.898023488972
>>> 2017-01-31 03:27:42.528327 Iteration 3400 mean classification accuracy (depth) 0.754941277571
>>> 2017-01-31 03:27:42.528344 Iteration 3400 mean classification accuracy (rgbd)  0.930392437697
>>> 2017-01-31 03:27:42.528356 Iteration 3400 mean testing loss (rgb) 0.428721591246
>>> 2017-01-31 03:27:42.528373 Iteration 3400 mean testing loss (depth) 1.59065760219
>>> 2017-01-31 03:27:42.528387 Iteration 3400 mean testing loss (rgbd) 0.267157707442
>>> 2017-01-31 03:27:42.528401 Iteration 3400 mean confusion matrix
[ 1.          0.1097561   1.          1.          1.          0.89440994
  1.          0.69565217  0.9047619   1.          1.          1.
  0.75675676  1.          1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.
  0.88028169  1.          1.          1.          1.          0.9689441
  0.21710526  0.84567901  1.          0.87234043  0.90714286  0.98639456
  0.78378378  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 03:27:43.666563 25291 solver.cpp:228] Iteration 3400, loss = 0.00136813
I0131 03:27:43.666609 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:27:43.666626 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00116758 (* 1 = 0.00116758 loss)
I0131 03:27:43.666635 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:27:43.666646 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.39514e-05 (* 1 = 2.39514e-05 loss)
I0131 03:27:43.666653 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:27:43.666661 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000176604 (* 1 = 0.000176604 loss)
I0131 03:27:43.666671 25291 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0131 03:30:34.794525 25291 solver.cpp:228] Iteration 3500, loss = 0.006944
I0131 03:30:34.794567 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:30:34.794579 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0168086 (* 1 = 0.0168086 loss)
I0131 03:30:34.794587 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:30:34.794595 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000103698 (* 1 = 0.000103698 loss)
I0131 03:30:34.794600 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:30:34.794606 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000326936 (* 1 = 0.000326936 loss)
I0131 03:30:34.794616 25291 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
>>> 2017-01-31 03:33:27.586154 Begin model classification tests
>>> 2017-01-31 03:36:18.539000 Iteration 3600 mean classification accuracy (rgb)  0.897593812661
>>> 2017-01-31 03:36:18.539104 Iteration 3600 mean classification accuracy (depth) 0.75408192495
>>> 2017-01-31 03:36:18.539145 Iteration 3600 mean classification accuracy (rgbd)  0.929389859639
>>> 2017-01-31 03:36:18.539186 Iteration 3600 mean testing loss (rgb) 0.437555664032
>>> 2017-01-31 03:36:18.539230 Iteration 3600 mean testing loss (depth) 1.55290113485
>>> 2017-01-31 03:36:18.539271 Iteration 3600 mean testing loss (rgbd) 0.269793530194
>>> 2017-01-31 03:36:18.539310 Iteration 3600 mean confusion matrix
[ 1.          0.12804878  1.          1.          1.          0.86956522
  1.          0.70434783  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.86335404  1.          1.          1.          1.          1.
  0.88732394  1.          1.          1.          1.          0.95031056
  0.20394737  0.85802469  1.          0.85106383  0.90714286  0.98639456
  0.78378378  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 03:36:19.132324 25291 solver.cpp:228] Iteration 3600, loss = 0.00346863
I0131 03:36:19.132364 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:36:19.132381 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00298753 (* 1 = 0.00298753 loss)
I0131 03:36:19.132390 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:36:19.132400 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.39183e-05 (* 1 = 1.39183e-05 loss)
I0131 03:36:19.132410 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:36:19.132419 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000467187 (* 1 = 0.000467187 loss)
I0131 03:36:19.132431 25291 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0131 03:39:00.550403 25291 solver.cpp:228] Iteration 3700, loss = 0.0106844
I0131 03:39:00.550442 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:39:00.550456 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000886396 (* 1 = 0.000886396 loss)
I0131 03:39:00.550462 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:39:00.550469 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.05426e-06 (* 1 = 1.05426e-06 loss)
I0131 03:39:00.550475 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:39:00.550482 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.75973e-05 (* 1 = 3.75973e-05 loss)
I0131 03:39:00.550488 25291 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
>>> 2017-01-31 03:41:42.814737 Begin model classification tests
>>> 2017-01-31 03:44:34.600175 Iteration 3800 mean classification accuracy (rgb)  0.898309939845
>>> 2017-01-31 03:44:34.600312 Iteration 3800 mean classification accuracy (depth) 0.751933543397
>>> 2017-01-31 03:44:34.600367 Iteration 3800 mean classification accuracy (rgbd)  0.931395015755
>>> 2017-01-31 03:44:34.600395 Iteration 3800 mean testing loss (rgb) 0.437878910571
>>> 2017-01-31 03:44:34.600432 Iteration 3800 mean testing loss (depth) 1.57802175307
>>> 2017-01-31 03:44:34.600458 Iteration 3800 mean testing loss (rgbd) 0.271208252821
>>> 2017-01-31 03:44:34.600480 Iteration 3800 mean confusion matrix
[ 1.          0.12195122  1.          1.          1.          0.88819876
  1.          0.70434783  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.86956522  1.          1.          1.          1.          1.          0.8943662
  1.          1.          1.          1.          0.98136646  0.19736842
  0.85802469  1.          0.87234043  0.90714286  0.98639456  0.81081081
  1.          0.95535714  1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.        ]
I0131 03:44:36.084251 25291 solver.cpp:228] Iteration 3800, loss = 0.00729239
I0131 03:44:36.084288 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:44:36.084302 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00719962 (* 1 = 0.00719962 loss)
I0131 03:44:36.084311 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:44:36.084319 25291 solver.cpp:244]     Train net output #3: rgb_loss = 7.09692e-06 (* 1 = 7.09692e-06 loss)
I0131 03:44:36.084326 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:44:36.084332 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 8.56703e-05 (* 1 = 8.56703e-05 loss)
I0131 03:44:36.084344 25291 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0131 03:47:02.170541 25291 solver.cpp:228] Iteration 3900, loss = 0.00869946
I0131 03:47:02.170586 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:47:02.170604 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00233491 (* 1 = 0.00233491 loss)
I0131 03:47:02.170610 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:47:02.170616 25291 solver.cpp:244]     Train net output #3: rgb_loss = 9.02906e-06 (* 1 = 9.02906e-06 loss)
I0131 03:47:02.170622 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:47:02.170627 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000417613 (* 1 = 0.000417613 loss)
I0131 03:47:02.170635 25291 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0131 03:49:37.861716 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_4000.caffemodel
I0131 03:50:06.526017 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_4000.solverstate
>>> 2017-01-31 03:50:32.438299 Begin model classification tests
>>> 2017-01-31 03:53:23.385505 Iteration 4000 mean classification accuracy (rgb)  0.89673446004
>>> 2017-01-31 03:53:23.385544 Iteration 4000 mean classification accuracy (depth) 0.754225150387
>>> 2017-01-31 03:53:23.385556 Iteration 4000 mean classification accuracy (rgbd)  0.928816957892
>>> 2017-01-31 03:53:23.385565 Iteration 4000 mean testing loss (rgb) 0.444136720047
>>> 2017-01-31 03:53:23.385578 Iteration 4000 mean testing loss (depth) 1.5604965389
>>> 2017-01-31 03:53:23.385587 Iteration 4000 mean testing loss (rgbd) 0.276041506426
>>> 2017-01-31 03:53:23.385595 Iteration 4000 mean confusion matrix
[ 1.          0.13414634  1.          1.          1.          0.83850932
  1.          0.71304348  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.88819876  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98136646
  0.19736842  0.85802469  1.          0.84397163  0.9         0.98639456
  0.81081081  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 03:53:24.159875 25291 solver.cpp:228] Iteration 4000, loss = 0.0180398
I0131 03:53:24.159948 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:53:24.159975 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0178917 (* 1 = 0.0178917 loss)
I0131 03:53:24.159991 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:53:24.160006 25291 solver.cpp:244]     Train net output #3: rgb_loss = 9.2951e-06 (* 1 = 9.2951e-06 loss)
I0131 03:53:24.160019 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:53:24.160032 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000138798 (* 1 = 0.000138798 loss)
I0131 03:53:24.160046 25291 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0131 03:56:11.224215 25291 solver.cpp:228] Iteration 4100, loss = 0.00873288
I0131 03:56:11.224252 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 03:56:11.224262 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0253533 (* 1 = 0.0253533 loss)
I0131 03:56:11.224268 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 03:56:11.224277 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.48615e-05 (* 1 = 1.48615e-05 loss)
I0131 03:56:11.224282 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 03:56:11.224288 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000380591 (* 1 = 0.000380591 loss)
I0131 03:56:11.224295 25291 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
>>> 2017-01-31 03:58:40.078890 Begin model classification tests
>>> 2017-01-31 04:01:33.395045 Iteration 4200 mean classification accuracy (rgb)  0.896448009166
>>> 2017-01-31 04:01:33.395089 Iteration 4200 mean classification accuracy (depth) 0.753222572329
>>> 2017-01-31 04:01:33.395098 Iteration 4200 mean classification accuracy (rgbd)  0.928244056144
>>> 2017-01-31 04:01:33.395108 Iteration 4200 mean testing loss (rgb) 0.444328875229
>>> 2017-01-31 04:01:33.395127 Iteration 4200 mean testing loss (depth) 1.58098112933
>>> 2017-01-31 04:01:33.395143 Iteration 4200 mean testing loss (rgbd) 0.277495309608
>>> 2017-01-31 04:01:33.395159 Iteration 4200 mean confusion matrix
[ 1.          0.12195122  1.          1.          1.          0.85093168
  1.          0.72173913  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.88819876  1.          1.          1.          1.          1.
  0.82394366  1.          1.          1.          1.          0.97515528
  0.19736842  0.85802469  1.          0.83687943  0.90714286  0.98639456
  0.76576577  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 04:01:33.997406 25291 solver.cpp:228] Iteration 4200, loss = 0.00064959
I0131 04:01:33.997452 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:01:33.997469 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00046164 (* 1 = 0.00046164 loss)
I0131 04:01:33.997481 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:01:33.997494 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.34749e-06 (* 1 = 4.34749e-06 loss)
I0131 04:01:33.997505 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:01:33.997516 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000183602 (* 1 = 0.000183602 loss)
I0131 04:01:33.997527 25291 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0131 04:03:44.591817 25291 solver.cpp:228] Iteration 4300, loss = 0.00865667
I0131 04:03:44.591858 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 04:03:44.591879 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0441051 (* 1 = 0.0441051 loss)
I0131 04:03:44.591888 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:03:44.591899 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.76254e-05 (* 1 = 3.76254e-05 loss)
I0131 04:03:44.591912 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:03:44.591924 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000365718 (* 1 = 0.000365718 loss)
I0131 04:03:44.591938 25291 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
>>> 2017-01-31 04:06:10.914088 Begin model classification tests
>>> 2017-01-31 04:09:03.059813 Iteration 4400 mean classification accuracy (rgb)  0.896161558293
>>> 2017-01-31 04:09:03.059853 Iteration 4400 mean classification accuracy (depth) 0.754798052134
>>> 2017-01-31 04:09:03.059862 Iteration 4400 mean classification accuracy (rgbd)  0.928244056144
>>> 2017-01-31 04:09:03.059871 Iteration 4400 mean testing loss (rgb) 0.444541416628
>>> 2017-01-31 04:09:03.059889 Iteration 4400 mean testing loss (depth) 1.59961586164
>>> 2017-01-31 04:09:03.059903 Iteration 4400 mean testing loss (rgbd) 0.277034351901
>>> 2017-01-31 04:09:03.059919 Iteration 4400 mean confusion matrix
[ 1.          0.13414634  1.          1.          1.          0.88819876
  1.          0.65217391  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.88198758  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.97515528
  0.20394737  0.86419753  1.          0.85106383  0.90714286  0.98639456
  0.74774775  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 04:09:06.175389 25291 solver.cpp:228] Iteration 4400, loss = 0.0035593
I0131 04:09:06.175437 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:09:06.175459 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00337986 (* 1 = 0.00337986 loss)
I0131 04:09:06.175470 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:09:06.175487 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.11416e-05 (* 1 = 2.11416e-05 loss)
I0131 04:09:06.175498 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:09:06.175511 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000158303 (* 1 = 0.000158303 loss)
I0131 04:09:06.175524 25291 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0131 04:11:07.149427 25291 solver.cpp:228] Iteration 4500, loss = 0.00780114
I0131 04:11:07.149469 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:11:07.149489 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0011252 (* 1 = 0.0011252 loss)
I0131 04:11:07.149500 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:11:07.149513 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.92983e-06 (* 1 = 8.92983e-06 loss)
I0131 04:11:07.149526 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:11:07.149540 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 8.84137e-05 (* 1 = 8.84137e-05 loss)
I0131 04:11:07.149554 25291 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
>>> 2017-01-31 04:12:58.515503 Begin model classification tests
>>> 2017-01-31 04:15:50.651527 Iteration 4600 mean classification accuracy (rgb)  0.898596390719
>>> 2017-01-31 04:15:50.651572 Iteration 4600 mean classification accuracy (depth) 0.753365797766
>>> 2017-01-31 04:15:50.651582 Iteration 4600 mean classification accuracy (rgbd)  0.925093096534
>>> 2017-01-31 04:15:50.651593 Iteration 4600 mean testing loss (rgb) 0.44389412104
>>> 2017-01-31 04:15:50.651605 Iteration 4600 mean testing loss (depth) 1.59829025172
>>> 2017-01-31 04:15:50.651613 Iteration 4600 mean testing loss (rgbd) 0.28523590014
>>> 2017-01-31 04:15:50.651620 Iteration 4600 mean confusion matrix
[ 1.          0.10365854  1.          1.          1.          0.72670807
  1.          0.68695652  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.89440994  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.20394737  0.86419753  1.          0.87234043  0.9         0.98639456
  0.73873874  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 04:15:55.365434 25291 solver.cpp:228] Iteration 4600, loss = 0.00679222
I0131 04:15:55.365483 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:15:55.365499 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00662265 (* 1 = 0.00662265 loss)
I0131 04:15:55.365506 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:15:55.365516 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.67818e-05 (* 1 = 1.67818e-05 loss)
I0131 04:15:55.365525 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:15:55.365533 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000152785 (* 1 = 0.000152785 loss)
I0131 04:15:55.365545 25291 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0131 04:17:47.780761 25291 solver.cpp:228] Iteration 4700, loss = 0.00757557
I0131 04:17:47.780841 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:17:47.780861 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000414609 (* 1 = 0.000414609 loss)
I0131 04:17:47.780874 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:17:47.780884 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.28594e-05 (* 1 = 2.28594e-05 loss)
I0131 04:17:47.780894 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:17:47.780903 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000465308 (* 1 = 0.000465308 loss)
I0131 04:17:47.780916 25291 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
>>> 2017-01-31 04:19:39.690198 Begin model classification tests
>>> 2017-01-31 04:22:33.393554 Iteration 4800 mean classification accuracy (rgb)  0.897880263535
>>> 2017-01-31 04:22:33.393596 Iteration 4800 mean classification accuracy (depth) 0.75179031796
>>> 2017-01-31 04:22:33.393611 Iteration 4800 mean classification accuracy (rgbd)  0.924663420223
>>> 2017-01-31 04:22:33.393620 Iteration 4800 mean testing loss (rgb) 0.457082489711
>>> 2017-01-31 04:22:33.393631 Iteration 4800 mean testing loss (depth) 1.60051189559
>>> 2017-01-31 04:22:33.393641 Iteration 4800 mean testing loss (rgbd) 0.286796823526
>>> 2017-01-31 04:22:33.393649 Iteration 4800 mean confusion matrix
[ 1.          0.10365854  1.          1.          1.          0.73291925
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.89440994  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19736842  0.86419753  1.          0.85815603  0.90714286  0.97959184
  0.72972973  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 04:22:34.300163 25291 solver.cpp:228] Iteration 4800, loss = 0.00112575
I0131 04:22:34.300205 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:22:34.300221 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00102837 (* 1 = 0.00102837 loss)
I0131 04:22:34.300227 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:22:34.300235 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.38823e-05 (* 1 = 3.38823e-05 loss)
I0131 04:22:34.300240 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:22:34.300247 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.34967e-05 (* 1 = 6.34967e-05 loss)
I0131 04:22:34.300256 25291 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0131 04:24:59.421052 25291 solver.cpp:228] Iteration 4900, loss = 0.0082014
I0131 04:24:59.421092 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:24:59.421108 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00336623 (* 1 = 0.00336623 loss)
I0131 04:24:59.421116 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:24:59.421125 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.24052e-05 (* 1 = 8.24052e-05 loss)
I0131 04:24:59.421133 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:24:59.421141 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.53495e-05 (* 1 = 4.53495e-05 loss)
I0131 04:24:59.421151 25291 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0131 04:26:53.427031 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_5000.caffemodel
I0131 04:28:03.102960 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_5000.solverstate
>>> 2017-01-31 04:28:33.580209 Begin model classification tests
>>> 2017-01-31 04:31:25.038147 Iteration 5000 mean classification accuracy (rgb)  0.898023488972
>>> 2017-01-31 04:31:25.038196 Iteration 5000 mean classification accuracy (depth) 0.750214838155
>>> 2017-01-31 04:31:25.038213 Iteration 5000 mean classification accuracy (rgbd)  0.925665998281
>>> 2017-01-31 04:31:25.038229 Iteration 5000 mean testing loss (rgb) 0.45341590754
>>> 2017-01-31 04:31:25.038256 Iteration 5000 mean testing loss (depth) 1.62549152725
>>> 2017-01-31 04:31:25.038274 Iteration 5000 mean testing loss (rgbd) 0.288776961128
>>> 2017-01-31 04:31:25.038290 Iteration 5000 mean confusion matrix
[ 1.          0.1097561   1.          1.          1.          0.7826087   1.
  0.69565217  0.9047619   1.          1.          1.          0.72972973
  1.          1.          1.          1.          1.          1.
  0.88819876  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98136646
  0.19078947  0.86419753  1.          0.85106383  0.90714286  0.97959184
  0.75675676  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 04:31:28.540652 25291 solver.cpp:228] Iteration 5000, loss = 0.00876844
I0131 04:31:28.540691 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:31:28.540701 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0082204 (* 1 = 0.0082204 loss)
I0131 04:31:28.540709 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:31:28.540720 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000487119 (* 1 = 0.000487119 loss)
I0131 04:31:28.540730 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:31:28.540741 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.09123e-05 (* 1 = 6.09123e-05 loss)
I0131 04:31:28.540753 25291 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0131 04:34:23.124642 25291 solver.cpp:228] Iteration 5100, loss = 0.00894232
I0131 04:34:23.124691 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:34:23.124709 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00872813 (* 1 = 0.00872813 loss)
I0131 04:34:23.124718 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:34:23.124728 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.6609e-05 (* 1 = 2.6609e-05 loss)
I0131 04:34:23.124737 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:34:23.124745 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000151022 (* 1 = 0.000151022 loss)
I0131 04:34:23.124754 25291 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
>>> 2017-01-31 04:36:56.244508 Begin model classification tests
>>> 2017-01-31 04:39:50.073773 Iteration 5200 mean classification accuracy (rgb)  0.895875107419
>>> 2017-01-31 04:39:50.073874 Iteration 5200 mean classification accuracy (depth) 0.746920653108
>>> 2017-01-31 04:39:50.073909 Iteration 5200 mean classification accuracy (rgbd)  0.925379547408
>>> 2017-01-31 04:39:50.073994 Iteration 5200 mean testing loss (rgb) 0.459448312844
>>> 2017-01-31 04:39:50.074033 Iteration 5200 mean testing loss (depth) 1.64566652553
>>> 2017-01-31 04:39:50.074066 Iteration 5200 mean testing loss (rgbd) 0.288719413845
>>> 2017-01-31 04:39:50.074099 Iteration 5200 mean confusion matrix
[ 1.          0.12195122  1.          1.          1.          0.78881988
  1.          0.69565217  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.86335404  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98136646
  0.19736842  0.85185185  1.          0.86524823  0.9         0.97959184
  0.74774775  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 04:39:55.670002 25291 solver.cpp:228] Iteration 5200, loss = 0.0654315
I0131 04:39:55.670042 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 04:39:55.670059 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0652373 (* 1 = 0.0652373 loss)
I0131 04:39:55.670069 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:39:55.670083 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.97344e-06 (* 1 = 4.97344e-06 loss)
I0131 04:39:55.670094 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:39:55.670105 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000189178 (* 1 = 0.000189178 loss)
I0131 04:39:55.670117 25291 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0131 04:42:48.001914 25291 solver.cpp:228] Iteration 5300, loss = 0.00803948
I0131 04:42:48.002027 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:42:48.002081 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00087645 (* 1 = 0.00087645 loss)
I0131 04:42:48.002110 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:42:48.002145 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.44624e-05 (* 1 = 1.44624e-05 loss)
I0131 04:42:48.002176 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:42:48.002213 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.48988e-05 (* 1 = 3.48988e-05 loss)
I0131 04:42:48.002291 25291 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
>>> 2017-01-31 04:45:11.346981 Begin model classification tests
>>> 2017-01-31 04:48:05.417592 Iteration 5400 mean classification accuracy (rgb)  0.896877685477
>>> 2017-01-31 04:48:05.417632 Iteration 5400 mean classification accuracy (depth) 0.749928387282
>>> 2017-01-31 04:48:05.417641 Iteration 5400 mean classification accuracy (rgbd)  0.925665998281
>>> 2017-01-31 04:48:05.417650 Iteration 5400 mean testing loss (rgb) 0.457360406407
>>> 2017-01-31 04:48:05.417660 Iteration 5400 mean testing loss (depth) 1.63304301807
>>> 2017-01-31 04:48:05.417667 Iteration 5400 mean testing loss (rgbd) 0.282550131766
>>> 2017-01-31 04:48:05.417674 Iteration 5400 mean confusion matrix
[ 1.          0.12195122  1.          1.          1.          0.7826087   1.
  0.69565217  0.9047619   1.          1.          1.          0.73873874
  1.          1.          1.          1.          1.          1.          0.8757764
  1.          1.          1.          1.          1.          0.83098592
  1.          1.          1.          1.          0.98136646  0.20394737
  0.83950617  1.          0.92907801  0.86428571  0.97278912  0.71171171
  1.          0.95535714  1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.        ]
I0131 04:48:06.378468 25291 solver.cpp:228] Iteration 5400, loss = 0.00175067
I0131 04:48:06.378566 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:48:06.378610 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00135959 (* 1 = 0.00135959 loss)
I0131 04:48:06.378671 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:48:06.378706 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.39036e-05 (* 1 = 1.39036e-05 loss)
I0131 04:48:06.378736 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:48:06.378764 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000377175 (* 1 = 0.000377175 loss)
I0131 04:48:06.378792 25291 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0131 04:49:55.210008 25291 solver.cpp:228] Iteration 5500, loss = 0.00686427
I0131 04:49:55.210059 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:49:55.210078 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00191676 (* 1 = 0.00191676 loss)
I0131 04:49:55.210088 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:49:55.210098 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.36931e-06 (* 1 = 2.36931e-06 loss)
I0131 04:49:55.210106 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:49:55.210124 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.69469e-05 (* 1 = 7.69469e-05 loss)
I0131 04:49:55.210135 25291 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
>>> 2017-01-31 04:52:05.430083 Begin model classification tests
>>> 2017-01-31 04:54:57.583616 Iteration 5600 mean classification accuracy (rgb)  0.897593812661
>>> 2017-01-31 04:54:57.583681 Iteration 5600 mean classification accuracy (depth) 0.750214838155
>>> 2017-01-31 04:54:57.583700 Iteration 5600 mean classification accuracy (rgbd)  0.925952449155
>>> 2017-01-31 04:54:57.583713 Iteration 5600 mean testing loss (rgb) 0.451463027552
>>> 2017-01-31 04:54:57.583734 Iteration 5600 mean testing loss (depth) 1.63716828864
>>> 2017-01-31 04:54:57.583749 Iteration 5600 mean testing loss (rgbd) 0.273419055856
>>> 2017-01-31 04:54:57.583764 Iteration 5600 mean confusion matrix
[ 1.          0.17682927  1.          1.          1.          0.73913043
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.88819876  1.          1.          1.          1.          1.
  0.83098592  1.          1.          1.          1.          0.98136646
  0.20394737  0.84567901  1.          0.90780142  0.87857143  0.97278912
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 04:54:58.191808 25291 solver.cpp:228] Iteration 5600, loss = 0.0001696
I0131 04:54:58.191851 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:54:58.191861 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000138911 (* 1 = 0.000138911 loss)
I0131 04:54:58.191869 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:54:58.191875 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.13995e-06 (* 1 = 1.13995e-06 loss)
I0131 04:54:58.191880 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:54:58.191885 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.95488e-05 (* 1 = 2.95488e-05 loss)
I0131 04:54:58.191893 25291 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0131 04:56:59.538518 25291 solver.cpp:228] Iteration 5700, loss = 0.00589895
I0131 04:56:59.538558 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 04:56:59.538573 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00808029 (* 1 = 0.00808029 loss)
I0131 04:56:59.538585 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 04:56:59.538599 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.41935e-06 (* 1 = 1.41935e-06 loss)
I0131 04:56:59.538611 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 04:56:59.538621 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.64754e-05 (* 1 = 3.64754e-05 loss)
I0131 04:56:59.538631 25291 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
>>> 2017-01-31 04:59:11.537616 Begin model classification tests
>>> 2017-01-31 05:02:10.260653 Iteration 5800 mean classification accuracy (rgb)  0.898166714408
>>> 2017-01-31 05:02:10.260699 Iteration 5800 mean classification accuracy (depth) 0.753938699513
>>> 2017-01-31 05:02:10.260720 Iteration 5800 mean classification accuracy (rgbd)  0.927671154397
>>> 2017-01-31 05:02:10.260736 Iteration 5800 mean testing loss (rgb) 0.449070049485
>>> 2017-01-31 05:02:10.260759 Iteration 5800 mean testing loss (depth) 1.60361686849
>>> 2017-01-31 05:02:10.260778 Iteration 5800 mean testing loss (rgbd) 0.268075693795
>>> 2017-01-31 05:02:10.260795 Iteration 5800 mean confusion matrix
[ 1.          0.18902439  1.          1.          1.          0.76397516
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.88819876  1.          1.          1.          1.          1.
  0.83098592  1.          1.          1.          1.          0.98136646
  0.20394737  0.88271605  1.          0.90780142  0.87857143  0.97278912
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:02:10.875365 25291 solver.cpp:228] Iteration 5800, loss = 0.00281271
I0131 05:02:10.875429 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:02:10.875461 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00258271 (* 1 = 0.00258271 loss)
I0131 05:02:10.875480 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:02:10.875507 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.92816e-05 (* 1 = 1.92816e-05 loss)
I0131 05:02:10.875525 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:02:10.875548 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000210722 (* 1 = 0.000210722 loss)
I0131 05:02:10.875568 25291 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0131 05:03:59.567443 25291 solver.cpp:228] Iteration 5900, loss = 0.00681027
I0131 05:03:59.567518 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:03:59.567553 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0210976 (* 1 = 0.0210976 loss)
I0131 05:03:59.567569 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:03:59.567590 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.79849e-05 (* 1 = 1.79849e-05 loss)
I0131 05:03:59.567602 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:03:59.567617 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.16329e-05 (* 1 = 7.16329e-05 loss)
I0131 05:03:59.567631 25291 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
I0131 05:05:37.886528 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_6000.caffemodel
I0131 05:07:01.213492 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_6000.solverstate
>>> 2017-01-31 05:07:19.985206 Begin model classification tests
>>> 2017-01-31 05:10:11.023954 Iteration 6000 mean classification accuracy (rgb)  0.896591234603
>>> 2017-01-31 05:10:11.023991 Iteration 6000 mean classification accuracy (depth) 0.750501289029
>>> 2017-01-31 05:10:11.024004 Iteration 6000 mean classification accuracy (rgbd)  0.928673732455
>>> 2017-01-31 05:10:11.024013 Iteration 6000 mean testing loss (rgb) 0.451057505405
>>> 2017-01-31 05:10:11.024024 Iteration 6000 mean testing loss (depth) 1.61385296397
>>> 2017-01-31 05:10:11.024033 Iteration 6000 mean testing loss (rgbd) 0.269418095668
>>> 2017-01-31 05:10:11.024041 Iteration 6000 mean confusion matrix
[ 1.          0.18292683  1.          1.          1.          0.80124224
  1.          0.70434783  0.9047619   1.          1.          1.
  0.73873874  1.          1.          1.          1.          1.          1.
  0.89440994  1.          1.          1.          1.          1.
  0.83098592  1.          1.          1.          1.          0.98136646
  0.20394737  0.87037037  1.          0.90780142  0.9         0.96598639
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:10:12.640517 25291 solver.cpp:228] Iteration 6000, loss = 0.000554091
I0131 05:10:12.640559 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:10:12.640580 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000408689 (* 1 = 0.000408689 loss)
I0131 05:10:12.640588 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:10:12.640599 25291 solver.cpp:244]     Train net output #3: rgb_loss = 9.51845e-05 (* 1 = 9.51845e-05 loss)
I0131 05:10:12.640609 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:10:12.640619 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 5.02179e-05 (* 1 = 5.02179e-05 loss)
I0131 05:10:12.640630 25291 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0131 05:12:00.592314 25291 solver.cpp:228] Iteration 6100, loss = 0.00697771
I0131 05:12:00.592353 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:12:00.592368 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00397264 (* 1 = 0.00397264 loss)
I0131 05:12:00.592376 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:12:00.592384 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.35554e-06 (* 1 = 6.35554e-06 loss)
I0131 05:12:00.592389 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:12:00.592396 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.27138e-05 (* 1 = 4.27138e-05 loss)
I0131 05:12:00.592404 25291 sgd_solver.cpp:106] Iteration 6100, lr = 0.001
>>> 2017-01-31 05:13:25.429951 Begin model classification tests
>>> 2017-01-31 05:16:17.515845 Iteration 6200 mean classification accuracy (rgb)  0.896018332856
>>> 2017-01-31 05:16:17.515905 Iteration 6200 mean classification accuracy (depth) 0.751933543397
>>> 2017-01-31 05:16:17.515926 Iteration 6200 mean classification accuracy (rgbd)  0.928960183329
>>> 2017-01-31 05:16:17.515943 Iteration 6200 mean testing loss (rgb) 0.452067637596
>>> 2017-01-31 05:16:17.515964 Iteration 6200 mean testing loss (depth) 1.62887349161
>>> 2017-01-31 05:16:17.515981 Iteration 6200 mean testing loss (rgbd) 0.270225576846
>>> 2017-01-31 05:16:17.515997 Iteration 6200 mean confusion matrix
[ 1.          0.17682927  1.          1.          1.          0.82608696
  1.          0.71304348  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.90062112  1.          1.          1.          1.          1.
  0.83098592  1.          1.          1.          1.          0.98136646
  0.20394737  0.88888889  1.          0.87943262  0.88571429  0.96598639
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:16:18.639082 25291 solver.cpp:228] Iteration 6200, loss = 0.00179292
I0131 05:16:18.639169 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:16:18.639207 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00107186 (* 1 = 0.00107186 loss)
I0131 05:16:18.639225 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:16:18.639242 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.44448e-05 (* 1 = 1.44448e-05 loss)
I0131 05:16:18.639252 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:16:18.639266 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000706611 (* 1 = 0.000706611 loss)
I0131 05:16:18.639277 25291 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0131 05:18:00.762470 25291 solver.cpp:228] Iteration 6300, loss = 0.00614228
I0131 05:18:00.762508 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:18:00.762529 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0039503 (* 1 = 0.0039503 loss)
I0131 05:18:00.762539 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:18:00.762552 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.23903e-05 (* 1 = 8.23903e-05 loss)
I0131 05:18:00.762562 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:18:00.762570 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.42818e-05 (* 1 = 3.42818e-05 loss)
I0131 05:18:00.762580 25291 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
>>> 2017-01-31 05:19:53.219881 Begin model classification tests
>>> 2017-01-31 05:22:46.304196 Iteration 6400 mean classification accuracy (rgb)  0.895302205672
>>> 2017-01-31 05:22:46.304238 Iteration 6400 mean classification accuracy (depth) 0.752363219708
>>> 2017-01-31 05:22:46.304248 Iteration 6400 mean classification accuracy (rgbd)  0.928960183329
>>> 2017-01-31 05:22:46.304258 Iteration 6400 mean testing loss (rgb) 0.455138981421
>>> 2017-01-31 05:22:46.304269 Iteration 6400 mean testing loss (depth) 1.63816069787
>>> 2017-01-31 05:22:46.304276 Iteration 6400 mean testing loss (rgbd) 0.271744385739
>>> 2017-01-31 05:22:46.304285 Iteration 6400 mean confusion matrix
[ 1.          0.17682927  1.          1.          1.          0.83850932
  1.          0.71304348  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.91925466  1.          1.          1.          1.          1.
  0.83098592  1.          1.          1.          1.          0.98136646
  0.21052632  0.86419753  1.          0.87943262  0.9         0.95238095
  0.66666667  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:22:46.884994 25291 solver.cpp:228] Iteration 6400, loss = 0.000258226
I0131 05:22:46.885031 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:22:46.885046 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000220459 (* 1 = 0.000220459 loss)
I0131 05:22:46.885053 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:22:46.885061 25291 solver.cpp:244]     Train net output #3: rgb_loss = 7.39144e-06 (* 1 = 7.39144e-06 loss)
I0131 05:22:46.885066 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:22:46.885072 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.03758e-05 (* 1 = 3.03758e-05 loss)
I0131 05:22:46.885080 25291 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0131 05:24:24.107482 25291 solver.cpp:228] Iteration 6500, loss = 0.0076658
I0131 05:24:24.107547 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:24:24.107573 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00345145 (* 1 = 0.00345145 loss)
I0131 05:24:24.107585 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:24:24.107596 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.00010375 (* 1 = 0.00010375 loss)
I0131 05:24:24.107606 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:24:24.107616 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.18827e-05 (* 1 = 6.18827e-05 loss)
I0131 05:24:24.107630 25291 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
>>> 2017-01-31 05:25:47.919945 Begin model classification tests
>>> 2017-01-31 05:28:38.513936 Iteration 6600 mean classification accuracy (rgb)  0.897020910914
>>> 2017-01-31 05:28:38.514002 Iteration 6600 mean classification accuracy (depth) 0.750501289029
>>> 2017-01-31 05:28:38.514011 Iteration 6600 mean classification accuracy (rgbd)  0.927814379834
>>> 2017-01-31 05:28:38.514019 Iteration 6600 mean testing loss (rgb) 0.445197654199
>>> 2017-01-31 05:28:38.514031 Iteration 6600 mean testing loss (depth) 1.61647469939
>>> 2017-01-31 05:28:38.514039 Iteration 6600 mean testing loss (rgbd) 0.274302183951
>>> 2017-01-31 05:28:38.514047 Iteration 6600 mean confusion matrix
[ 1.          0.17073171  1.          1.          1.          0.81987578
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.91925466  1.          1.          1.          1.          1.
  0.83098592  1.          1.          1.          1.          0.98136646
  0.21052632  0.87037037  1.          0.87943262  0.88571429  0.95918367
  0.64864865  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:28:39.098244 25291 solver.cpp:228] Iteration 6600, loss = 0.0578161
I0131 05:28:39.098281 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 05:28:39.098291 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0577046 (* 1 = 0.0577046 loss)
I0131 05:28:39.098299 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:28:39.098305 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.69821e-05 (* 1 = 1.69821e-05 loss)
I0131 05:28:39.098310 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:28:39.098316 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 9.44726e-05 (* 1 = 9.44726e-05 loss)
I0131 05:28:39.098322 25291 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0131 05:30:16.882227 25291 solver.cpp:228] Iteration 6700, loss = 0.00784626
I0131 05:30:16.882274 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:30:16.882284 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00258994 (* 1 = 0.00258994 loss)
I0131 05:30:16.882292 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:30:16.882297 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.50045e-05 (* 1 = 2.50045e-05 loss)
I0131 05:30:16.882302 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:30:16.882308 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00015096 (* 1 = 0.00015096 loss)
I0131 05:30:16.882314 25291 sgd_solver.cpp:106] Iteration 6700, lr = 0.001
>>> 2017-01-31 05:31:32.390907 Begin model classification tests
>>> 2017-01-31 05:34:28.324664 Iteration 6800 mean classification accuracy (rgb)  0.896448009166
>>> 2017-01-31 05:34:28.324714 Iteration 6800 mean classification accuracy (depth) 0.755943855629
>>> 2017-01-31 05:34:28.324731 Iteration 6800 mean classification accuracy (rgbd)  0.928960183329
>>> 2017-01-31 05:34:28.324741 Iteration 6800 mean testing loss (rgb) 0.446404259766
>>> 2017-01-31 05:34:28.324754 Iteration 6800 mean testing loss (depth) 1.60211611046
>>> 2017-01-31 05:34:28.324765 Iteration 6800 mean testing loss (rgbd) 0.270498633334
>>> 2017-01-31 05:34:28.324774 Iteration 6800 mean confusion matrix
[ 1.          0.19512195  1.          1.          1.          0.83229814
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.91925466  1.          1.          1.          1.          1.
  0.83098592  1.          1.          1.          1.          0.98136646
  0.20394737  0.87037037  1.          0.87943262  0.89285714  0.95238095
  0.67567568  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:34:28.902482 25291 solver.cpp:228] Iteration 6800, loss = 0.00860593
I0131 05:34:28.902528 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:34:28.902544 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00835408 (* 1 = 0.00835408 loss)
I0131 05:34:28.902552 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:34:28.902560 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.32636e-05 (* 1 = 5.32636e-05 loss)
I0131 05:34:28.902567 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:34:28.902575 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000198593 (* 1 = 0.000198593 loss)
I0131 05:34:28.902583 25291 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0131 05:35:46.100097 25291 solver.cpp:228] Iteration 6900, loss = 0.00992687
I0131 05:35:46.100150 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:35:46.100174 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00950106 (* 1 = 0.00950106 loss)
I0131 05:35:46.100185 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:35:46.100198 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.66035e-05 (* 1 = 4.66035e-05 loss)
I0131 05:35:46.100208 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:35:46.100219 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.84664e-05 (* 1 = 7.84664e-05 loss)
I0131 05:35:46.100230 25291 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
I0131 05:37:06.484983 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_7000.caffemodel
I0131 05:38:05.803737 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_7000.solverstate
>>> 2017-01-31 05:38:21.540449 Begin model classification tests
>>> 2017-01-31 05:41:11.596588 Iteration 7000 mean classification accuracy (rgb)  0.89902606703
>>> 2017-01-31 05:41:11.596644 Iteration 7000 mean classification accuracy (depth) 0.749785161845
>>> 2017-01-31 05:41:11.596664 Iteration 7000 mean classification accuracy (rgbd)  0.929246634202
>>> 2017-01-31 05:41:11.596680 Iteration 7000 mean testing loss (rgb) 0.441140805134
>>> 2017-01-31 05:41:11.596701 Iteration 7000 mean testing loss (depth) 1.63912398322
>>> 2017-01-31 05:41:11.596715 Iteration 7000 mean testing loss (rgbd) 0.273754265741
>>> 2017-01-31 05:41:11.596728 Iteration 7000 mean confusion matrix
[ 1.          0.18902439  1.          1.          1.          0.83850932
  1.          0.70434783  0.9047619   1.          1.          1.
  0.73873874  1.          1.          1.          1.          1.          1.
  0.91925466  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          1.
  0.19736842  0.87037037  1.          0.87943262  0.9         0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:41:13.691542 25291 solver.cpp:228] Iteration 7000, loss = 0.0126592
I0131 05:41:13.691579 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:41:13.691596 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0121652 (* 1 = 0.0121652 loss)
I0131 05:41:13.691603 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:41:13.691612 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.49675e-05 (* 1 = 1.49675e-05 loss)
I0131 05:41:13.691617 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:41:13.691625 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000479103 (* 1 = 0.000479103 loss)
I0131 05:41:13.691635 25291 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0131 05:42:49.743796 25291 solver.cpp:228] Iteration 7100, loss = 0.00838255
I0131 05:42:49.743835 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:42:49.743860 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00958143 (* 1 = 0.00958143 loss)
I0131 05:42:49.743866 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:42:49.743875 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.85912e-05 (* 1 = 1.85912e-05 loss)
I0131 05:42:49.743881 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:42:49.743888 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.55461e-05 (* 1 = 3.55461e-05 loss)
I0131 05:42:49.743896 25291 sgd_solver.cpp:106] Iteration 7100, lr = 0.001
>>> 2017-01-31 05:44:29.763956 Begin model classification tests
>>> 2017-01-31 05:47:21.550751 Iteration 7200 mean classification accuracy (rgb)  0.898596390719
>>> 2017-01-31 05:47:21.550802 Iteration 7200 mean classification accuracy (depth) 0.750644514466
>>> 2017-01-31 05:47:21.550817 Iteration 7200 mean classification accuracy (rgbd)  0.930392437697
>>> 2017-01-31 05:47:21.550828 Iteration 7200 mean testing loss (rgb) 0.440984344276
>>> 2017-01-31 05:47:21.550846 Iteration 7200 mean testing loss (depth) 1.63460440292
>>> 2017-01-31 05:47:21.550859 Iteration 7200 mean testing loss (rgbd) 0.270527595309
>>> 2017-01-31 05:47:21.550872 Iteration 7200 mean confusion matrix
[ 1.          0.18902439  1.          1.          1.          0.83850932
  1.          0.72173913  0.9047619   1.          1.          1.
  0.74774775  1.          1.          1.          1.          1.          1.
  0.91925466  1.          1.          1.          1.          1.
  0.83098592  1.          1.          1.          1.          1.
  0.19078947  0.87037037  1.          0.87234043  0.9         0.94557823
  0.73873874  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:47:22.143744 25291 solver.cpp:228] Iteration 7200, loss = 0.0065257
I0131 05:47:22.143784 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:47:22.143793 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00628787 (* 1 = 0.00628787 loss)
I0131 05:47:22.143800 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:47:22.143806 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.63212e-05 (* 1 = 1.63212e-05 loss)
I0131 05:47:22.143812 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:47:22.143817 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000221512 (* 1 = 0.000221512 loss)
I0131 05:47:22.143824 25291 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0131 05:48:24.307168 25291 solver.cpp:228] Iteration 7300, loss = 0.00529301
I0131 05:48:24.307205 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:48:24.307215 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00584757 (* 1 = 0.00584757 loss)
I0131 05:48:24.307222 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:48:24.307229 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.84832e-06 (* 1 = 3.84832e-06 loss)
I0131 05:48:24.307234 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:48:24.307240 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.61126e-05 (* 1 = 2.61126e-05 loss)
I0131 05:48:24.307246 25291 sgd_solver.cpp:106] Iteration 7300, lr = 0.001
>>> 2017-01-31 05:49:29.649827 Begin model classification tests
>>> 2017-01-31 05:52:30.227498 Iteration 7400 mean classification accuracy (rgb)  0.898882841593
>>> 2017-01-31 05:52:30.227539 Iteration 7400 mean classification accuracy (depth) 0.749928387282
>>> 2017-01-31 05:52:30.227548 Iteration 7400 mean classification accuracy (rgbd)  0.929389859639
>>> 2017-01-31 05:52:30.227556 Iteration 7400 mean testing loss (rgb) 0.442126411263
>>> 2017-01-31 05:52:30.227567 Iteration 7400 mean testing loss (depth) 1.61736057103
>>> 2017-01-31 05:52:30.227574 Iteration 7400 mean testing loss (rgbd) 0.269539157792
>>> 2017-01-31 05:52:30.227582 Iteration 7400 mean confusion matrix
[ 1.          0.18902439  1.          1.          1.          0.83850932
  1.          0.72173913  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.91925466  1.          1.          1.          1.          1.
  0.82394366  1.          1.          1.          1.          1.
  0.19736842  0.87037037  1.          0.87234043  0.9         0.95238095
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:52:30.798141 25291 solver.cpp:228] Iteration 7400, loss = 0.00255053
I0131 05:52:30.798189 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:52:30.798205 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00242605 (* 1 = 0.00242605 loss)
I0131 05:52:30.798213 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:52:30.798223 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.87258e-05 (* 1 = 1.87258e-05 loss)
I0131 05:52:30.798229 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:52:30.798243 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000105759 (* 1 = 0.000105759 loss)
I0131 05:52:30.798255 25291 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0131 05:53:32.232038 25291 solver.cpp:228] Iteration 7500, loss = 0.00585804
I0131 05:53:32.232077 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:53:32.232087 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00157937 (* 1 = 0.00157937 loss)
I0131 05:53:32.232096 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:53:32.232102 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.58273e-05 (* 1 = 3.58273e-05 loss)
I0131 05:53:32.232107 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:53:32.232113 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00124725 (* 1 = 0.00124725 loss)
I0131 05:53:32.232120 25291 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
>>> 2017-01-31 05:54:33.388494 Begin model classification tests
>>> 2017-01-31 05:57:36.073667 Iteration 7600 mean classification accuracy (rgb)  0.89902606703
>>> 2017-01-31 05:57:36.073726 Iteration 7600 mean classification accuracy (depth) 0.752936121455
>>> 2017-01-31 05:57:36.073750 Iteration 7600 mean classification accuracy (rgbd)  0.93024921226
>>> 2017-01-31 05:57:36.073767 Iteration 7600 mean testing loss (rgb) 0.442343149893
>>> 2017-01-31 05:57:36.073791 Iteration 7600 mean testing loss (depth) 1.56942233386
>>> 2017-01-31 05:57:36.073808 Iteration 7600 mean testing loss (rgbd) 0.272375512591
>>> 2017-01-31 05:57:36.073823 Iteration 7600 mean confusion matrix
[ 1.          0.18292683  1.          1.          1.          0.83850932
  1.          0.71304348  0.9047619   1.          1.          1.
  0.73873874  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.82394366  1.          1.          1.          1.          0.99378882
  0.19736842  0.87037037  1.          0.87234043  0.9         0.95918367
  0.73873874  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 05:57:36.667981 25291 solver.cpp:228] Iteration 7600, loss = 0.00373238
I0131 05:57:36.668020 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:57:36.668030 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00346304 (* 1 = 0.00346304 loss)
I0131 05:57:36.668038 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:57:36.668045 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.64402e-05 (* 1 = 6.64402e-05 loss)
I0131 05:57:36.668051 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:57:36.668056 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000202903 (* 1 = 0.000202903 loss)
I0131 05:57:36.668063 25291 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0131 05:58:37.955632 25291 solver.cpp:228] Iteration 7700, loss = 0.00567611
I0131 05:58:37.955672 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 05:58:37.955684 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00930431 (* 1 = 0.00930431 loss)
I0131 05:58:37.955693 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 05:58:37.955699 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.55692e-05 (* 1 = 2.55692e-05 loss)
I0131 05:58:37.955705 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 05:58:37.955711 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 1.25176e-05 (* 1 = 1.25176e-05 loss)
I0131 05:58:37.955718 25291 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
>>> 2017-01-31 05:59:39.564121 Begin model classification tests
>>> 2017-01-31 06:02:44.422269 Iteration 7800 mean classification accuracy (rgb)  0.89902606703
>>> 2017-01-31 06:02:44.422328 Iteration 7800 mean classification accuracy (depth) 0.752792896018
>>> 2017-01-31 06:02:44.422359 Iteration 7800 mean classification accuracy (rgbd)  0.929246634202
>>> 2017-01-31 06:02:44.422381 Iteration 7800 mean testing loss (rgb) 0.442605920273
>>> 2017-01-31 06:02:44.422408 Iteration 7800 mean testing loss (depth) 1.59569628132
>>> 2017-01-31 06:02:44.422423 Iteration 7800 mean testing loss (rgbd) 0.274191611285
>>> 2017-01-31 06:02:44.422440 Iteration 7800 mean confusion matrix
[ 1.          0.17682927  1.          1.          1.          0.7826087   1.
  0.71304348  0.9047619   1.          1.          1.          0.72972973
  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.82394366  1.          1.          1.          1.          0.98757764
  0.19736842  0.87654321  1.          0.87234043  0.9         0.97959184
  0.74774775  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:02:45.019021 25291 solver.cpp:228] Iteration 7800, loss = 0.00158511
I0131 06:02:45.019088 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:02:45.019132 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00157408 (* 1 = 0.00157408 loss)
I0131 06:02:45.019160 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:02:45.019196 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.87431e-07 (* 1 = 3.87431e-07 loss)
I0131 06:02:45.019227 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:02:45.019265 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 1.06434e-05 (* 1 = 1.06434e-05 loss)
I0131 06:02:45.019289 25291 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0131 06:03:52.511131 25291 solver.cpp:228] Iteration 7900, loss = 0.00715565
I0131 06:03:52.511200 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:03:52.511243 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00264791 (* 1 = 0.00264791 loss)
I0131 06:03:52.511265 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:03:52.511287 25291 solver.cpp:244]     Train net output #3: rgb_loss = 7.28693e-06 (* 1 = 7.28693e-06 loss)
I0131 06:03:52.511304 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:03:52.511327 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.57884e-05 (* 1 = 6.57884e-05 loss)
I0131 06:03:52.511355 25291 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
I0131 06:04:52.917407 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_8000.caffemodel
I0131 06:05:06.115862 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_8000.solverstate
>>> 2017-01-31 06:05:09.601008 Begin model classification tests
>>> 2017-01-31 06:08:04.560972 Iteration 8000 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 06:08:04.561017 Iteration 8000 mean classification accuracy (depth) 0.752792896018
>>> 2017-01-31 06:08:04.561034 Iteration 8000 mean classification accuracy (rgbd)  0.929103408765
>>> 2017-01-31 06:08:04.561045 Iteration 8000 mean testing loss (rgb) 0.443619296744
>>> 2017-01-31 06:08:04.561059 Iteration 8000 mean testing loss (depth) 1.59633545221
>>> 2017-01-31 06:08:04.561069 Iteration 8000 mean testing loss (rgbd) 0.280075166924
>>> 2017-01-31 06:08:04.561077 Iteration 8000 mean confusion matrix
[ 1.          0.12195122  1.          1.          1.          0.81987578
  1.          0.72173913  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.82394366  1.          1.          1.          1.          0.99378882
  0.19078947  0.91358025  1.          0.87234043  0.89285714  0.96598639
  0.73873874  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:08:05.184731 25291 solver.cpp:228] Iteration 8000, loss = 0.000926455
I0131 06:08:05.184782 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:08:05.184805 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00074573 (* 1 = 0.00074573 loss)
I0131 06:08:05.184826 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:08:05.184847 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.94428e-06 (* 1 = 6.94428e-06 loss)
I0131 06:08:05.184864 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:08:05.184880 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00017378 (* 1 = 0.00017378 loss)
I0131 06:08:05.184895 25291 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0131 06:09:06.665791 25291 solver.cpp:228] Iteration 8100, loss = 0.00679513
I0131 06:09:06.665827 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:09:06.665841 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00945672 (* 1 = 0.00945672 loss)
I0131 06:09:06.665850 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:09:06.665861 25291 solver.cpp:244]     Train net output #3: rgb_loss = 7.991e-06 (* 1 = 7.991e-06 loss)
I0131 06:09:06.665871 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:09:06.665884 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 8.81029e-05 (* 1 = 8.81029e-05 loss)
I0131 06:09:06.665895 25291 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
>>> 2017-01-31 06:10:07.186588 Begin model classification tests
>>> 2017-01-31 06:13:00.695360 Iteration 8200 mean classification accuracy (rgb)  0.898596390719
>>> 2017-01-31 06:13:00.695437 Iteration 8200 mean classification accuracy (depth) 0.751217416213
>>> 2017-01-31 06:13:00.695477 Iteration 8200 mean classification accuracy (rgbd)  0.927384703523
>>> 2017-01-31 06:13:00.695512 Iteration 8200 mean testing loss (rgb) 0.448133229417
>>> 2017-01-31 06:13:00.695554 Iteration 8200 mean testing loss (depth) 1.59641743188
>>> 2017-01-31 06:13:00.695586 Iteration 8200 mean testing loss (rgbd) 0.28712325354
>>> 2017-01-31 06:13:00.695614 Iteration 8200 mean confusion matrix
[ 1.          0.10365854  1.          1.          1.          0.80745342
  1.          0.72173913  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.82394366  1.          1.          1.          1.          0.97515528
  0.18421053  0.91358025  1.          0.87234043  0.88571429  0.94557823
  0.74774775  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:13:01.340349 25291 solver.cpp:228] Iteration 8200, loss = 0.000464438
I0131 06:13:01.340414 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:13:01.340436 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000401137 (* 1 = 0.000401137 loss)
I0131 06:13:01.340447 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:13:01.340461 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.41951e-06 (* 1 = 8.41951e-06 loss)
I0131 06:13:01.340471 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:13:01.340482 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 5.48821e-05 (* 1 = 5.48821e-05 loss)
I0131 06:13:01.340495 25291 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0131 06:14:02.537134 25291 solver.cpp:228] Iteration 8300, loss = 0.00752028
I0131 06:14:02.537187 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:14:02.537204 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00405286 (* 1 = 0.00405286 loss)
I0131 06:14:02.537212 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:14:02.537222 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.45703e-05 (* 1 = 1.45703e-05 loss)
I0131 06:14:02.537232 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:14:02.537243 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000137824 (* 1 = 0.000137824 loss)
I0131 06:14:02.537256 25291 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
>>> 2017-01-31 06:15:03.169594 Begin model classification tests
>>> 2017-01-31 06:17:51.057032 Iteration 8400 mean classification accuracy (rgb)  0.897307361787
>>> 2017-01-31 06:17:51.057095 Iteration 8400 mean classification accuracy (depth) 0.75136064165
>>> 2017-01-31 06:17:51.057117 Iteration 8400 mean classification accuracy (rgbd)  0.926382125465
>>> 2017-01-31 06:17:51.057132 Iteration 8400 mean testing loss (rgb) 0.459548337966
>>> 2017-01-31 06:17:51.057153 Iteration 8400 mean testing loss (depth) 1.60587156836
>>> 2017-01-31 06:17:51.057171 Iteration 8400 mean testing loss (rgbd) 0.29002039866
>>> 2017-01-31 06:17:51.057187 Iteration 8400 mean confusion matrix
[ 1.          0.10365854  1.          1.          1.          0.81987578
  1.          0.72173913  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.82394366  1.          1.          1.          1.          0.98136646
  0.18421053  0.89506173  1.          0.87943262  0.85        0.94557823
  0.72072072  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:17:51.677443 25291 solver.cpp:228] Iteration 8400, loss = 0.00125006
I0131 06:17:51.677584 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:17:51.677631 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00117906 (* 1 = 0.00117906 loss)
I0131 06:17:51.677682 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:17:51.677726 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.75858e-06 (* 1 = 8.75858e-06 loss)
I0131 06:17:51.677767 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:17:51.677805 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.22375e-05 (* 1 = 6.22375e-05 loss)
I0131 06:17:51.677847 25291 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0131 06:18:54.720065 25291 solver.cpp:228] Iteration 8500, loss = 0.00748864
I0131 06:18:54.720118 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:18:54.720141 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00604078 (* 1 = 0.00604078 loss)
I0131 06:18:54.720150 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:18:54.720157 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.30698e-05 (* 1 = 5.30698e-05 loss)
I0131 06:18:54.720165 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:18:54.720172 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000127215 (* 1 = 0.000127215 loss)
I0131 06:18:54.720181 25291 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
>>> 2017-01-31 06:19:54.780794 Begin model classification tests
>>> 2017-01-31 06:22:42.301326 Iteration 8600 mean classification accuracy (rgb)  0.897593812661
>>> 2017-01-31 06:22:42.301377 Iteration 8600 mean classification accuracy (depth) 0.754654826697
>>> 2017-01-31 06:22:42.301391 Iteration 8600 mean classification accuracy (rgbd)  0.928530507018
>>> 2017-01-31 06:22:42.301402 Iteration 8600 mean testing loss (rgb) 0.449747853199
>>> 2017-01-31 06:22:42.301422 Iteration 8600 mean testing loss (depth) 1.60980854681
>>> 2017-01-31 06:22:42.301436 Iteration 8600 mean testing loss (rgbd) 0.279896176734
>>> 2017-01-31 06:22:42.301449 Iteration 8600 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.83850932
  1.          0.72173913  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.89506173  1.          0.87943262  0.86428571  0.94557823
  0.73873874  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:22:42.925587 25291 solver.cpp:228] Iteration 8600, loss = 0.0393946
I0131 06:22:42.925637 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 06:22:42.925657 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0393078 (* 1 = 0.0393078 loss)
I0131 06:22:42.925669 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:22:42.925686 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.61555e-05 (* 1 = 2.61555e-05 loss)
I0131 06:22:42.925698 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:22:42.925712 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.06441e-05 (* 1 = 6.06441e-05 loss)
I0131 06:22:42.925727 25291 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0131 06:23:43.028823 25291 solver.cpp:228] Iteration 8700, loss = 0.00608788
I0131 06:23:43.028863 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:23:43.028877 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00446942 (* 1 = 0.00446942 loss)
I0131 06:23:43.028884 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:23:43.028892 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000221214 (* 1 = 0.000221214 loss)
I0131 06:23:43.028898 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:23:43.028904 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000163284 (* 1 = 0.000163284 loss)
I0131 06:23:43.028913 25291 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
>>> 2017-01-31 06:24:42.707485 Begin model classification tests
>>> 2017-01-31 06:27:35.628071 Iteration 8800 mean classification accuracy (rgb)  0.897880263535
>>> 2017-01-31 06:27:35.628116 Iteration 8800 mean classification accuracy (depth) 0.752506445145
>>> 2017-01-31 06:27:35.628125 Iteration 8800 mean classification accuracy (rgbd)  0.928530507018
>>> 2017-01-31 06:27:35.628134 Iteration 8800 mean testing loss (rgb) 0.439112623613
>>> 2017-01-31 06:27:35.628145 Iteration 8800 mean testing loss (depth) 1.61189974157
>>> 2017-01-31 06:27:35.628152 Iteration 8800 mean testing loss (rgbd) 0.280985157493
>>> 2017-01-31 06:27:35.628159 Iteration 8800 mean confusion matrix
[ 1.          0.11585366  1.          1.          1.          0.86335404
  1.          0.70434783  0.91269841  1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.88888889  1.          0.87234043  0.88571429  0.95238095
  0.72972973  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:27:36.202783 25291 solver.cpp:228] Iteration 8800, loss = 0.00533565
I0131 06:27:36.202821 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:27:36.202831 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00229494 (* 1 = 0.00229494 loss)
I0131 06:27:36.202836 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:27:36.202841 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.00291606 (* 1 = 0.00291606 loss)
I0131 06:27:36.202847 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:27:36.202852 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000124653 (* 1 = 0.000124653 loss)
I0131 06:27:36.202859 25291 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0131 06:28:36.145223 25291 solver.cpp:228] Iteration 8900, loss = 0.0059923
I0131 06:28:36.145279 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:28:36.145292 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00372622 (* 1 = 0.00372622 loss)
I0131 06:28:36.145303 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:28:36.145310 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.5276e-06 (* 1 = 8.5276e-06 loss)
I0131 06:28:36.145316 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:28:36.145323 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.88702e-05 (* 1 = 4.88702e-05 loss)
I0131 06:28:36.145333 25291 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
I0131 06:29:35.920533 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_9000.caffemodel
I0131 06:29:44.172505 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_9000.solverstate
>>> 2017-01-31 06:29:45.858319 Begin model classification tests
>>> 2017-01-31 06:32:40.720804 Iteration 9000 mean classification accuracy (rgb)  0.899169292466
>>> 2017-01-31 06:32:40.720870 Iteration 9000 mean classification accuracy (depth) 0.749212260097
>>> 2017-01-31 06:32:40.720889 Iteration 9000 mean classification accuracy (rgbd)  0.929676310513
>>> 2017-01-31 06:32:40.720902 Iteration 9000 mean testing loss (rgb) 0.425868620752
>>> 2017-01-31 06:32:40.720921 Iteration 9000 mean testing loss (depth) 1.63184410162
>>> 2017-01-31 06:32:40.720936 Iteration 9000 mean testing loss (rgbd) 0.277111664168
>>> 2017-01-31 06:32:40.720950 Iteration 9000 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.88819876
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.93167702  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.87654321  1.          0.87943262  0.88571429  0.95918367
  0.72072072  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:32:41.336695 25291 solver.cpp:228] Iteration 9000, loss = 0.00149314
I0131 06:32:41.336792 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:32:41.336841 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00101708 (* 1 = 0.00101708 loss)
I0131 06:32:41.336870 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:32:41.336894 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000124541 (* 1 = 0.000124541 loss)
I0131 06:32:41.336912 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:32:41.336935 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000351517 (* 1 = 0.000351517 loss)
I0131 06:32:41.336961 25291 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0131 06:33:43.454815 25291 solver.cpp:228] Iteration 9100, loss = 0.00594643
I0131 06:33:43.454912 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:33:43.454972 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00437418 (* 1 = 0.00437418 loss)
I0131 06:33:43.455001 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:33:43.455076 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000392716 (* 1 = 0.000392716 loss)
I0131 06:33:43.455107 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:33:43.455139 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000711442 (* 1 = 0.000711442 loss)
I0131 06:33:43.455162 25291 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
>>> 2017-01-31 06:34:45.857182 Begin model classification tests
>>> 2017-01-31 06:37:45.920493 Iteration 9200 mean classification accuracy (rgb)  0.901174448582
>>> 2017-01-31 06:37:45.920536 Iteration 9200 mean classification accuracy (depth) 0.750930965339
>>> 2017-01-31 06:37:45.920545 Iteration 9200 mean classification accuracy (rgbd)  0.931251790318
>>> 2017-01-31 06:37:45.920551 Iteration 9200 mean testing loss (rgb) 0.417422292273
>>> 2017-01-31 06:37:45.920564 Iteration 9200 mean testing loss (depth) 1.6266650264
>>> 2017-01-31 06:37:45.920571 Iteration 9200 mean testing loss (rgbd) 0.271242149979
>>> 2017-01-31 06:37:45.920578 Iteration 9200 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.88198758
  1.          0.73913043  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.93167702  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.96296296  1.          0.87943262  0.86428571  0.95918367
  0.7027027   1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:37:46.463965 25291 solver.cpp:228] Iteration 9200, loss = 0.00076467
I0131 06:37:46.464006 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:37:46.464020 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000639199 (* 1 = 0.000639199 loss)
I0131 06:37:46.464027 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:37:46.464035 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.03406e-05 (* 1 = 1.03406e-05 loss)
I0131 06:37:46.464041 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:37:46.464048 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00011513 (* 1 = 0.00011513 loss)
I0131 06:37:46.464056 25291 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0131 06:38:48.976482 25291 solver.cpp:228] Iteration 9300, loss = 0.00798636
I0131 06:38:48.976546 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:38:48.976567 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00267658 (* 1 = 0.00267658 loss)
I0131 06:38:48.976577 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:38:48.976584 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.14048e-06 (* 1 = 3.14048e-06 loss)
I0131 06:38:48.976591 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:38:48.976598 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 1.18802e-05 (* 1 = 1.18802e-05 loss)
I0131 06:38:48.976604 25291 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
>>> 2017-01-31 06:39:50.601744 Begin model classification tests
>>> 2017-01-31 06:42:46.663008 Iteration 9400 mean classification accuracy (rgb)  0.900315095961
>>> 2017-01-31 06:42:46.663070 Iteration 9400 mean classification accuracy (depth) 0.753652248639
>>> 2017-01-31 06:42:46.663083 Iteration 9400 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 06:42:46.663096 Iteration 9400 mean testing loss (rgb) 0.420519815616
>>> 2017-01-31 06:42:46.663114 Iteration 9400 mean testing loss (depth) 1.57674245494
>>> 2017-01-31 06:42:46.663127 Iteration 9400 mean testing loss (rgbd) 0.271438476627
>>> 2017-01-31 06:42:46.663137 Iteration 9400 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.88819876
  1.          0.72173913  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.93167702  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.95061728  1.          0.87943262  0.86428571  0.95918367
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:42:47.356937 25291 solver.cpp:228] Iteration 9400, loss = 0.0011871
I0131 06:42:47.357237 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:42:47.357331 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0011712 (* 1 = 0.0011712 loss)
I0131 06:42:47.357406 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:42:47.357486 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.64659e-06 (* 1 = 1.64659e-06 loss)
I0131 06:42:47.357559 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:42:47.357636 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 1.42522e-05 (* 1 = 1.42522e-05 loss)
I0131 06:42:47.357712 25291 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0131 06:43:49.309604 25291 solver.cpp:228] Iteration 9500, loss = 0.00601385
I0131 06:43:49.309666 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:43:49.309691 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00284829 (* 1 = 0.00284829 loss)
I0131 06:43:49.309706 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:43:49.309721 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.18135e-05 (* 1 = 4.18135e-05 loss)
I0131 06:43:49.309729 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:43:49.309736 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000177867 (* 1 = 0.000177867 loss)
I0131 06:43:49.309744 25291 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
>>> 2017-01-31 06:44:51.460642 Begin model classification tests
>>> 2017-01-31 06:47:47.307377 Iteration 9600 mean classification accuracy (rgb)  0.899742194214
>>> 2017-01-31 06:47:47.307438 Iteration 9600 mean classification accuracy (depth) 0.75408192495
>>> 2017-01-31 06:47:47.307467 Iteration 9600 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 06:47:47.307488 Iteration 9600 mean testing loss (rgb) 0.422718893306
>>> 2017-01-31 06:47:47.307513 Iteration 9600 mean testing loss (depth) 1.58225115627
>>> 2017-01-31 06:47:47.307529 Iteration 9600 mean testing loss (rgbd) 0.272848381692
>>> 2017-01-31 06:47:47.307542 Iteration 9600 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.88819876
  1.          0.72173913  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.95679012  1.          0.88652482  0.87142857  0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:47:47.879411 25291 solver.cpp:228] Iteration 9600, loss = 0.000242003
I0131 06:47:47.879498 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:47:47.879556 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000202894 (* 1 = 0.000202894 loss)
I0131 06:47:47.879590 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:47:47.879624 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.03614e-06 (* 1 = 3.03614e-06 loss)
I0131 06:47:47.879644 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:47:47.879673 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.60727e-05 (* 1 = 3.60727e-05 loss)
I0131 06:47:47.879700 25291 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0131 06:48:50.320849 25291 solver.cpp:228] Iteration 9700, loss = 0.00778019
I0131 06:48:50.320888 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:48:50.320900 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0149695 (* 1 = 0.0149695 loss)
I0131 06:48:50.320907 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:48:50.320914 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.78392e-05 (* 1 = 1.78392e-05 loss)
I0131 06:48:50.320920 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:48:50.320927 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000222879 (* 1 = 0.000222879 loss)
I0131 06:48:50.320935 25291 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
>>> 2017-01-31 06:49:52.448016 Begin model classification tests
>>> 2017-01-31 06:52:48.735804 Iteration 9800 mean classification accuracy (rgb)  0.899885419651
>>> 2017-01-31 06:52:48.735856 Iteration 9800 mean classification accuracy (depth) 0.753222572329
>>> 2017-01-31 06:52:48.735872 Iteration 9800 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 06:52:48.735882 Iteration 9800 mean testing loss (rgb) 0.421103808421
>>> 2017-01-31 06:52:48.735897 Iteration 9800 mean testing loss (depth) 1.57985572687
>>> 2017-01-31 06:52:48.735908 Iteration 9800 mean testing loss (rgbd) 0.271986804334
>>> 2017-01-31 06:52:48.735918 Iteration 9800 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.95061728  1.          0.87943262  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:52:49.294409 25291 solver.cpp:228] Iteration 9800, loss = 0.00204376
I0131 06:52:49.294464 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:52:49.294486 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00178299 (* 1 = 0.00178299 loss)
I0131 06:52:49.294497 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:52:49.294507 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000113408 (* 1 = 0.000113408 loss)
I0131 06:52:49.294513 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:52:49.294523 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000147364 (* 1 = 0.000147364 loss)
I0131 06:52:49.294533 25291 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0131 06:53:52.304548 25291 solver.cpp:228] Iteration 9900, loss = 0.00648164
I0131 06:53:52.304591 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:53:52.304610 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00128837 (* 1 = 0.00128837 loss)
I0131 06:53:52.304622 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:53:52.304636 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000140966 (* 1 = 0.000140966 loss)
I0131 06:53:52.304646 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:53:52.304661 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.36046e-05 (* 1 = 7.36046e-05 loss)
I0131 06:53:52.304672 25291 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0131 06:54:53.947412 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_10000.caffemodel
I0131 06:55:53.593461 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_10000.solverstate
>>> 2017-01-31 06:55:55.091480 Begin model classification tests
>>> 2017-01-31 06:58:44.294758 Iteration 10000 mean classification accuracy (rgb)  0.900315095961
>>> 2017-01-31 06:58:44.294794 Iteration 10000 mean classification accuracy (depth) 0.758378688055
>>> 2017-01-31 06:58:44.294803 Iteration 10000 mean classification accuracy (rgbd)  0.930965339444
>>> 2017-01-31 06:58:44.294809 Iteration 10000 mean testing loss (rgb) 0.423534366248
>>> 2017-01-31 06:58:44.294820 Iteration 10000 mean testing loss (depth) 1.54489950352
>>> 2017-01-31 06:58:44.294827 Iteration 10000 mean testing loss (rgbd) 0.272613078621
>>> 2017-01-31 06:58:44.294834 Iteration 10000 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.88819876
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.96296296  1.          0.87943262  0.88571429  0.95918367
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 06:58:44.885298 25291 solver.cpp:228] Iteration 10000, loss = 0.0235097
I0131 06:58:44.885344 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:58:44.885360 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0234358 (* 1 = 0.0234358 loss)
I0131 06:58:44.885370 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:58:44.885380 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.6301e-05 (* 1 = 1.6301e-05 loss)
I0131 06:58:44.885390 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:58:44.885401 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 5.75494e-05 (* 1 = 5.75494e-05 loss)
I0131 06:58:44.885411 25291 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0131 06:59:44.980497 25291 solver.cpp:228] Iteration 10100, loss = 0.00704032
I0131 06:59:44.980618 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 06:59:44.980654 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00403645 (* 1 = 0.00403645 loss)
I0131 06:59:44.980672 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 06:59:44.980690 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.57046e-06 (* 1 = 2.57046e-06 loss)
I0131 06:59:44.980702 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 06:59:44.980718 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 8.1748e-05 (* 1 = 8.1748e-05 loss)
I0131 06:59:44.980732 25291 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
>>> 2017-01-31 07:00:44.674376 Begin model classification tests
>>> 2017-01-31 07:03:36.877230 Iteration 10200 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 07:03:36.877296 Iteration 10200 mean classification accuracy (depth) 0.758521913492
>>> 2017-01-31 07:03:36.877319 Iteration 10200 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 07:03:36.877335 Iteration 10200 mean testing loss (rgb) 0.424308734899
>>> 2017-01-31 07:03:36.877358 Iteration 10200 mean testing loss (depth) 1.54076676814
>>> 2017-01-31 07:03:36.877374 Iteration 10200 mean testing loss (rgbd) 0.272563241261
>>> 2017-01-31 07:03:36.877389 Iteration 10200 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.88819876
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.94444444  1.          0.87943262  0.88571429  0.96598639
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:03:37.492465 25291 solver.cpp:228] Iteration 10200, loss = 0.00477167
I0131 07:03:37.492513 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:03:37.492532 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00443341 (* 1 = 0.00443341 loss)
I0131 07:03:37.492539 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:03:37.492547 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000129721 (* 1 = 0.000129721 loss)
I0131 07:03:37.492555 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:03:37.492563 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000208541 (* 1 = 0.000208541 loss)
I0131 07:03:37.492570 25291 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0131 07:04:37.336797 25291 solver.cpp:228] Iteration 10300, loss = 0.00540182
I0131 07:04:37.336844 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:04:37.336860 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00113271 (* 1 = 0.00113271 loss)
I0131 07:04:37.336869 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:04:37.336879 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.39604e-05 (* 1 = 6.39604e-05 loss)
I0131 07:04:37.336889 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:04:37.336901 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.59713e-05 (* 1 = 6.59713e-05 loss)
I0131 07:04:37.336912 25291 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
>>> 2017-01-31 07:05:37.556687 Begin model classification tests
>>> 2017-01-31 07:08:25.661283 Iteration 10400 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 07:08:25.661325 Iteration 10400 mean classification accuracy (depth) 0.757805786308
>>> 2017-01-31 07:08:25.661334 Iteration 10400 mean classification accuracy (rgbd)  0.930822114007
>>> 2017-01-31 07:08:25.661342 Iteration 10400 mean testing loss (rgb) 0.424489245337
>>> 2017-01-31 07:08:25.661353 Iteration 10400 mean testing loss (depth) 1.54510007785
>>> 2017-01-31 07:08:25.661360 Iteration 10400 mean testing loss (rgbd) 0.272733942652
>>> 2017-01-31 07:08:25.661366 Iteration 10400 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.94444444  1.          0.87943262  0.88571429  0.96598639
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:08:26.217135 25291 solver.cpp:228] Iteration 10400, loss = 0.00194681
I0131 07:08:26.217170 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:08:26.217180 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00190098 (* 1 = 0.00190098 loss)
I0131 07:08:26.217187 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:08:26.217193 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.49763e-05 (* 1 = 1.49763e-05 loss)
I0131 07:08:26.217198 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:08:26.217203 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.08477e-05 (* 1 = 3.08477e-05 loss)
I0131 07:08:26.217209 25291 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0131 07:09:26.013458 25291 solver.cpp:228] Iteration 10500, loss = 0.00703327
I0131 07:09:26.013500 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:09:26.013510 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00227504 (* 1 = 0.00227504 loss)
I0131 07:09:26.013517 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:09:26.013523 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.63064e-06 (* 1 = 4.63064e-06 loss)
I0131 07:09:26.013528 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:09:26.013535 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.20644e-05 (* 1 = 4.20644e-05 loss)
I0131 07:09:26.013540 25291 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
>>> 2017-01-31 07:10:25.868154 Begin model classification tests
>>> 2017-01-31 07:13:18.206999 Iteration 10600 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 07:13:18.207059 Iteration 10600 mean classification accuracy (depth) 0.757376109997
>>> 2017-01-31 07:13:18.207090 Iteration 10600 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 07:13:18.207107 Iteration 10600 mean testing loss (rgb) 0.424468283386
>>> 2017-01-31 07:13:18.207129 Iteration 10600 mean testing loss (depth) 1.55160943832
>>> 2017-01-31 07:13:18.207146 Iteration 10600 mean testing loss (rgbd) 0.272847329817
>>> 2017-01-31 07:13:18.207165 Iteration 10600 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.94444444  1.          0.87943262  0.88571429  0.95918367
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:13:18.821698 25291 solver.cpp:228] Iteration 10600, loss = 0.00261552
I0131 07:13:18.821753 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:13:18.821784 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00242517 (* 1 = 0.00242517 loss)
I0131 07:13:18.821799 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:13:18.821817 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000103901 (* 1 = 0.000103901 loss)
I0131 07:13:18.821832 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:13:18.821851 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 8.64521e-05 (* 1 = 8.64521e-05 loss)
I0131 07:13:18.821861 25291 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0131 07:14:21.187163 25291 solver.cpp:228] Iteration 10700, loss = 0.00709194
I0131 07:14:21.187229 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:14:21.187248 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00297742 (* 1 = 0.00297742 loss)
I0131 07:14:21.187257 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:14:21.187264 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.29487e-05 (* 1 = 2.29487e-05 loss)
I0131 07:14:21.187273 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:14:21.187281 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000110777 (* 1 = 0.000110777 loss)
I0131 07:14:21.187296 25291 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
>>> 2017-01-31 07:15:23.483149 Begin model classification tests
>>> 2017-01-31 07:18:19.861543 Iteration 10800 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 07:18:19.861609 Iteration 10800 mean classification accuracy (depth) 0.75680320825
>>> 2017-01-31 07:18:19.861632 Iteration 10800 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 07:18:19.861649 Iteration 10800 mean testing loss (rgb) 0.424374414939
>>> 2017-01-31 07:18:19.861673 Iteration 10800 mean testing loss (depth) 1.55141722344
>>> 2017-01-31 07:18:19.861691 Iteration 10800 mean testing loss (rgbd) 0.272736858554
>>> 2017-01-31 07:18:19.861709 Iteration 10800 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.94444444  1.          0.87943262  0.88571429  0.95918367
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:18:20.452509 25291 solver.cpp:228] Iteration 10800, loss = 0.00712755
I0131 07:18:20.452579 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:18:20.452618 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0070507 (* 1 = 0.0070507 loss)
I0131 07:18:20.452643 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:18:20.452674 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.19611e-06 (* 1 = 8.19611e-06 loss)
I0131 07:18:20.452698 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:18:20.452728 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.86581e-05 (* 1 = 6.86581e-05 loss)
I0131 07:18:20.452759 25291 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0131 07:19:22.596362 25291 solver.cpp:228] Iteration 10900, loss = 0.00717355
I0131 07:19:22.596398 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:19:22.596408 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0012233 (* 1 = 0.0012233 loss)
I0131 07:19:22.596416 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:19:22.596423 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.08618e-06 (* 1 = 2.08618e-06 loss)
I0131 07:19:22.596428 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:19:22.596433 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 1.93595e-05 (* 1 = 1.93595e-05 loss)
I0131 07:19:22.596441 25291 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0131 07:20:24.612725 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_11000.caffemodel
I0131 07:21:14.898358 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_11000.solverstate
>>> 2017-01-31 07:21:16.308539 Begin model classification tests
>>> 2017-01-31 07:24:06.527463 Iteration 11000 mean classification accuracy (rgb)  0.900028645087
>>> 2017-01-31 07:24:06.527512 Iteration 11000 mean classification accuracy (depth) 0.756659982813
>>> 2017-01-31 07:24:06.527525 Iteration 11000 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 07:24:06.527536 Iteration 11000 mean testing loss (rgb) 0.424535773763
>>> 2017-01-31 07:24:06.527549 Iteration 11000 mean testing loss (depth) 1.55044219437
>>> 2017-01-31 07:24:06.527557 Iteration 11000 mean testing loss (rgbd) 0.272826082628
>>> 2017-01-31 07:24:06.527565 Iteration 11000 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95918367
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:24:07.136842 25291 solver.cpp:228] Iteration 11000, loss = 0.000808204
I0131 07:24:07.136884 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:24:07.136898 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000452205 (* 1 = 0.000452205 loss)
I0131 07:24:07.136905 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:24:07.136911 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000316327 (* 1 = 0.000316327 loss)
I0131 07:24:07.136917 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:24:07.136925 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.96712e-05 (* 1 = 3.96712e-05 loss)
I0131 07:24:07.136934 25291 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0131 07:25:07.695927 25291 solver.cpp:228] Iteration 11100, loss = 0.00474756
I0131 07:25:07.695966 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:25:07.695976 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000649153 (* 1 = 0.000649153 loss)
I0131 07:25:07.695981 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:25:07.695987 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.21507e-05 (* 1 = 1.21507e-05 loss)
I0131 07:25:07.695992 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:25:07.695998 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000102458 (* 1 = 0.000102458 loss)
I0131 07:25:07.696008 25291 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
>>> 2017-01-31 07:26:07.646514 Begin model classification tests
>>> 2017-01-31 07:29:04.265931 Iteration 11200 mean classification accuracy (rgb)  0.900028645087
>>> 2017-01-31 07:29:04.265988 Iteration 11200 mean classification accuracy (depth) 0.756230306502
>>> 2017-01-31 07:29:04.266004 Iteration 11200 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 07:29:04.266017 Iteration 11200 mean testing loss (rgb) 0.424604636316
>>> 2017-01-31 07:29:04.266035 Iteration 11200 mean testing loss (depth) 1.5515785445
>>> 2017-01-31 07:29:04.266050 Iteration 11200 mean testing loss (rgbd) 0.273156103899
>>> 2017-01-31 07:29:04.266063 Iteration 11200 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95918367
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:29:04.876801 25291 solver.cpp:228] Iteration 11200, loss = 0.000949878
I0131 07:29:04.876852 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:29:04.876868 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000914162 (* 1 = 0.000914162 loss)
I0131 07:29:04.876878 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:29:04.876889 25291 solver.cpp:244]     Train net output #3: rgb_loss = 7.73403e-06 (* 1 = 7.73403e-06 loss)
I0131 07:29:04.876899 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:29:04.876911 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.79813e-05 (* 1 = 2.79813e-05 loss)
I0131 07:29:04.876924 25291 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0131 07:30:08.080906 25291 solver.cpp:228] Iteration 11300, loss = 0.00540877
I0131 07:30:08.080945 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:30:08.080955 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000790139 (* 1 = 0.000790139 loss)
I0131 07:30:08.080963 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:30:08.080971 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.81109e-05 (* 1 = 1.81109e-05 loss)
I0131 07:30:08.080976 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:30:08.080982 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 8.79502e-05 (* 1 = 8.79502e-05 loss)
I0131 07:30:08.080989 25291 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
>>> 2017-01-31 07:31:10.405898 Begin model classification tests
>>> 2017-01-31 07:34:09.089985 Iteration 11400 mean classification accuracy (rgb)  0.899312517903
>>> 2017-01-31 07:34:09.090028 Iteration 11400 mean classification accuracy (depth) 0.756230306502
>>> 2017-01-31 07:34:09.090038 Iteration 11400 mean classification accuracy (rgbd)  0.930392437697
>>> 2017-01-31 07:34:09.090047 Iteration 11400 mean testing loss (rgb) 0.425045468345
>>> 2017-01-31 07:34:09.090059 Iteration 11400 mean testing loss (depth) 1.55234682968
>>> 2017-01-31 07:34:09.090067 Iteration 11400 mean testing loss (rgbd) 0.273438154249
>>> 2017-01-31 07:34:09.090074 Iteration 11400 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:34:09.641518 25291 solver.cpp:228] Iteration 11400, loss = 0.00309065
I0131 07:34:09.641557 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:34:09.641567 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00245489 (* 1 = 0.00245489 loss)
I0131 07:34:09.641577 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:34:09.641582 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000107288 (* 1 = 0.000107288 loss)
I0131 07:34:09.641588 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:34:09.641594 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000528473 (* 1 = 0.000528473 loss)
I0131 07:34:09.641607 25291 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0131 07:35:12.362957 25291 solver.cpp:228] Iteration 11500, loss = 0.00688679
I0131 07:35:12.363040 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:35:12.363086 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00775011 (* 1 = 0.00775011 loss)
I0131 07:35:12.363107 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:35:12.363122 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.77339e-05 (* 1 = 3.77339e-05 loss)
I0131 07:35:12.363131 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:35:12.363142 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 9.04272e-05 (* 1 = 9.04272e-05 loss)
I0131 07:35:12.363152 25291 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
>>> 2017-01-31 07:36:14.227841 Begin model classification tests
>>> 2017-01-31 07:39:07.816217 Iteration 11600 mean classification accuracy (rgb)  0.899169292466
>>> 2017-01-31 07:39:07.816258 Iteration 11600 mean classification accuracy (depth) 0.756946433687
>>> 2017-01-31 07:39:07.816273 Iteration 11600 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 07:39:07.816285 Iteration 11600 mean testing loss (rgb) 0.425247069636
>>> 2017-01-31 07:39:07.816303 Iteration 11600 mean testing loss (depth) 1.55152162128
>>> 2017-01-31 07:39:07.816318 Iteration 11600 mean testing loss (rgbd) 0.273482778341
>>> 2017-01-31 07:39:07.816332 Iteration 11600 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:39:08.362316 25291 solver.cpp:228] Iteration 11600, loss = 0.0112967
I0131 07:39:08.362354 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:39:08.362366 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0112463 (* 1 = 0.0112463 loss)
I0131 07:39:08.362376 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:39:08.362386 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.42307e-06 (* 1 = 1.42307e-06 loss)
I0131 07:39:08.362395 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:39:08.362403 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.89956e-05 (* 1 = 4.89956e-05 loss)
I0131 07:39:08.362412 25291 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0131 07:40:10.659694 25291 solver.cpp:228] Iteration 11700, loss = 0.00524613
I0131 07:40:10.659766 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:40:10.659787 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00388739 (* 1 = 0.00388739 loss)
I0131 07:40:10.659798 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:40:10.659812 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.23822e-05 (* 1 = 1.23822e-05 loss)
I0131 07:40:10.659821 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:40:10.659832 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.43784e-05 (* 1 = 6.43784e-05 loss)
I0131 07:40:10.659847 25291 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
>>> 2017-01-31 07:41:12.225076 Begin model classification tests
>>> 2017-01-31 07:44:08.756535 Iteration 11800 mean classification accuracy (rgb)  0.899169292466
>>> 2017-01-31 07:44:08.756599 Iteration 11800 mean classification accuracy (depth) 0.755657404755
>>> 2017-01-31 07:44:08.756623 Iteration 11800 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 07:44:08.756639 Iteration 11800 mean testing loss (rgb) 0.425467657283
>>> 2017-01-31 07:44:08.756662 Iteration 11800 mean testing loss (depth) 1.55288729245
>>> 2017-01-31 07:44:08.756679 Iteration 11800 mean testing loss (rgbd) 0.273634731665
>>> 2017-01-31 07:44:08.756695 Iteration 11800 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:44:09.370234 25291 solver.cpp:228] Iteration 11800, loss = 0.00183706
I0131 07:44:09.370290 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:44:09.370309 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0017986 (* 1 = 0.0017986 loss)
I0131 07:44:09.370319 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:44:09.370329 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.36403e-06 (* 1 = 3.36403e-06 loss)
I0131 07:44:09.370339 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:44:09.370348 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.50993e-05 (* 1 = 3.50993e-05 loss)
I0131 07:44:09.370359 25291 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0131 07:45:12.156800 25291 solver.cpp:228] Iteration 11900, loss = 0.0050576
I0131 07:45:12.156863 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:45:12.156883 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00188287 (* 1 = 0.00188287 loss)
I0131 07:45:12.156890 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:45:12.156898 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.89045e-06 (* 1 = 6.89045e-06 loss)
I0131 07:45:12.156903 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:45:12.156911 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000178433 (* 1 = 0.000178433 loss)
I0131 07:45:12.156919 25291 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0131 07:46:14.565713 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_12000.caffemodel
I0131 07:47:20.069737 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_12000.solverstate
>>> 2017-01-31 07:47:22.222276 Begin model classification tests
>>> 2017-01-31 07:50:19.349167 Iteration 12000 mean classification accuracy (rgb)  0.899169292466
>>> 2017-01-31 07:50:19.349232 Iteration 12000 mean classification accuracy (depth) 0.755800630192
>>> 2017-01-31 07:50:19.349253 Iteration 12000 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 07:50:19.349263 Iteration 12000 mean testing loss (rgb) 0.425879284745
>>> 2017-01-31 07:50:19.349282 Iteration 12000 mean testing loss (depth) 1.55296744211
>>> 2017-01-31 07:50:19.349298 Iteration 12000 mean testing loss (rgbd) 0.273765302586
>>> 2017-01-31 07:50:19.349314 Iteration 12000 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:50:20.290729 25291 solver.cpp:228] Iteration 12000, loss = 0.000800548
I0131 07:50:20.290824 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:50:20.290876 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00076836 (* 1 = 0.00076836 loss)
I0131 07:50:20.290910 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:50:20.290946 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.49863e-06 (* 1 = 5.49863e-06 loss)
I0131 07:50:20.290972 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:50:20.290997 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.66891e-05 (* 1 = 2.66891e-05 loss)
I0131 07:50:20.291013 25291 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0131 07:51:23.702499 25291 solver.cpp:228] Iteration 12100, loss = 0.00655118
I0131 07:51:23.702554 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:51:23.702574 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00222074 (* 1 = 0.00222074 loss)
I0131 07:51:23.702582 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:51:23.702591 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000472582 (* 1 = 0.000472582 loss)
I0131 07:51:23.702600 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:51:23.702610 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.0013936 (* 1 = 0.0013936 loss)
I0131 07:51:23.702620 25291 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
>>> 2017-01-31 07:52:24.833074 Begin model classification tests
>>> 2017-01-31 07:55:21.708209 Iteration 12200 mean classification accuracy (rgb)  0.898453165282
>>> 2017-01-31 07:55:21.708273 Iteration 12200 mean classification accuracy (depth) 0.756659982813
>>> 2017-01-31 07:55:21.708294 Iteration 12200 mean classification accuracy (rgbd)  0.930392437697
>>> 2017-01-31 07:55:21.708309 Iteration 12200 mean testing loss (rgb) 0.426947948894
>>> 2017-01-31 07:55:21.708334 Iteration 12200 mean testing loss (depth) 1.55665892358
>>> 2017-01-31 07:55:21.708351 Iteration 12200 mean testing loss (rgbd) 0.274555416952
>>> 2017-01-31 07:55:21.708367 Iteration 12200 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 07:55:22.285887 25291 solver.cpp:228] Iteration 12200, loss = 0.00184873
I0131 07:55:22.285955 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:55:22.285992 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00169143 (* 1 = 0.00169143 loss)
I0131 07:55:22.286003 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:55:22.286018 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.0126e-05 (* 1 = 2.0126e-05 loss)
I0131 07:55:22.286029 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:55:22.286039 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000137181 (* 1 = 0.000137181 loss)
I0131 07:55:22.286058 25291 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0131 07:56:23.937822 25291 solver.cpp:228] Iteration 12300, loss = 0.00508112
I0131 07:56:23.937891 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 07:56:23.937913 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00208353 (* 1 = 0.00208353 loss)
I0131 07:56:23.937922 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 07:56:23.937932 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.34814e-06 (* 1 = 6.34814e-06 loss)
I0131 07:56:23.937938 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 07:56:23.937947 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.01488e-05 (* 1 = 7.01488e-05 loss)
I0131 07:56:23.937958 25291 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
>>> 2017-01-31 07:57:26.028585 Begin model classification tests
>>> 2017-01-31 08:00:22.597020 Iteration 12400 mean classification accuracy (rgb)  0.898453165282
>>> 2017-01-31 08:00:22.597127 Iteration 12400 mean classification accuracy (depth) 0.756230306502
>>> 2017-01-31 08:00:22.597165 Iteration 12400 mean classification accuracy (rgbd)  0.930392437697
>>> 2017-01-31 08:00:22.597196 Iteration 12400 mean testing loss (rgb) 0.426929732769
>>> 2017-01-31 08:00:22.597238 Iteration 12400 mean testing loss (depth) 1.55656914563
>>> 2017-01-31 08:00:22.597273 Iteration 12400 mean testing loss (rgbd) 0.274658653136
>>> 2017-01-31 08:00:22.597302 Iteration 12400 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:00:23.193097 25291 solver.cpp:228] Iteration 12400, loss = 0.00317537
I0131 08:00:23.193158 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:00:23.193176 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00310874 (* 1 = 0.00310874 loss)
I0131 08:00:23.193191 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:00:23.193202 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.5316e-06 (* 1 = 3.5316e-06 loss)
I0131 08:00:23.193209 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:00:23.193217 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.31028e-05 (* 1 = 6.31028e-05 loss)
I0131 08:00:23.193226 25291 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0131 08:01:26.019562 25291 solver.cpp:228] Iteration 12500, loss = 0.0049743
I0131 08:01:26.019614 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:01:26.019637 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00555465 (* 1 = 0.00555465 loss)
I0131 08:01:26.019646 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:01:26.019655 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000100902 (* 1 = 0.000100902 loss)
I0131 08:01:26.019664 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:01:26.019672 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000137182 (* 1 = 0.000137182 loss)
I0131 08:01:26.019681 25291 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
>>> 2017-01-31 08:02:26.817448 Begin model classification tests
>>> 2017-01-31 08:05:21.403481 Iteration 12600 mean classification accuracy (rgb)  0.898309939845
>>> 2017-01-31 08:05:21.403584 Iteration 12600 mean classification accuracy (depth) 0.755657404755
>>> 2017-01-31 08:05:21.403624 Iteration 12600 mean classification accuracy (rgbd)  0.930392437697
>>> 2017-01-31 08:05:21.403649 Iteration 12600 mean testing loss (rgb) 0.426720140115
>>> 2017-01-31 08:05:21.403677 Iteration 12600 mean testing loss (depth) 1.56241393175
>>> 2017-01-31 08:05:21.403693 Iteration 12600 mean testing loss (rgbd) 0.274547167357
>>> 2017-01-31 08:05:21.403709 Iteration 12600 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.95238095
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:05:21.977156 25291 solver.cpp:228] Iteration 12600, loss = 0.00129948
I0131 08:05:21.977205 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:05:21.977226 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0010544 (* 1 = 0.0010544 loss)
I0131 08:05:21.977236 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:05:21.977246 25291 solver.cpp:244]     Train net output #3: rgb_loss = 7.50677e-06 (* 1 = 7.50677e-06 loss)
I0131 08:05:21.977254 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:05:21.977263 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000237573 (* 1 = 0.000237573 loss)
I0131 08:05:21.977273 25291 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0131 08:06:23.971388 25291 solver.cpp:228] Iteration 12700, loss = 0.00561063
I0131 08:06:23.971467 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:06:23.971514 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00238515 (* 1 = 0.00238515 loss)
I0131 08:06:23.971544 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:06:23.971571 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.65052e-06 (* 1 = 8.65052e-06 loss)
I0131 08:06:23.971596 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:06:23.971607 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 5.31474e-05 (* 1 = 5.31474e-05 loss)
I0131 08:06:23.971626 25291 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
>>> 2017-01-31 08:07:25.191754 Begin model classification tests
>>> 2017-01-31 08:10:21.716605 Iteration 12800 mean classification accuracy (rgb)  0.897880263535
>>> 2017-01-31 08:10:21.716654 Iteration 12800 mean classification accuracy (depth) 0.755370953881
>>> 2017-01-31 08:10:21.716663 Iteration 12800 mean classification accuracy (rgbd)  0.930392437697
>>> 2017-01-31 08:10:21.716671 Iteration 12800 mean testing loss (rgb) 0.427048831073
>>> 2017-01-31 08:10:21.716682 Iteration 12800 mean testing loss (depth) 1.56402953025
>>> 2017-01-31 08:10:21.716689 Iteration 12800 mean testing loss (rgbd) 0.274576886253
>>> 2017-01-31 08:10:21.716696 Iteration 12800 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:10:22.277217 25291 solver.cpp:228] Iteration 12800, loss = 0.00211815
I0131 08:10:22.277271 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:10:22.277287 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00207535 (* 1 = 0.00207535 loss)
I0131 08:10:22.277297 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:10:22.277307 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.26564e-06 (* 1 = 4.26564e-06 loss)
I0131 08:10:22.277317 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:10:22.277328 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.85285e-05 (* 1 = 3.85285e-05 loss)
I0131 08:10:22.277338 25291 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0131 08:11:25.370846 25291 solver.cpp:228] Iteration 12900, loss = 0.00680787
I0131 08:11:25.370890 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:11:25.370903 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00861802 (* 1 = 0.00861802 loss)
I0131 08:11:25.370913 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:11:25.370923 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.84867e-05 (* 1 = 3.84867e-05 loss)
I0131 08:11:25.370930 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:11:25.370939 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 9.27555e-05 (* 1 = 9.27555e-05 loss)
I0131 08:11:25.370949 25291 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0131 08:12:27.549844 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_13000.caffemodel
I0131 08:13:38.281738 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_13000.solverstate
>>> 2017-01-31 08:13:39.630986 Begin model classification tests
>>> 2017-01-31 08:16:36.502853 Iteration 13000 mean classification accuracy (rgb)  0.897880263535
>>> 2017-01-31 08:16:36.502916 Iteration 13000 mean classification accuracy (depth) 0.754798052134
>>> 2017-01-31 08:16:36.502937 Iteration 13000 mean classification accuracy (rgbd)  0.930392437697
>>> 2017-01-31 08:16:36.502951 Iteration 13000 mean testing loss (rgb) 0.426879413257
>>> 2017-01-31 08:16:36.502968 Iteration 13000 mean testing loss (depth) 1.57160018453
>>> 2017-01-31 08:16:36.502986 Iteration 13000 mean testing loss (rgbd) 0.274436144038
>>> 2017-01-31 08:16:36.503002 Iteration 13000 mean confusion matrix
[ 1.          0.1402439   1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:16:37.177161 25291 solver.cpp:228] Iteration 13000, loss = 0.0163837
I0131 08:16:37.177202 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:16:37.177212 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0163475 (* 1 = 0.0163475 loss)
I0131 08:16:37.177217 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:16:37.177227 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.95152e-06 (* 1 = 6.95152e-06 loss)
I0131 08:16:37.177232 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:16:37.177238 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.93276e-05 (* 1 = 2.93276e-05 loss)
I0131 08:16:37.177244 25291 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0131 08:17:38.312552 25291 solver.cpp:228] Iteration 13100, loss = 0.00758292
I0131 08:17:38.312625 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:17:38.312647 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00165766 (* 1 = 0.00165766 loss)
I0131 08:17:38.312661 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:17:38.312675 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.703e-06 (* 1 = 3.703e-06 loss)
I0131 08:17:38.312685 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:17:38.312696 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 5.66497e-05 (* 1 = 5.66497e-05 loss)
I0131 08:17:38.312710 25291 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
>>> 2017-01-31 08:18:38.468019 Begin model classification tests
>>> 2017-01-31 08:21:26.759613 Iteration 13200 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 08:21:26.759656 Iteration 13200 mean classification accuracy (depth) 0.755514179318
>>> 2017-01-31 08:21:26.759665 Iteration 13200 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 08:21:26.759675 Iteration 13200 mean testing loss (rgb) 0.415129664227
>>> 2017-01-31 08:21:26.759686 Iteration 13200 mean testing loss (depth) 1.56996587559
>>> 2017-01-31 08:21:26.759693 Iteration 13200 mean testing loss (rgbd) 0.270853301667
>>> 2017-01-31 08:21:26.759701 Iteration 13200 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:21:27.335036 25291 solver.cpp:228] Iteration 13200, loss = 0.000802934
I0131 08:21:27.335093 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:21:27.335103 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000688773 (* 1 = 0.000688773 loss)
I0131 08:21:27.335111 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:21:27.335119 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.44164e-05 (* 1 = 1.44164e-05 loss)
I0131 08:21:27.335125 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:21:27.335131 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 9.97442e-05 (* 1 = 9.97442e-05 loss)
I0131 08:21:27.335140 25291 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0131 08:22:27.262096 25291 solver.cpp:228] Iteration 13300, loss = 0.00613889
I0131 08:22:27.262132 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:22:27.262142 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00422464 (* 1 = 0.00422464 loss)
I0131 08:22:27.262151 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:22:27.262157 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.47507e-05 (* 1 = 1.47507e-05 loss)
I0131 08:22:27.262163 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:22:27.262171 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.44215e-05 (* 1 = 7.44215e-05 loss)
I0131 08:22:27.262177 25291 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
>>> 2017-01-31 08:23:26.731583 Begin model classification tests
>>> 2017-01-31 08:26:14.514960 Iteration 13400 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 08:26:14.515003 Iteration 13400 mean classification accuracy (depth) 0.754798052134
>>> 2017-01-31 08:26:14.515017 Iteration 13400 mean classification accuracy (rgbd)  0.930822114007
>>> 2017-01-31 08:26:14.515028 Iteration 13400 mean testing loss (rgb) 0.415184238474
>>> 2017-01-31 08:26:14.515046 Iteration 13400 mean testing loss (depth) 1.57505483109
>>> 2017-01-31 08:26:14.515060 Iteration 13400 mean testing loss (rgbd) 0.270617355464
>>> 2017-01-31 08:26:14.515074 Iteration 13400 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.9068323   1.
  0.71304348  0.9047619   1.          1.          1.          0.72072072
  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.88652482  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:26:15.077098 25291 solver.cpp:228] Iteration 13400, loss = 0.000606575
I0131 08:26:15.077138 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:26:15.077153 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00053444 (* 1 = 0.00053444 loss)
I0131 08:26:15.077162 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:26:15.077173 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.3587e-06 (* 1 = 4.3587e-06 loss)
I0131 08:26:15.077183 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:26:15.077195 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.7776e-05 (* 1 = 6.7776e-05 loss)
I0131 08:26:15.077208 25291 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0131 08:27:15.416370 25291 solver.cpp:228] Iteration 13500, loss = 0.00401633
I0131 08:27:15.416404 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:27:15.416414 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0170879 (* 1 = 0.0170879 loss)
I0131 08:27:15.416421 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:27:15.416427 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.2395e-06 (* 1 = 4.2395e-06 loss)
I0131 08:27:15.416432 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:27:15.416437 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.66045e-05 (* 1 = 3.66045e-05 loss)
I0131 08:27:15.416445 25291 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
>>> 2017-01-31 08:28:15.994627 Begin model classification tests
>>> 2017-01-31 08:31:04.326923 Iteration 13600 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 08:31:04.326964 Iteration 13600 mean classification accuracy (depth) 0.75451160126
>>> 2017-01-31 08:31:04.326974 Iteration 13600 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 08:31:04.326984 Iteration 13600 mean testing loss (rgb) 0.415111799976
>>> 2017-01-31 08:31:04.326996 Iteration 13600 mean testing loss (depth) 1.57353088683
>>> 2017-01-31 08:31:04.327003 Iteration 13600 mean testing loss (rgbd) 0.270476561214
>>> 2017-01-31 08:31:04.327011 Iteration 13600 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.9068323   1.
  0.71304348  0.9047619   1.          1.          1.          0.72072072
  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:31:04.887509 25291 solver.cpp:228] Iteration 13600, loss = 0.000843838
I0131 08:31:04.887547 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:31:04.887557 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000793595 (* 1 = 0.000793595 loss)
I0131 08:31:04.887562 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:31:04.887568 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.73708e-06 (* 1 = 5.73708e-06 loss)
I0131 08:31:04.887573 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:31:04.887579 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.45069e-05 (* 1 = 4.45069e-05 loss)
I0131 08:31:04.887589 25291 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0131 08:32:05.422107 25291 solver.cpp:228] Iteration 13700, loss = 0.00669304
I0131 08:32:05.422148 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:32:05.422158 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0095266 (* 1 = 0.0095266 loss)
I0131 08:32:05.422166 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:32:05.422173 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.02708e-06 (* 1 = 4.02708e-06 loss)
I0131 08:32:05.422178 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:32:05.422183 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.05191e-05 (* 1 = 7.05191e-05 loss)
I0131 08:32:05.422188 25291 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
>>> 2017-01-31 08:33:06.060756 Begin model classification tests
>>> 2017-01-31 08:36:02.423844 Iteration 13800 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 08:36:02.423916 Iteration 13800 mean classification accuracy (depth) 0.75451160126
>>> 2017-01-31 08:36:02.424004 Iteration 13800 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 08:36:02.424084 Iteration 13800 mean testing loss (rgb) 0.415418630728
>>> 2017-01-31 08:36:02.424114 Iteration 13800 mean testing loss (depth) 1.57007546916
>>> 2017-01-31 08:36:02.424132 Iteration 13800 mean testing loss (rgbd) 0.270666839323
>>> 2017-01-31 08:36:02.424149 Iteration 13800 mean confusion matrix
[ 1.          0.15853659  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:36:03.021399 25291 solver.cpp:228] Iteration 13800, loss = 0.00183906
I0131 08:36:03.021456 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:36:03.021481 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00170417 (* 1 = 0.00170417 loss)
I0131 08:36:03.021491 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:36:03.021502 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.96229e-06 (* 1 = 4.96229e-06 loss)
I0131 08:36:03.021510 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:36:03.021520 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.00012993 (* 1 = 0.00012993 loss)
I0131 08:36:03.021530 25291 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0131 08:37:04.078933 25291 solver.cpp:228] Iteration 13900, loss = 0.00601623
I0131 08:37:04.078985 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:37:04.079002 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00838463 (* 1 = 0.00838463 loss)
I0131 08:37:04.079013 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:37:04.079023 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.39828e-05 (* 1 = 3.39828e-05 loss)
I0131 08:37:04.079035 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:37:04.079046 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000238246 (* 1 = 0.000238246 loss)
I0131 08:37:04.079057 25291 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0131 08:38:06.337389 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_14000.caffemodel
I0131 08:39:12.580476 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_14000.solverstate
>>> 2017-01-31 08:39:13.960789 Begin model classification tests
>>> 2017-01-31 08:42:14.769150 Iteration 14000 mean classification accuracy (rgb)  0.900171870524
>>> 2017-01-31 08:42:14.769237 Iteration 14000 mean classification accuracy (depth) 0.754941277571
>>> 2017-01-31 08:42:14.769272 Iteration 14000 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 08:42:14.769298 Iteration 14000 mean testing loss (rgb) 0.415812696857
>>> 2017-01-31 08:42:14.769330 Iteration 14000 mean testing loss (depth) 1.5725415265
>>> 2017-01-31 08:42:14.769351 Iteration 14000 mean testing loss (rgbd) 0.271421794177
>>> 2017-01-31 08:42:14.769369 Iteration 14000 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:42:15.472193 25291 solver.cpp:228] Iteration 14000, loss = 0.00106839
I0131 08:42:15.472262 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:42:15.472278 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000969796 (* 1 = 0.000969796 loss)
I0131 08:42:15.472290 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:42:15.472301 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.57256e-05 (* 1 = 2.57256e-05 loss)
I0131 08:42:15.472311 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:42:15.472319 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.28719e-05 (* 1 = 7.28719e-05 loss)
I0131 08:42:15.472331 25291 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0131 08:43:18.466087 25291 solver.cpp:228] Iteration 14100, loss = 0.0062065
I0131 08:43:18.466192 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:43:18.466251 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00173232 (* 1 = 0.00173232 loss)
I0131 08:43:18.466290 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:43:18.466321 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.28008e-05 (* 1 = 1.28008e-05 loss)
I0131 08:43:18.466336 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:43:18.466364 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.24356e-05 (* 1 = 6.24356e-05 loss)
I0131 08:43:18.466387 25291 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
>>> 2017-01-31 08:44:20.954389 Begin model classification tests
>>> 2017-01-31 08:47:18.140291 Iteration 14200 mean classification accuracy (rgb)  0.900028645087
>>> 2017-01-31 08:47:18.140354 Iteration 14200 mean classification accuracy (depth) 0.754941277571
>>> 2017-01-31 08:47:18.140363 Iteration 14200 mean classification accuracy (rgbd)  0.930678888571
>>> 2017-01-31 08:47:18.140370 Iteration 14200 mean testing loss (rgb) 0.416927527724
>>> 2017-01-31 08:47:18.140384 Iteration 14200 mean testing loss (depth) 1.57089641259
>>> 2017-01-31 08:47:18.140391 Iteration 14200 mean testing loss (rgbd) 0.272193414544
>>> 2017-01-31 08:47:18.140398 Iteration 14200 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:47:18.740954 25291 solver.cpp:228] Iteration 14200, loss = 0.00114782
I0131 08:47:18.741005 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:47:18.741021 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0011116 (* 1 = 0.0011116 loss)
I0131 08:47:18.741030 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:47:18.741039 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.31892e-06 (* 1 = 8.31892e-06 loss)
I0131 08:47:18.741046 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:47:18.741057 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.79037e-05 (* 1 = 2.79037e-05 loss)
I0131 08:47:18.741068 25291 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0131 08:48:21.194905 25291 solver.cpp:228] Iteration 14300, loss = 0.00511115
I0131 08:48:21.194970 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:48:21.195000 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00214457 (* 1 = 0.00214457 loss)
I0131 08:48:21.195015 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:48:21.195032 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.43617e-05 (* 1 = 2.43617e-05 loss)
I0131 08:48:21.195044 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:48:21.195060 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.53987e-05 (* 1 = 2.53987e-05 loss)
I0131 08:48:21.195073 25291 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
>>> 2017-01-31 08:49:22.962099 Begin model classification tests
>>> 2017-01-31 08:52:20.131380 Iteration 14400 mean classification accuracy (rgb)  0.900028645087
>>> 2017-01-31 08:52:20.131435 Iteration 14400 mean classification accuracy (depth) 0.754798052134
>>> 2017-01-31 08:52:20.131450 Iteration 14400 mean classification accuracy (rgbd)  0.930822114007
>>> 2017-01-31 08:52:20.131461 Iteration 14400 mean testing loss (rgb) 0.416762418048
>>> 2017-01-31 08:52:20.131478 Iteration 14400 mean testing loss (depth) 1.5694712685
>>> 2017-01-31 08:52:20.131492 Iteration 14400 mean testing loss (rgbd) 0.271941858541
>>> 2017-01-31 08:52:20.131506 Iteration 14400 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72972973  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:52:20.875341 25291 solver.cpp:228] Iteration 14400, loss = 0.00349464
I0131 08:52:20.875427 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:52:20.875460 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0034173 (* 1 = 0.0034173 loss)
I0131 08:52:20.875479 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:52:20.875506 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.03084e-06 (* 1 = 4.03084e-06 loss)
I0131 08:52:20.875526 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:52:20.875552 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.33048e-05 (* 1 = 7.33048e-05 loss)
I0131 08:52:20.875571 25291 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0131 08:53:24.816823 25291 solver.cpp:228] Iteration 14500, loss = 0.00597305
I0131 08:53:24.816892 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:53:24.816916 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00910361 (* 1 = 0.00910361 loss)
I0131 08:53:24.816929 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:53:24.816939 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000146303 (* 1 = 0.000146303 loss)
I0131 08:53:24.816946 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:53:24.816953 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000131613 (* 1 = 0.000131613 loss)
I0131 08:53:24.816962 25291 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
>>> 2017-01-31 08:54:25.920889 Begin model classification tests
>>> 2017-01-31 08:57:22.187815 Iteration 14600 mean classification accuracy (rgb)  0.899885419651
>>> 2017-01-31 08:57:22.187894 Iteration 14600 mean classification accuracy (depth) 0.754941277571
>>> 2017-01-31 08:57:22.187920 Iteration 14600 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 08:57:22.187940 Iteration 14600 mean testing loss (rgb) 0.417455784593
>>> 2017-01-31 08:57:22.187970 Iteration 14600 mean testing loss (depth) 1.57445768592
>>> 2017-01-31 08:57:22.187999 Iteration 14600 mean testing loss (rgbd) 0.272622423987
>>> 2017-01-31 08:57:22.188028 Iteration 14600 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 08:57:22.770645 25291 solver.cpp:228] Iteration 14600, loss = 0.00459464
I0131 08:57:22.770704 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:57:22.770732 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00454924 (* 1 = 0.00454924 loss)
I0131 08:57:22.770748 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:57:22.770768 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.71159e-05 (* 1 = 1.71159e-05 loss)
I0131 08:57:22.770783 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:57:22.770798 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.82842e-05 (* 1 = 2.82842e-05 loss)
I0131 08:57:22.770813 25291 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0131 08:58:24.566179 25291 solver.cpp:228] Iteration 14700, loss = 0.00689184
I0131 08:58:24.566218 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 08:58:24.566229 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00286693 (* 1 = 0.00286693 loss)
I0131 08:58:24.566241 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 08:58:24.566252 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.56762e-05 (* 1 = 3.56762e-05 loss)
I0131 08:58:24.566258 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 08:58:24.566264 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000124811 (* 1 = 0.000124811 loss)
I0131 08:58:24.566272 25291 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
>>> 2017-01-31 08:59:26.438746 Begin model classification tests
>>> 2017-01-31 09:02:21.447400 Iteration 14800 mean classification accuracy (rgb)  0.899885419651
>>> 2017-01-31 09:02:21.447443 Iteration 14800 mean classification accuracy (depth) 0.754654826697
>>> 2017-01-31 09:02:21.447452 Iteration 14800 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 09:02:21.447460 Iteration 14800 mean testing loss (rgb) 0.417637773197
>>> 2017-01-31 09:02:21.447470 Iteration 14800 mean testing loss (depth) 1.57387700384
>>> 2017-01-31 09:02:21.447477 Iteration 14800 mean testing loss (rgbd) 0.272833316253
>>> 2017-01-31 09:02:21.447484 Iteration 14800 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:02:22.010042 25291 solver.cpp:228] Iteration 14800, loss = 0.00170464
I0131 09:02:22.010082 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:02:22.010092 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00167842 (* 1 = 0.00167842 loss)
I0131 09:02:22.010100 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:02:22.010107 25291 solver.cpp:244]     Train net output #3: rgb_loss = 9.84107e-06 (* 1 = 9.84107e-06 loss)
I0131 09:02:22.010113 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:02:22.010118 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 1.63866e-05 (* 1 = 1.63866e-05 loss)
I0131 09:02:22.010124 25291 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0131 09:03:23.866791 25291 solver.cpp:228] Iteration 14900, loss = 0.00453136
I0131 09:03:23.866844 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:03:23.866861 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00884598 (* 1 = 0.00884598 loss)
I0131 09:03:23.866876 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:03:23.866889 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.00016019 (* 1 = 0.00016019 loss)
I0131 09:03:23.866899 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:03:23.866912 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.28045e-05 (* 1 = 6.28045e-05 loss)
I0131 09:03:23.866925 25291 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0131 09:04:25.464566 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_15000.caffemodel
I0131 09:05:26.798816 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_15000.solverstate
>>> 2017-01-31 09:05:28.278927 Begin model classification tests
>>> 2017-01-31 09:08:28.263107 Iteration 15000 mean classification accuracy (rgb)  0.899885419651
>>> 2017-01-31 09:08:28.263212 Iteration 15000 mean classification accuracy (depth) 0.754654826697
>>> 2017-01-31 09:08:28.263252 Iteration 15000 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 09:08:28.263274 Iteration 15000 mean testing loss (rgb) 0.417459236129
>>> 2017-01-31 09:08:28.263308 Iteration 15000 mean testing loss (depth) 1.57499640948
>>> 2017-01-31 09:08:28.263339 Iteration 15000 mean testing loss (rgbd) 0.272721452327
>>> 2017-01-31 09:08:28.263361 Iteration 15000 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:08:28.897961 25291 solver.cpp:228] Iteration 15000, loss = 0.00424869
I0131 09:08:28.898000 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:08:28.898010 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00408918 (* 1 = 0.00408918 loss)
I0131 09:08:28.898015 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:08:28.898021 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.89355e-05 (* 1 = 1.89355e-05 loss)
I0131 09:08:28.898026 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:08:28.898031 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000140575 (* 1 = 0.000140575 loss)
I0131 09:08:28.898041 25291 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0131 09:09:32.073859 25291 solver.cpp:228] Iteration 15100, loss = 0.00498454
I0131 09:09:32.073927 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:09:32.073959 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00372551 (* 1 = 0.00372551 loss)
I0131 09:09:32.073968 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:09:32.073976 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.34124e-05 (* 1 = 3.34124e-05 loss)
I0131 09:09:32.073984 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:09:32.073998 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.36263e-05 (* 1 = 7.36263e-05 loss)
I0131 09:09:32.074018 25291 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
>>> 2017-01-31 09:10:34.657163 Begin model classification tests
>>> 2017-01-31 09:13:30.429411 Iteration 15200 mean classification accuracy (rgb)  0.899885419651
>>> 2017-01-31 09:13:30.429463 Iteration 15200 mean classification accuracy (depth) 0.753795474076
>>> 2017-01-31 09:13:30.429473 Iteration 15200 mean classification accuracy (rgbd)  0.930535663134
>>> 2017-01-31 09:13:30.429480 Iteration 15200 mean testing loss (rgb) 0.417773945546
>>> 2017-01-31 09:13:30.429492 Iteration 15200 mean testing loss (depth) 1.57780685891
>>> 2017-01-31 09:13:30.429500 Iteration 15200 mean testing loss (rgbd) 0.273101364376
>>> 2017-01-31 09:13:30.429507 Iteration 15200 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.94557823
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:13:31.035161 25291 solver.cpp:228] Iteration 15200, loss = 0.00126149
I0131 09:13:31.035202 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:13:31.035214 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00118323 (* 1 = 0.00118323 loss)
I0131 09:13:31.035223 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:13:31.035230 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.18529e-05 (* 1 = 1.18529e-05 loss)
I0131 09:13:31.035238 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:13:31.035243 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.64089e-05 (* 1 = 6.64089e-05 loss)
I0131 09:13:31.035251 25291 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0131 09:14:32.621254 25291 solver.cpp:228] Iteration 15300, loss = 0.00492079
I0131 09:14:32.621300 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:14:32.621320 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0101776 (* 1 = 0.0101776 loss)
I0131 09:14:32.621331 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:14:32.621346 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.10748e-06 (* 1 = 5.10748e-06 loss)
I0131 09:14:32.621359 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:14:32.621371 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.55678e-05 (* 1 = 4.55678e-05 loss)
I0131 09:14:32.621382 25291 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
>>> 2017-01-31 09:15:33.921671 Begin model classification tests
>>> 2017-01-31 09:18:29.113517 Iteration 15400 mean classification accuracy (rgb)  0.899885419651
>>> 2017-01-31 09:18:29.113600 Iteration 15400 mean classification accuracy (depth) 0.753509023203
>>> 2017-01-31 09:18:29.113621 Iteration 15400 mean classification accuracy (rgbd)  0.93024921226
>>> 2017-01-31 09:18:29.113635 Iteration 15400 mean testing loss (rgb) 0.417930762458
>>> 2017-01-31 09:18:29.113657 Iteration 15400 mean testing loss (depth) 1.57920903117
>>> 2017-01-31 09:18:29.113673 Iteration 15400 mean testing loss (rgbd) 0.273309193994
>>> 2017-01-31 09:18:29.113688 Iteration 15400 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.90062112
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:18:30.322312 25291 solver.cpp:228] Iteration 15400, loss = 0.00305389
I0131 09:18:30.322397 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:18:30.322434 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.002637 (* 1 = 0.002637 loss)
I0131 09:18:30.322458 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:18:30.322479 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000320626 (* 1 = 0.000320626 loss)
I0131 09:18:30.322496 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:18:30.322515 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 9.62596e-05 (* 1 = 9.62596e-05 loss)
I0131 09:18:30.322535 25291 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0131 09:19:32.229387 25291 solver.cpp:228] Iteration 15500, loss = 0.00489326
I0131 09:19:32.229425 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:19:32.229436 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.020332 (* 1 = 0.020332 loss)
I0131 09:19:32.229444 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:19:32.229449 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.16368e-05 (* 1 = 1.16368e-05 loss)
I0131 09:19:32.229455 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:19:32.229461 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.33495e-05 (* 1 = 7.33495e-05 loss)
I0131 09:19:32.229468 25291 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
>>> 2017-01-31 09:20:34.173902 Begin model classification tests
>>> 2017-01-31 09:23:29.188685 Iteration 15600 mean classification accuracy (rgb)  0.899885419651
>>> 2017-01-31 09:23:29.188728 Iteration 15600 mean classification accuracy (depth) 0.753365797766
>>> 2017-01-31 09:23:29.188737 Iteration 15600 mean classification accuracy (rgbd)  0.930105986823
>>> 2017-01-31 09:23:29.188746 Iteration 15600 mean testing loss (rgb) 0.417672317393
>>> 2017-01-31 09:23:29.188757 Iteration 15600 mean testing loss (depth) 1.57961335169
>>> 2017-01-31 09:23:29.188765 Iteration 15600 mean testing loss (rgbd) 0.273730234774
>>> 2017-01-31 09:23:29.188773 Iteration 15600 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.90062112
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:23:29.742472 25291 solver.cpp:228] Iteration 15600, loss = 0.0025575
I0131 09:23:29.742508 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:23:29.742517 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00190628 (* 1 = 0.00190628 loss)
I0131 09:23:29.742524 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:23:29.742530 25291 solver.cpp:244]     Train net output #3: rgb_loss = 9.39013e-05 (* 1 = 9.39013e-05 loss)
I0131 09:23:29.742535 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:23:29.742542 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000557317 (* 1 = 0.000557317 loss)
I0131 09:23:29.742547 25291 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0131 09:24:30.097128 25291 solver.cpp:228] Iteration 15700, loss = 0.00617627
I0131 09:24:30.097198 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:24:30.097219 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00129668 (* 1 = 0.00129668 loss)
I0131 09:24:30.097230 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:24:30.097242 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.29788e-05 (* 1 = 2.29788e-05 loss)
I0131 09:24:30.097254 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:24:30.097267 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.97912e-05 (* 1 = 3.97912e-05 loss)
I0131 09:24:30.097280 25291 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
>>> 2017-01-31 09:25:29.725542 Begin model classification tests
>>> 2017-01-31 09:28:18.546045 Iteration 15800 mean classification accuracy (rgb)  0.899598968777
>>> 2017-01-31 09:28:18.546091 Iteration 15800 mean classification accuracy (depth) 0.753938699513
>>> 2017-01-31 09:28:18.546105 Iteration 15800 mean classification accuracy (rgbd)  0.93024921226
>>> 2017-01-31 09:28:18.546118 Iteration 15800 mean testing loss (rgb) 0.418266032804
>>> 2017-01-31 09:28:18.546135 Iteration 15800 mean testing loss (depth) 1.57849065055
>>> 2017-01-31 09:28:18.546149 Iteration 15800 mean testing loss (rgbd) 0.274080302448
>>> 2017-01-31 09:28:18.546163 Iteration 15800 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.90062112
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:28:19.098141 25291 solver.cpp:228] Iteration 15800, loss = 0.0015056
I0131 09:28:19.098181 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:28:19.098196 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000768287 (* 1 = 0.000768287 loss)
I0131 09:28:19.098206 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:28:19.098215 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000510169 (* 1 = 0.000510169 loss)
I0131 09:28:19.098224 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:28:19.098235 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000227147 (* 1 = 0.000227147 loss)
I0131 09:28:19.098253 25291 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0131 09:29:19.488948 25291 solver.cpp:228] Iteration 15900, loss = 0.00669808
I0131 09:29:19.488996 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:29:19.489008 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000910305 (* 1 = 0.000910305 loss)
I0131 09:29:19.489017 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:29:19.489024 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.55841e-05 (* 1 = 2.55841e-05 loss)
I0131 09:29:19.489030 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:29:19.489038 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.79188e-05 (* 1 = 6.79188e-05 loss)
I0131 09:29:19.489048 25291 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0131 09:30:18.844321 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_16000.caffemodel
I0131 09:30:31.927209 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_16000.solverstate
>>> 2017-01-31 09:30:33.850247 Begin model classification tests
>>> 2017-01-31 09:33:24.356322 Iteration 16000 mean classification accuracy (rgb)  0.899598968777
>>> 2017-01-31 09:33:24.356379 Iteration 16000 mean classification accuracy (depth) 0.753652248639
>>> 2017-01-31 09:33:24.356396 Iteration 16000 mean classification accuracy (rgbd)  0.930105986823
>>> 2017-01-31 09:33:24.356410 Iteration 16000 mean testing loss (rgb) 0.418331008178
>>> 2017-01-31 09:33:24.356430 Iteration 16000 mean testing loss (depth) 1.58042159967
>>> 2017-01-31 09:33:24.356446 Iteration 16000 mean testing loss (rgbd) 0.273724100631
>>> 2017-01-31 09:33:24.356461 Iteration 16000 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.90062112
  1.          0.69565217  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:33:24.986641 25291 solver.cpp:228] Iteration 16000, loss = 0.00189871
I0131 09:33:24.986678 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:33:24.986688 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00185729 (* 1 = 0.00185729 loss)
I0131 09:33:24.986696 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:33:24.986703 25291 solver.cpp:244]     Train net output #3: rgb_loss = 8.27788e-06 (* 1 = 8.27788e-06 loss)
I0131 09:33:24.986708 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:33:24.986714 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 3.3135e-05 (* 1 = 3.3135e-05 loss)
I0131 09:33:24.986721 25291 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0131 09:34:25.784317 25291 solver.cpp:228] Iteration 16100, loss = 0.00426175
I0131 09:34:25.784355 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:34:25.784365 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00593199 (* 1 = 0.00593199 loss)
I0131 09:34:25.784373 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:34:25.784380 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.13725e-06 (* 1 = 5.13725e-06 loss)
I0131 09:34:25.784385 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:34:25.784391 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 1.68911e-05 (* 1 = 1.68911e-05 loss)
I0131 09:34:25.784399 25291 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
>>> 2017-01-31 09:35:25.888547 Begin model classification tests
>>> 2017-01-31 09:38:14.745250 Iteration 16200 mean classification accuracy (rgb)  0.899598968777
>>> 2017-01-31 09:38:14.745290 Iteration 16200 mean classification accuracy (depth) 0.753795474076
>>> 2017-01-31 09:38:14.745299 Iteration 16200 mean classification accuracy (rgbd)  0.929962761386
>>> 2017-01-31 09:38:14.745307 Iteration 16200 mean testing loss (rgb) 0.418320632482
>>> 2017-01-31 09:38:14.745318 Iteration 16200 mean testing loss (depth) 1.58006692926
>>> 2017-01-31 09:38:14.745325 Iteration 16200 mean testing loss (rgbd) 0.273801400338
>>> 2017-01-31 09:38:14.745332 Iteration 16200 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.90062112
  1.          0.69565217  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:38:15.355348 25291 solver.cpp:228] Iteration 16200, loss = 0.000745533
I0131 09:38:15.355393 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:38:15.355409 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000564213 (* 1 = 0.000564213 loss)
I0131 09:38:15.355418 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:38:15.355427 25291 solver.cpp:244]     Train net output #3: rgb_loss = 7.04496e-06 (* 1 = 7.04496e-06 loss)
I0131 09:38:15.355433 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:38:15.355439 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000174275 (* 1 = 0.000174275 loss)
I0131 09:38:15.355448 25291 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0131 09:39:15.507815 25291 solver.cpp:228] Iteration 16300, loss = 0.00508842
I0131 09:39:15.507858 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:39:15.507871 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000996062 (* 1 = 0.000996062 loss)
I0131 09:39:15.507879 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:39:15.507887 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.16888e-05 (* 1 = 4.16888e-05 loss)
I0131 09:39:15.507894 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:39:15.507899 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.32577e-05 (* 1 = 6.32577e-05 loss)
I0131 09:39:15.507907 25291 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
>>> 2017-01-31 09:40:15.441552 Begin model classification tests
>>> 2017-01-31 09:43:06.925063 Iteration 16400 mean classification accuracy (rgb)  0.899598968777
>>> 2017-01-31 09:43:06.925104 Iteration 16400 mean classification accuracy (depth) 0.754225150387
>>> 2017-01-31 09:43:06.925113 Iteration 16400 mean classification accuracy (rgbd)  0.92981953595
>>> 2017-01-31 09:43:06.925122 Iteration 16400 mean testing loss (rgb) 0.418400006017
>>> 2017-01-31 09:43:06.925133 Iteration 16400 mean testing loss (depth) 1.57967174033
>>> 2017-01-31 09:43:06.925141 Iteration 16400 mean testing loss (rgbd) 0.273913515495
>>> 2017-01-31 09:43:06.925148 Iteration 16400 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.69565217  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:43:07.490911 25291 solver.cpp:228] Iteration 16400, loss = 0.00398432
I0131 09:43:07.490973 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:43:07.490998 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00384337 (* 1 = 0.00384337 loss)
I0131 09:43:07.491008 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:43:07.491026 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.88766e-06 (* 1 = 4.88766e-06 loss)
I0131 09:43:07.491036 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:43:07.491047 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000136066 (* 1 = 0.000136066 loss)
I0131 09:43:07.491058 25291 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0131 09:44:08.970701 25291 solver.cpp:228] Iteration 16500, loss = 0.00708569
I0131 09:44:08.970741 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:44:08.970757 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00216235 (* 1 = 0.00216235 loss)
I0131 09:44:08.970767 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:44:08.970777 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000103934 (* 1 = 0.000103934 loss)
I0131 09:44:08.970788 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:44:08.970798 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.90296e-05 (* 1 = 6.90296e-05 loss)
I0131 09:44:08.970806 25291 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
>>> 2017-01-31 09:45:08.200731 Begin model classification tests
>>> 2017-01-31 09:47:59.380177 Iteration 16600 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 09:47:59.380273 Iteration 16600 mean classification accuracy (depth) 0.754654826697
>>> 2017-01-31 09:47:59.380310 Iteration 16600 mean classification accuracy (rgbd)  0.929962761386
>>> 2017-01-31 09:47:59.380335 Iteration 16600 mean testing loss (rgb) 0.418714766291
>>> 2017-01-31 09:47:59.380365 Iteration 16600 mean testing loss (depth) 1.57680227629
>>> 2017-01-31 09:47:59.380386 Iteration 16600 mean testing loss (rgbd) 0.27379064748
>>> 2017-01-31 09:47:59.380405 Iteration 16600 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.69565217  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:47:59.943320 25291 solver.cpp:228] Iteration 16600, loss = 0.00492526
I0131 09:47:59.943362 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:47:59.943377 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00476504 (* 1 = 0.00476504 loss)
I0131 09:47:59.943383 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:47:59.943390 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.23628e-05 (* 1 = 2.23628e-05 loss)
I0131 09:47:59.943397 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:47:59.943404 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000137856 (* 1 = 0.000137856 loss)
I0131 09:47:59.943413 25291 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0131 09:49:02.502622 25291 solver.cpp:228] Iteration 16700, loss = 0.00552221
I0131 09:49:02.502660 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:49:02.502671 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00824183 (* 1 = 0.00824183 loss)
I0131 09:49:02.502678 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:49:02.502686 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000262505 (* 1 = 0.000262505 loss)
I0131 09:49:02.502691 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:49:02.502698 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.85479e-05 (* 1 = 4.85479e-05 loss)
I0131 09:49:02.502706 25291 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
>>> 2017-01-31 09:50:03.791335 Begin model classification tests
>>> 2017-01-31 09:53:00.014070 Iteration 16800 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 09:53:00.014135 Iteration 16800 mean classification accuracy (depth) 0.754798052134
>>> 2017-01-31 09:53:00.014151 Iteration 16800 mean classification accuracy (rgbd)  0.929962761386
>>> 2017-01-31 09:53:00.014164 Iteration 16800 mean testing loss (rgb) 0.41836030846
>>> 2017-01-31 09:53:00.014185 Iteration 16800 mean testing loss (depth) 1.57703833778
>>> 2017-01-31 09:53:00.014198 Iteration 16800 mean testing loss (rgbd) 0.273681790226
>>> 2017-01-31 09:53:00.014211 Iteration 16800 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.69565217  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:53:00.617684 25291 solver.cpp:228] Iteration 16800, loss = 0.00816764
I0131 09:53:00.617756 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:53:00.617790 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00795615 (* 1 = 0.00795615 loss)
I0131 09:53:00.617808 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:53:00.617821 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.00092e-05 (* 1 = 1.00092e-05 loss)
I0131 09:53:00.617830 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:53:00.617841 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000201478 (* 1 = 0.000201478 loss)
I0131 09:53:00.617851 25291 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0131 09:54:03.596164 25291 solver.cpp:228] Iteration 16900, loss = 0.00585902
I0131 09:54:03.596245 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:54:03.596266 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00225047 (* 1 = 0.00225047 loss)
I0131 09:54:03.596277 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:54:03.596292 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.36763e-05 (* 1 = 1.36763e-05 loss)
I0131 09:54:03.596304 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:54:03.596318 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.36088e-05 (* 1 = 6.36088e-05 loss)
I0131 09:54:03.596330 25291 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0131 09:55:05.567073 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_17000.caffemodel
I0131 09:56:08.036422 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_17000.solverstate
>>> 2017-01-31 09:56:09.341968 Begin model classification tests
>>> 2017-01-31 09:59:06.761311 Iteration 17000 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 09:59:06.761358 Iteration 17000 mean classification accuracy (depth) 0.75451160126
>>> 2017-01-31 09:59:06.761369 Iteration 17000 mean classification accuracy (rgbd)  0.92981953595
>>> 2017-01-31 09:59:06.761378 Iteration 17000 mean testing loss (rgb) 0.418458389369
>>> 2017-01-31 09:59:06.761391 Iteration 17000 mean testing loss (depth) 1.57293728228
>>> 2017-01-31 09:59:06.761402 Iteration 17000 mean testing loss (rgbd) 0.273631358875
>>> 2017-01-31 09:59:06.761410 Iteration 17000 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.69565217  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93197279
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 09:59:07.344205 25291 solver.cpp:228] Iteration 17000, loss = 0.00235601
I0131 09:59:07.344245 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 09:59:07.344256 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00202093 (* 1 = 0.00202093 loss)
I0131 09:59:07.344264 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 09:59:07.344272 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000263464 (* 1 = 0.000263464 loss)
I0131 09:59:07.344279 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 09:59:07.344287 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.16209e-05 (* 1 = 7.16209e-05 loss)
I0131 09:59:07.344295 25291 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0131 10:00:07.740895 25291 solver.cpp:228] Iteration 17100, loss = 0.00595795
I0131 10:00:07.740947 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:00:07.740967 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00255938 (* 1 = 0.00255938 loss)
I0131 10:00:07.740978 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:00:07.740988 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000254047 (* 1 = 0.000254047 loss)
I0131 10:00:07.740998 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:00:07.741008 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000314784 (* 1 = 0.000314784 loss)
I0131 10:00:07.741019 25291 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
>>> 2017-01-31 10:01:07.426081 Begin model classification tests
>>> 2017-01-31 10:04:03.382816 Iteration 17200 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 10:04:03.382852 Iteration 17200 mean classification accuracy (depth) 0.75451160126
>>> 2017-01-31 10:04:03.382860 Iteration 17200 mean classification accuracy (rgbd)  0.929962761386
>>> 2017-01-31 10:04:03.382869 Iteration 17200 mean testing loss (rgb) 0.418952924019
>>> 2017-01-31 10:04:03.382880 Iteration 17200 mean testing loss (depth) 1.57558091675
>>> 2017-01-31 10:04:03.382887 Iteration 17200 mean testing loss (rgbd) 0.273015066971
>>> 2017-01-31 10:04:03.382894 Iteration 17200 mean confusion matrix
[ 1.          0.15243902  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.92517007
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:04:03.973314 25291 solver.cpp:228] Iteration 17200, loss = 0.00417664
I0131 10:04:03.973366 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:04:03.973387 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00407107 (* 1 = 0.00407107 loss)
I0131 10:04:03.973398 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:04:03.973412 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.70089e-05 (* 1 = 1.70089e-05 loss)
I0131 10:04:03.973423 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:04:03.973434 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 8.85609e-05 (* 1 = 8.85609e-05 loss)
I0131 10:04:03.973445 25291 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0131 10:05:06.555245 25291 solver.cpp:228] Iteration 17300, loss = 0.00541277
I0131 10:05:06.555311 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:05:06.555330 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000320032 (* 1 = 0.000320032 loss)
I0131 10:05:06.555346 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:05:06.555371 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.74891e-05 (* 1 = 1.74891e-05 loss)
I0131 10:05:06.555390 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:05:06.555424 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.60295e-05 (* 1 = 4.60295e-05 loss)
I0131 10:05:06.555451 25291 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
>>> 2017-01-31 10:06:08.763948 Begin model classification tests
>>> 2017-01-31 10:09:04.024084 Iteration 17400 mean classification accuracy (rgb)  0.899598968777
>>> 2017-01-31 10:09:04.024136 Iteration 17400 mean classification accuracy (depth) 0.75451160126
>>> 2017-01-31 10:09:04.024157 Iteration 17400 mean classification accuracy (rgbd)  0.929962761386
>>> 2017-01-31 10:09:04.024171 Iteration 17400 mean testing loss (rgb) 0.418830897158
>>> 2017-01-31 10:09:04.024191 Iteration 17400 mean testing loss (depth) 1.57900322679
>>> 2017-01-31 10:09:04.024206 Iteration 17400 mean testing loss (rgbd) 0.272934810587
>>> 2017-01-31 10:09:04.024220 Iteration 17400 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.90062112
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.92517007
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:09:04.583992 25291 solver.cpp:228] Iteration 17400, loss = 0.00958613
I0131 10:09:04.584034 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:09:04.584048 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00945205 (* 1 = 0.00945205 loss)
I0131 10:09:04.584058 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:09:04.584067 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.18946e-05 (* 1 = 2.18946e-05 loss)
I0131 10:09:04.584080 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:09:04.584092 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000112191 (* 1 = 0.000112191 loss)
I0131 10:09:04.584103 25291 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0131 10:10:06.561769 25291 solver.cpp:228] Iteration 17500, loss = 0.005384
I0131 10:10:06.561813 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:10:06.561826 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00200269 (* 1 = 0.00200269 loss)
I0131 10:10:06.561835 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:10:06.561843 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.96811e-05 (* 1 = 2.96811e-05 loss)
I0131 10:10:06.561851 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:10:06.561859 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000120741 (* 1 = 0.000120741 loss)
I0131 10:10:06.561869 25291 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
>>> 2017-01-31 10:11:07.912232 Begin model classification tests
>>> 2017-01-31 10:13:56.768358 Iteration 17600 mean classification accuracy (rgb)  0.899598968777
>>> 2017-01-31 10:13:56.768396 Iteration 17600 mean classification accuracy (depth) 0.755084503008
>>> 2017-01-31 10:13:56.768405 Iteration 17600 mean classification accuracy (rgbd)  0.930105986823
>>> 2017-01-31 10:13:56.768413 Iteration 17600 mean testing loss (rgb) 0.418624501843
>>> 2017-01-31 10:13:56.768424 Iteration 17600 mean testing loss (depth) 1.58228895037
>>> 2017-01-31 10:13:56.768432 Iteration 17600 mean testing loss (rgbd) 0.272778286934
>>> 2017-01-31 10:13:56.768439 Iteration 17600 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:13:57.328682 25291 solver.cpp:228] Iteration 17600, loss = 0.00324068
I0131 10:13:57.328722 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:13:57.328732 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00313008 (* 1 = 0.00313008 loss)
I0131 10:13:57.328740 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:13:57.328747 25291 solver.cpp:244]     Train net output #3: rgb_loss = 9.29513e-06 (* 1 = 9.29513e-06 loss)
I0131 10:13:57.328752 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:13:57.328758 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000101308 (* 1 = 0.000101308 loss)
I0131 10:13:57.328763 25291 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0131 10:14:57.528923 25291 solver.cpp:228] Iteration 17700, loss = 0.00514538
I0131 10:14:57.528972 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 0.96875
I0131 10:14:57.528992 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0576744 (* 1 = 0.0576744 loss)
I0131 10:14:57.529003 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:14:57.529016 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.73623e-05 (* 1 = 1.73623e-05 loss)
I0131 10:14:57.529028 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:14:57.529041 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 1.77146e-05 (* 1 = 1.77146e-05 loss)
I0131 10:14:57.529053 25291 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
>>> 2017-01-31 10:15:56.846875 Begin model classification tests
>>> 2017-01-31 10:18:45.448272 Iteration 17800 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 10:18:45.448318 Iteration 17800 mean classification accuracy (depth) 0.755370953881
>>> 2017-01-31 10:18:45.448334 Iteration 17800 mean classification accuracy (rgbd)  0.930105986823
>>> 2017-01-31 10:18:45.448347 Iteration 17800 mean testing loss (rgb) 0.418892081915
>>> 2017-01-31 10:18:45.448366 Iteration 17800 mean testing loss (depth) 1.58471951053
>>> 2017-01-31 10:18:45.448381 Iteration 17800 mean testing loss (rgbd) 0.272933404001
>>> 2017-01-31 10:18:45.448395 Iteration 17800 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87943262  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:18:46.041230 25291 solver.cpp:228] Iteration 17800, loss = 0.00189008
I0131 10:18:46.041280 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:18:46.041303 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00122338 (* 1 = 0.00122338 loss)
I0131 10:18:46.041316 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:18:46.041328 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.00014869 (* 1 = 0.00014869 loss)
I0131 10:18:46.041339 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:18:46.041349 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000518009 (* 1 = 0.000518009 loss)
I0131 10:18:46.041362 25291 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0131 10:19:47.184213 25291 solver.cpp:228] Iteration 17900, loss = 0.00498768
I0131 10:19:47.184260 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:19:47.184272 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00612464 (* 1 = 0.00612464 loss)
I0131 10:19:47.184280 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:19:47.184288 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.89246e-06 (* 1 = 1.89246e-06 loss)
I0131 10:19:47.184293 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:19:47.184299 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.29894e-05 (* 1 = 4.29894e-05 loss)
I0131 10:19:47.184306 25291 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0131 10:20:48.456032 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_18000.caffemodel
I0131 10:21:05.808722 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_18000.solverstate
>>> 2017-01-31 10:21:08.907977 Begin model classification tests
>>> 2017-01-31 10:24:01.680752 Iteration 18000 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 10:24:01.680796 Iteration 18000 mean classification accuracy (depth) 0.75451160126
>>> 2017-01-31 10:24:01.680815 Iteration 18000 mean classification accuracy (rgbd)  0.930105986823
>>> 2017-01-31 10:24:01.680829 Iteration 18000 mean testing loss (rgb) 0.418639215712
>>> 2017-01-31 10:24:01.680849 Iteration 18000 mean testing loss (depth) 1.5852124059
>>> 2017-01-31 10:24:01.680864 Iteration 18000 mean testing loss (rgbd) 0.272965886917
>>> 2017-01-31 10:24:01.680878 Iteration 18000 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87234043  0.88571429  0.93877551
  0.69369369  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:24:02.299469 25291 solver.cpp:228] Iteration 18000, loss = 0.0332276
I0131 10:24:02.299510 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:24:02.299528 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0331947 (* 1 = 0.0331947 loss)
I0131 10:24:02.299538 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:24:02.299551 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.1836e-06 (* 1 = 4.1836e-06 loss)
I0131 10:24:02.299562 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:24:02.299574 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 2.87306e-05 (* 1 = 2.87306e-05 loss)
I0131 10:24:02.299587 25291 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0131 10:25:02.969774 25291 solver.cpp:228] Iteration 18100, loss = 0.00540051
I0131 10:25:02.969833 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:25:02.969859 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.01272 (* 1 = 0.01272 loss)
I0131 10:25:02.969872 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:25:02.969888 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000113248 (* 1 = 0.000113248 loss)
I0131 10:25:02.969899 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:25:02.969911 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000110752 (* 1 = 0.000110752 loss)
I0131 10:25:02.969923 25291 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
>>> 2017-01-31 10:26:02.314712 Begin model classification tests
>>> 2017-01-31 10:28:57.305362 Iteration 18200 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 10:28:57.305449 Iteration 18200 mean classification accuracy (depth) 0.754225150387
>>> 2017-01-31 10:28:57.305489 Iteration 18200 mean classification accuracy (rgbd)  0.92981953595
>>> 2017-01-31 10:28:57.305519 Iteration 18200 mean testing loss (rgb) 0.418957846109
>>> 2017-01-31 10:28:57.305550 Iteration 18200 mean testing loss (depth) 1.58458436969
>>> 2017-01-31 10:28:57.305573 Iteration 18200 mean testing loss (rgbd) 0.273247836815
>>> 2017-01-31 10:28:57.305593 Iteration 18200 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87234043  0.88571429  0.93197279
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:28:57.897055 25291 solver.cpp:228] Iteration 18200, loss = 0.00856456
I0131 10:28:57.897131 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:28:57.897150 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00792841 (* 1 = 0.00792841 loss)
I0131 10:28:57.897161 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:28:57.897173 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000212448 (* 1 = 0.000212448 loss)
I0131 10:28:57.897182 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:28:57.897194 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000423706 (* 1 = 0.000423706 loss)
I0131 10:28:57.897207 25291 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0131 10:30:00.597283 25291 solver.cpp:228] Iteration 18300, loss = 0.00666155
I0131 10:30:00.597376 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:30:00.597425 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0109234 (* 1 = 0.0109234 loss)
I0131 10:30:00.597457 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:30:00.597487 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.27887e-06 (* 1 = 5.27887e-06 loss)
I0131 10:30:00.597512 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:30:00.597540 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000129552 (* 1 = 0.000129552 loss)
I0131 10:30:00.597568 25291 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
>>> 2017-01-31 10:31:01.769928 Begin model classification tests
>>> 2017-01-31 10:33:59.535995 Iteration 18400 mean classification accuracy (rgb)  0.89945574334
>>> 2017-01-31 10:33:59.536060 Iteration 18400 mean classification accuracy (depth) 0.75451160126
>>> 2017-01-31 10:33:59.536091 Iteration 18400 mean classification accuracy (rgbd)  0.92981953595
>>> 2017-01-31 10:33:59.536121 Iteration 18400 mean testing loss (rgb) 0.419025655702
>>> 2017-01-31 10:33:59.536161 Iteration 18400 mean testing loss (depth) 1.58679352979
>>> 2017-01-31 10:33:59.536180 Iteration 18400 mean testing loss (rgbd) 0.273756869063
>>> 2017-01-31 10:33:59.536198 Iteration 18400 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87234043  0.88571429  0.93197279
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:34:00.129860 25291 solver.cpp:228] Iteration 18400, loss = 0.00559307
I0131 10:34:00.129904 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:34:00.129914 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00519058 (* 1 = 0.00519058 loss)
I0131 10:34:00.129920 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:34:00.129926 25291 solver.cpp:244]     Train net output #3: rgb_loss = 4.3846e-05 (* 1 = 4.3846e-05 loss)
I0131 10:34:00.129931 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:34:00.129936 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000358642 (* 1 = 0.000358642 loss)
I0131 10:34:00.129943 25291 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0131 10:34:59.212972 25291 solver.cpp:228] Iteration 18500, loss = 0.004191
I0131 10:34:59.213024 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:34:59.213035 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00135258 (* 1 = 0.00135258 loss)
I0131 10:34:59.213043 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:34:59.213050 25291 solver.cpp:244]     Train net output #3: rgb_loss = 5.78386e-05 (* 1 = 5.78386e-05 loss)
I0131 10:34:59.213055 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:34:59.213062 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000163177 (* 1 = 0.000163177 loss)
I0131 10:34:59.213068 25291 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
>>> 2017-01-31 10:35:57.406690 Begin model classification tests
>>> 2017-01-31 10:38:43.206391 Iteration 18600 mean classification accuracy (rgb)  0.899598968777
>>> 2017-01-31 10:38:43.206452 Iteration 18600 mean classification accuracy (depth) 0.754225150387
>>> 2017-01-31 10:38:43.206476 Iteration 18600 mean classification accuracy (rgbd)  0.929533085076
>>> 2017-01-31 10:38:43.206492 Iteration 18600 mean testing loss (rgb) 0.419024751685
>>> 2017-01-31 10:38:43.206513 Iteration 18600 mean testing loss (depth) 1.58950006452
>>> 2017-01-31 10:38:43.206528 Iteration 18600 mean testing loss (rgbd) 0.27391241747
>>> 2017-01-31 10:38:43.206543 Iteration 18600 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.69565217  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87234043  0.88571429  0.93197279
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:38:43.809027 25291 solver.cpp:228] Iteration 18600, loss = 0.00879517
I0131 10:38:43.809072 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:38:43.809090 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00771789 (* 1 = 0.00771789 loss)
I0131 10:38:43.809098 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:38:43.809105 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000367929 (* 1 = 0.000367929 loss)
I0131 10:38:43.809113 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:38:43.809120 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000709355 (* 1 = 0.000709355 loss)
I0131 10:38:43.809128 25291 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0131 10:39:42.905565 25291 solver.cpp:228] Iteration 18700, loss = 0.00536322
I0131 10:39:42.905619 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:39:42.905639 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000876625 (* 1 = 0.000876625 loss)
I0131 10:39:42.905650 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:39:42.905663 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.87481e-05 (* 1 = 1.87481e-05 loss)
I0131 10:39:42.905673 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:39:42.905685 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 4.39561e-05 (* 1 = 4.39561e-05 loss)
I0131 10:39:42.905696 25291 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
>>> 2017-01-31 10:40:40.772507 Begin model classification tests
>>> 2017-01-31 10:43:30.169237 Iteration 18800 mean classification accuracy (rgb)  0.899742194214
>>> 2017-01-31 10:43:30.169280 Iteration 18800 mean classification accuracy (depth) 0.753509023203
>>> 2017-01-31 10:43:30.169290 Iteration 18800 mean classification accuracy (rgbd)  0.92981953595
>>> 2017-01-31 10:43:30.169298 Iteration 18800 mean testing loss (rgb) 0.418554737404
>>> 2017-01-31 10:43:30.169308 Iteration 18800 mean testing loss (depth) 1.58909967843
>>> 2017-01-31 10:43:30.169315 Iteration 18800 mean testing loss (rgbd) 0.274017175819
>>> 2017-01-31 10:43:30.169322 Iteration 18800 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.81690141  1.          1.          1.          1.          0.98757764
  0.19078947  0.94444444  1.          0.87234043  0.88571429  0.93197279
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:43:30.722894 25291 solver.cpp:228] Iteration 18800, loss = 0.00147041
I0131 10:43:30.722935 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:43:30.722944 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00136593 (* 1 = 0.00136593 loss)
I0131 10:43:30.722954 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:43:30.722959 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.78454e-05 (* 1 = 2.78454e-05 loss)
I0131 10:43:30.722965 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:43:30.722970 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.66339e-05 (* 1 = 7.66339e-05 loss)
I0131 10:43:30.722976 25291 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0131 10:44:31.069547 25291 solver.cpp:228] Iteration 18900, loss = 0.00400961
I0131 10:44:31.069586 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:44:31.069595 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00020195 (* 1 = 0.00020195 loss)
I0131 10:44:31.069604 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:44:31.069612 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.2092e-05 (* 1 = 3.2092e-05 loss)
I0131 10:44:31.069617 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:44:31.069622 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000114797 (* 1 = 0.000114797 loss)
I0131 10:44:31.069629 25291 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0131 10:45:30.243115 25291 solver.cpp:454] Snapshotting to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_19000.caffemodel
I0131 10:45:45.076577 25291 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/kevin/snapshot/rgbd_stage3_iter_19000.solverstate
>>> 2017-01-31 10:45:47.028369 Begin model classification tests
>>> 2017-01-31 10:48:36.678000 Iteration 19000 mean classification accuracy (rgb)  0.899598968777
>>> 2017-01-31 10:48:36.678040 Iteration 19000 mean classification accuracy (depth) 0.752936121455
>>> 2017-01-31 10:48:36.678050 Iteration 19000 mean classification accuracy (rgbd)  0.929533085076
>>> 2017-01-31 10:48:36.678061 Iteration 19000 mean testing loss (rgb) 0.418638685447
>>> 2017-01-31 10:48:36.678072 Iteration 19000 mean testing loss (depth) 1.59144627596
>>> 2017-01-31 10:48:36.678079 Iteration 19000 mean testing loss (rgbd) 0.274148612253
>>> 2017-01-31 10:48:36.678091 Iteration 19000 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.80985915  1.          1.          1.          1.          0.98757764
  0.19078947  0.9382716   1.          0.87234043  0.88571429  0.93197279
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:48:37.266345 25291 solver.cpp:228] Iteration 19000, loss = 0.00309693
I0131 10:48:37.266384 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:48:37.266394 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00296055 (* 1 = 0.00296055 loss)
I0131 10:48:37.266403 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:48:37.266412 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.53326e-05 (* 1 = 6.53326e-05 loss)
I0131 10:48:37.266422 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:48:37.266433 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.10502e-05 (* 1 = 7.10502e-05 loss)
I0131 10:48:37.266443 25291 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0131 10:49:37.206056 25291 solver.cpp:228] Iteration 19100, loss = 0.00534924
I0131 10:49:37.206192 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:49:37.206236 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00969648 (* 1 = 0.00969648 loss)
I0131 10:49:37.206274 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:49:37.206296 25291 solver.cpp:244]     Train net output #3: rgb_loss = 0.000126194 (* 1 = 0.000126194 loss)
I0131 10:49:37.206308 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:49:37.206320 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 6.92897e-05 (* 1 = 6.92897e-05 loss)
I0131 10:49:37.206339 25291 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
>>> 2017-01-31 10:50:36.333896 Begin model classification tests
>>> 2017-01-31 10:53:31.912139 Iteration 19200 mean classification accuracy (rgb)  0.899312517903
>>> 2017-01-31 10:53:31.912203 Iteration 19200 mean classification accuracy (depth) 0.753795474076
>>> 2017-01-31 10:53:31.912225 Iteration 19200 mean classification accuracy (rgbd)  0.928960183329
>>> 2017-01-31 10:53:31.912238 Iteration 19200 mean testing loss (rgb) 0.419593306492
>>> 2017-01-31 10:53:31.912254 Iteration 19200 mean testing loss (depth) 1.58934979076
>>> 2017-01-31 10:53:31.912265 Iteration 19200 mean testing loss (rgbd) 0.275535504375
>>> 2017-01-31 10:53:31.912278 Iteration 19200 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.71304348  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.80985915  1.          1.          1.          1.          0.98757764
  0.18421053  0.9382716   1.          0.87943262  0.88571429  0.89795918
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:53:32.487007 25291 solver.cpp:228] Iteration 19200, loss = 0.0024646
I0131 10:53:32.487108 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:53:32.487154 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00233277 (* 1 = 0.00233277 loss)
I0131 10:53:32.487193 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:53:32.487233 25291 solver.cpp:244]     Train net output #3: rgb_loss = 2.8456e-05 (* 1 = 2.8456e-05 loss)
I0131 10:53:32.487272 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:53:32.487306 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000103369 (* 1 = 0.000103369 loss)
I0131 10:53:32.487368 25291 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0131 10:54:32.900272 25291 solver.cpp:228] Iteration 19300, loss = 0.0047504
I0131 10:54:32.900362 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:54:32.900398 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.0153071 (* 1 = 0.0153071 loss)
I0131 10:54:32.900418 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:54:32.900436 25291 solver.cpp:244]     Train net output #3: rgb_loss = 6.94036e-06 (* 1 = 6.94036e-06 loss)
I0131 10:54:32.900451 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:54:32.900467 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000237867 (* 1 = 0.000237867 loss)
I0131 10:54:32.900483 25291 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
>>> 2017-01-31 10:55:32.770326 Begin model classification tests
>>> 2017-01-31 10:58:26.362382 Iteration 19400 mean classification accuracy (rgb)  0.899169292466
>>> 2017-01-31 10:58:26.362427 Iteration 19400 mean classification accuracy (depth) 0.753222572329
>>> 2017-01-31 10:58:26.362444 Iteration 19400 mean classification accuracy (rgbd)  0.928673732455
>>> 2017-01-31 10:58:26.362456 Iteration 19400 mean testing loss (rgb) 0.419663048617
>>> 2017-01-31 10:58:26.362474 Iteration 19400 mean testing loss (depth) 1.59200070082
>>> 2017-01-31 10:58:26.362490 Iteration 19400 mean testing loss (rgbd) 0.27592027642
>>> 2017-01-31 10:58:26.362505 Iteration 19400 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.80985915  1.          1.          1.          1.          0.98757764
  0.18421053  0.9382716   1.          0.87234043  0.88571429  0.89795918
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 10:58:26.926151 25291 solver.cpp:228] Iteration 19400, loss = 0.00632654
I0131 10:58:26.926195 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:58:26.926209 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.00617447 (* 1 = 0.00617447 loss)
I0131 10:58:26.926220 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:58:26.926230 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.03827e-05 (* 1 = 1.03827e-05 loss)
I0131 10:58:26.926245 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:58:26.926256 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000141689 (* 1 = 0.000141689 loss)
I0131 10:58:26.926270 25291 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0131 10:59:27.230303 25291 solver.cpp:228] Iteration 19500, loss = 0.00527075
I0131 10:59:27.230396 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 10:59:27.230448 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000881931 (* 1 = 0.000881931 loss)
I0131 10:59:27.230474 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 10:59:27.230502 25291 solver.cpp:244]     Train net output #3: rgb_loss = 1.57375e-05 (* 1 = 1.57375e-05 loss)
I0131 10:59:27.230521 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 10:59:27.230542 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 7.33856e-05 (* 1 = 7.33856e-05 loss)
I0131 10:59:27.230563 25291 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
>>> 2017-01-31 11:00:29.303243 Begin model classification tests
>>> 2017-01-31 11:03:22.910180 Iteration 19600 mean classification accuracy (rgb)  0.89902606703
>>> 2017-01-31 11:03:22.910304 Iteration 19600 mean classification accuracy (depth) 0.753222572329
>>> 2017-01-31 11:03:22.910339 Iteration 19600 mean classification accuracy (rgbd)  0.928816957892
>>> 2017-01-31 11:03:22.910360 Iteration 19600 mean testing loss (rgb) 0.41992006998
>>> 2017-01-31 11:03:22.910384 Iteration 19600 mean testing loss (depth) 1.59118452002
>>> 2017-01-31 11:03:22.910399 Iteration 19600 mean testing loss (rgbd) 0.275701068786
>>> 2017-01-31 11:03:22.910415 Iteration 19600 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.80985915  1.          1.          1.          1.          0.98757764
  0.18421053  0.9382716   1.          0.87943262  0.88571429  0.89795918
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 11:03:23.492650 25291 solver.cpp:228] Iteration 19600, loss = 0.000516407
I0131 11:03:23.492693 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 11:03:23.492703 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000308414 (* 1 = 0.000308414 loss)
I0131 11:03:23.492710 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 11:03:23.492717 25291 solver.cpp:244]     Train net output #3: rgb_loss = 3.55027e-06 (* 1 = 3.55027e-06 loss)
I0131 11:03:23.492722 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 11:03:23.492728 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 0.000204442 (* 1 = 0.000204442 loss)
I0131 11:03:23.492734 25291 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0131 11:04:25.175870 25291 solver.cpp:228] Iteration 19700, loss = 0.00658175
I0131 11:04:25.175954 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 11:04:25.175992 25291 solver.cpp:244]     Train net output #1: depth_loss = 0.000263121 (* 1 = 0.000263121 loss)
I0131 11:04:25.176008 25291 solver.cpp:244]     Train net output #2: rgb_accuracy = 1
I0131 11:04:25.176029 25291 solver.cpp:244]     Train net output #3: rgb_loss = 9.16693e-06 (* 1 = 9.16693e-06 loss)
I0131 11:04:25.176041 25291 solver.cpp:244]     Train net output #4: rgbd_accuracy = 1
I0131 11:04:25.176056 25291 solver.cpp:244]     Train net output #5: rgbd_loss = 5.35513e-05 (* 1 = 5.35513e-05 loss)
I0131 11:04:25.176070 25291 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
>>> 2017-01-31 11:05:25.253792 Begin model classification tests
>>> 2017-01-31 11:08:19.347575 Iteration 19800 mean classification accuracy (rgb)  0.898882841593
>>> 2017-01-31 11:08:19.347645 Iteration 19800 mean classification accuracy (depth) 0.753079346892
>>> 2017-01-31 11:08:19.347667 Iteration 19800 mean classification accuracy (rgbd)  0.928673732455
>>> 2017-01-31 11:08:19.347686 Iteration 19800 mean testing loss (rgb) 0.420144162994
>>> 2017-01-31 11:08:19.347707 Iteration 19800 mean testing loss (depth) 1.59120710171
>>> 2017-01-31 11:08:19.347721 Iteration 19800 mean testing loss (rgbd) 0.275965077832
>>> 2017-01-31 11:08:19.347735 Iteration 19800 mean confusion matrix
[ 1.          0.14634146  1.          1.          1.          0.89440994
  1.          0.70434783  0.9047619   1.          1.          1.
  0.72072072  1.          1.          1.          1.          1.          1.
  0.92546584  1.          1.          1.          1.          1.
  0.80985915  1.          1.          1.          1.          0.98757764
  0.18421053  0.9382716   1.          0.87234043  0.88571429  0.89795918
  0.68468468  1.          0.95535714  1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.          1.        ]
I0131 11:08:20.020774 25291 solver.cpp:228] Iteration 19800, loss = 0.00526393
I0131 11:08:20.020844 25291 solver.cpp:244]     Train net output #0: depth_accuracy = 1
I0131 11:08:20.020864 25291 solver.cpp:244]     Train net output #1: depth_lo